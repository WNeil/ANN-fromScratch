{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f027e162-1016-4255-988d-fb567cccc38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now processing the data, this will take a while...\n",
      "Epoch 1/25, Batch 1/119, Loss: 5.777004842681532\n",
      "Epoch 1/25, Batch 2/119, Loss: 5.474618732066435\n",
      "Epoch 1/25, Batch 3/119, Loss: 4.368222795705219\n",
      "Epoch 1/25, Batch 4/119, Loss: 3.9884882048629318\n",
      "Epoch 1/25, Batch 5/119, Loss: 4.1596952655205675\n",
      "Epoch 1/25, Batch 6/119, Loss: 3.4474067150013346\n",
      "Epoch 1/25, Batch 7/119, Loss: 3.132475710847291\n",
      "Epoch 1/25, Batch 8/119, Loss: 5.439696426771947\n",
      "Epoch 1/25, Batch 9/119, Loss: 3.398846669118386\n",
      "Epoch 1/25, Batch 10/119, Loss: 2.9195501285236336\n",
      "Epoch 1/25, Batch 11/119, Loss: 3.2056809842661695\n",
      "Epoch 1/25, Batch 12/119, Loss: 3.1532243785456213\n",
      "Epoch 1/25, Batch 13/119, Loss: 3.2605686279976966\n",
      "Epoch 1/25, Batch 14/119, Loss: 4.328222415939447\n",
      "Epoch 1/25, Batch 15/119, Loss: 2.7476509477826756\n",
      "Epoch 1/25, Batch 16/119, Loss: 3.7320204102386323\n",
      "Epoch 1/25, Batch 17/119, Loss: 2.6869778071334167\n",
      "Epoch 1/25, Batch 18/119, Loss: 3.8981357898625033\n",
      "Epoch 1/25, Batch 19/119, Loss: 4.236784871493132\n",
      "Epoch 1/25, Batch 20/119, Loss: 3.3618551676426685\n",
      "Epoch 1/25, Batch 21/119, Loss: 3.5515520061607617\n",
      "Epoch 1/25, Batch 22/119, Loss: 2.788490939325609\n",
      "Epoch 1/25, Batch 23/119, Loss: 2.9424283233155912\n",
      "Epoch 1/25, Batch 24/119, Loss: 3.150992291184171\n",
      "Epoch 1/25, Batch 25/119, Loss: 3.2964625788834483\n",
      "Epoch 1/25, Batch 26/119, Loss: 3.1370426008274315\n",
      "Epoch 1/25, Batch 27/119, Loss: 3.202729895765057\n",
      "Epoch 1/25, Batch 28/119, Loss: 3.3561515719439137\n",
      "Epoch 1/25, Batch 29/119, Loss: 3.5245381945587635\n",
      "Epoch 1/25, Batch 30/119, Loss: 3.4881911082148647\n",
      "Epoch 1/25, Batch 31/119, Loss: 3.0743538868480345\n",
      "Epoch 1/25, Batch 32/119, Loss: 4.254611675866497\n",
      "Epoch 1/25, Batch 33/119, Loss: 3.7882742226854664\n",
      "Epoch 1/25, Batch 34/119, Loss: 4.4859157681631965\n",
      "Epoch 1/25, Batch 35/119, Loss: 2.9752644474256553\n",
      "Epoch 1/25, Batch 36/119, Loss: 3.1658553568502006\n",
      "Epoch 1/25, Batch 37/119, Loss: 3.3677024175001504\n",
      "Epoch 1/25, Batch 38/119, Loss: 4.389842809569955\n",
      "Epoch 1/25, Batch 39/119, Loss: 2.6712429535322877\n",
      "Epoch 1/25, Batch 40/119, Loss: 5.20092853526838\n",
      "Epoch 1/25, Batch 41/119, Loss: 3.164411064296082\n",
      "Epoch 1/25, Batch 42/119, Loss: 3.1596781652058956\n",
      "Epoch 1/25, Batch 43/119, Loss: 4.359533476969522\n",
      "Epoch 1/25, Batch 44/119, Loss: 4.1321535532376075\n",
      "Epoch 1/25, Batch 45/119, Loss: 3.704065365847364\n",
      "Epoch 1/25, Batch 46/119, Loss: 3.200536540736184\n",
      "Epoch 1/25, Batch 47/119, Loss: 3.144066457238339\n",
      "Epoch 1/25, Batch 48/119, Loss: 2.9793035520906757\n",
      "Epoch 1/25, Batch 49/119, Loss: 3.388935009960084\n",
      "Epoch 1/25, Batch 50/119, Loss: 3.0031465458185536\n",
      "Epoch 1/25, Batch 51/119, Loss: 3.89794153916773\n",
      "Epoch 1/25, Batch 52/119, Loss: 3.5416690362688086\n",
      "Epoch 1/25, Batch 53/119, Loss: 4.37668890386313\n",
      "Epoch 1/25, Batch 54/119, Loss: 4.3759114698771\n",
      "Epoch 1/25, Batch 55/119, Loss: 3.1646138836182143\n",
      "Epoch 1/25, Batch 56/119, Loss: 2.959853692550677\n",
      "Epoch 1/25, Batch 57/119, Loss: 3.0285566025898727\n",
      "Epoch 1/25, Batch 58/119, Loss: 3.43536155841974\n",
      "Epoch 1/25, Batch 59/119, Loss: 3.2376395875826542\n",
      "Epoch 1/25, Batch 60/119, Loss: 3.049652071404066\n",
      "Epoch 1/25, Batch 61/119, Loss: 3.63968247175221\n",
      "Epoch 1/25, Batch 62/119, Loss: 4.3325246546119685\n",
      "Epoch 1/25, Batch 63/119, Loss: 3.034487999273679\n",
      "Epoch 1/25, Batch 64/119, Loss: 4.235278698415187\n",
      "Epoch 1/25, Batch 65/119, Loss: 2.6678229174271104\n",
      "Epoch 1/25, Batch 66/119, Loss: 3.276542228250014\n",
      "Epoch 1/25, Batch 67/119, Loss: 5.472518961063343\n",
      "Epoch 1/25, Batch 68/119, Loss: 2.827027458084544\n",
      "Epoch 1/25, Batch 69/119, Loss: 3.6488378566488016\n",
      "Epoch 1/25, Batch 70/119, Loss: 3.5417837350508026\n",
      "Epoch 1/25, Batch 71/119, Loss: 3.2005978021052655\n",
      "Epoch 1/25, Batch 72/119, Loss: 2.728840109294097\n",
      "Epoch 1/25, Batch 73/119, Loss: 2.691182777665677\n",
      "Epoch 1/25, Batch 74/119, Loss: 3.8787061976387265\n",
      "Epoch 1/25, Batch 75/119, Loss: 3.2120446438350716\n",
      "Epoch 1/25, Batch 76/119, Loss: 3.586801658203178\n",
      "Epoch 1/25, Batch 77/119, Loss: 4.702875562761905\n",
      "Epoch 1/25, Batch 78/119, Loss: 4.418260914553201\n",
      "Epoch 1/25, Batch 79/119, Loss: 3.886276241589693\n",
      "Epoch 1/25, Batch 80/119, Loss: 3.3252496142784684\n",
      "Epoch 1/25, Batch 81/119, Loss: 2.996090046181238\n",
      "Epoch 1/25, Batch 82/119, Loss: 3.268172494297363\n",
      "Epoch 1/25, Batch 83/119, Loss: 3.296539962869938\n",
      "Epoch 1/25, Batch 84/119, Loss: 3.453228201221906\n",
      "Epoch 1/25, Batch 85/119, Loss: 3.2516293443606896\n",
      "Epoch 1/25, Batch 86/119, Loss: 3.1400854953190143\n",
      "Epoch 1/25, Batch 87/119, Loss: 4.682525454268603\n",
      "Epoch 1/25, Batch 88/119, Loss: 3.123349342901841\n",
      "Epoch 1/25, Batch 89/119, Loss: 3.2236859700736358\n",
      "Epoch 1/25, Batch 90/119, Loss: 3.098752794088986\n",
      "Epoch 1/25, Batch 91/119, Loss: 3.6091451405881014\n",
      "Epoch 1/25, Batch 92/119, Loss: 4.041888526648842\n",
      "Epoch 1/25, Batch 93/119, Loss: 3.6386117450336672\n",
      "Epoch 1/25, Batch 94/119, Loss: 4.208978684210699\n",
      "Epoch 1/25, Batch 95/119, Loss: 3.683921813365583\n",
      "Epoch 1/25, Batch 96/119, Loss: 3.0515021429506346\n",
      "Epoch 1/25, Batch 97/119, Loss: 4.283777941045965\n",
      "Epoch 1/25, Batch 98/119, Loss: 3.3670727891885117\n",
      "Epoch 1/25, Batch 99/119, Loss: 4.748583325587238\n",
      "Epoch 1/25, Batch 100/119, Loss: 4.203288521044101\n",
      "Epoch 1/25, Batch 101/119, Loss: 3.4796244358577435\n",
      "Epoch 1/25, Batch 102/119, Loss: 2.832335008347874\n",
      "Epoch 1/25, Batch 103/119, Loss: 5.938209870209803\n",
      "Epoch 1/25, Batch 104/119, Loss: 3.0873540620646787\n",
      "Epoch 1/25, Batch 105/119, Loss: 4.385525291082539\n",
      "Epoch 1/25, Batch 106/119, Loss: 5.987181118569431\n",
      "Epoch 1/25, Batch 107/119, Loss: 4.0758614148385455\n",
      "Epoch 1/25, Batch 108/119, Loss: 4.056578103725887\n",
      "Epoch 1/25, Batch 109/119, Loss: 3.73030160153468\n",
      "Epoch 1/25, Batch 110/119, Loss: 3.7592828618112346\n",
      "Epoch 1/25, Batch 111/119, Loss: 4.899425492500205\n",
      "Epoch 1/25, Batch 112/119, Loss: 5.286591575454802\n",
      "Epoch 1/25, Batch 113/119, Loss: 4.854496112862033\n",
      "Epoch 1/25, Batch 114/119, Loss: 3.63168934898029\n",
      "Epoch 1/25, Batch 115/119, Loss: 3.336622402312146\n",
      "Epoch 1/25, Batch 116/119, Loss: 4.231484714284964\n",
      "Epoch 1/25, Batch 117/119, Loss: 4.605868489655004\n",
      "Epoch 1/25, Batch 118/119, Loss: 3.749025480867234\n",
      "Epoch 1/25, Batch 119/119, Loss: 3.8248930054698946\n",
      "Epoch 1/25, Batch 120/119, Loss: 4.564465494024563\n",
      "Epoch 2/25, Batch 1/119, Loss: 4.713995519181814\n",
      "Epoch 2/25, Batch 2/119, Loss: 4.276940156950246\n",
      "Epoch 2/25, Batch 3/119, Loss: 3.886343151919634\n",
      "Epoch 2/25, Batch 4/119, Loss: 4.992623691067017\n",
      "Epoch 2/25, Batch 5/119, Loss: 3.403838620873992\n",
      "Epoch 2/25, Batch 6/119, Loss: 5.321721801857593\n",
      "Epoch 2/25, Batch 7/119, Loss: 3.806257193824285\n",
      "Epoch 2/25, Batch 8/119, Loss: 5.108699284680526\n",
      "Epoch 2/25, Batch 9/119, Loss: 4.232093554026906\n",
      "Epoch 2/25, Batch 10/119, Loss: 5.682302314711988\n",
      "Epoch 2/25, Batch 11/119, Loss: 3.9617755629097973\n",
      "Epoch 2/25, Batch 12/119, Loss: 5.122246844220851\n",
      "Epoch 2/25, Batch 13/119, Loss: 4.04516775086636\n",
      "Epoch 2/25, Batch 14/119, Loss: 5.272568346682133\n",
      "Epoch 2/25, Batch 15/119, Loss: 3.596998839700561\n",
      "Epoch 2/25, Batch 16/119, Loss: 4.227925666102693\n",
      "Epoch 2/25, Batch 17/119, Loss: 3.717239580613425\n",
      "Epoch 2/25, Batch 18/119, Loss: 4.070897806528987\n",
      "Epoch 2/25, Batch 19/119, Loss: 4.321957650835647\n",
      "Epoch 2/25, Batch 20/119, Loss: 5.769839286111942\n",
      "Epoch 2/25, Batch 21/119, Loss: 4.475313550665501\n",
      "Epoch 2/25, Batch 22/119, Loss: 5.588137874959143\n",
      "Epoch 2/25, Batch 23/119, Loss: 3.8220391452848843\n",
      "Epoch 2/25, Batch 24/119, Loss: 4.550792724848529\n",
      "Epoch 2/25, Batch 25/119, Loss: 6.008162083555246\n",
      "Epoch 2/25, Batch 26/119, Loss: 4.621233863701944\n",
      "Epoch 2/25, Batch 27/119, Loss: 4.482877957564403\n",
      "Epoch 2/25, Batch 28/119, Loss: 4.9475738192432575\n",
      "Epoch 2/25, Batch 29/119, Loss: 4.851400261612673\n",
      "Epoch 2/25, Batch 30/119, Loss: 4.668646861718958\n",
      "Epoch 2/25, Batch 31/119, Loss: 3.2139006463575592\n",
      "Epoch 2/25, Batch 32/119, Loss: 3.0386295326023913\n",
      "Epoch 2/25, Batch 33/119, Loss: 2.923657512815831\n",
      "Epoch 2/25, Batch 34/119, Loss: 5.064113578911257\n",
      "Epoch 2/25, Batch 35/119, Loss: 5.97301827624351\n",
      "Epoch 2/25, Batch 36/119, Loss: 5.437948471202737\n",
      "Epoch 2/25, Batch 37/119, Loss: 3.397361582457262\n",
      "Epoch 2/25, Batch 38/119, Loss: 4.219218014053776\n",
      "Epoch 2/25, Batch 39/119, Loss: 4.206393505988595\n",
      "Epoch 2/25, Batch 40/119, Loss: 5.620978575909141\n",
      "Epoch 2/25, Batch 41/119, Loss: 3.383507288531459\n",
      "Epoch 2/25, Batch 42/119, Loss: 4.983752708081549\n",
      "Epoch 2/25, Batch 43/119, Loss: 4.569657277514987\n",
      "Epoch 2/25, Batch 44/119, Loss: 4.645069929899838\n",
      "Epoch 2/25, Batch 45/119, Loss: 2.882083357938806\n",
      "Epoch 2/25, Batch 46/119, Loss: 3.56112279772382\n",
      "Epoch 2/25, Batch 47/119, Loss: 5.1839869684946684\n",
      "Epoch 2/25, Batch 48/119, Loss: 3.6376283256594726\n",
      "Epoch 2/25, Batch 49/119, Loss: 5.088605312325817\n",
      "Epoch 2/25, Batch 50/119, Loss: 5.08574880027002\n",
      "Epoch 2/25, Batch 51/119, Loss: 3.545461361924091\n",
      "Epoch 2/25, Batch 52/119, Loss: 4.4730326096621456\n",
      "Epoch 2/25, Batch 53/119, Loss: 4.947821977472052\n",
      "Epoch 2/25, Batch 54/119, Loss: 4.929172150867445\n",
      "Epoch 2/25, Batch 55/119, Loss: 3.3679261929183477\n",
      "Epoch 2/25, Batch 56/119, Loss: 5.206005616374036\n",
      "Epoch 2/25, Batch 57/119, Loss: 5.101291881735521\n",
      "Epoch 2/25, Batch 58/119, Loss: 3.451307266294898\n",
      "Epoch 2/25, Batch 59/119, Loss: 3.7676326368371633\n",
      "Epoch 2/25, Batch 60/119, Loss: 3.6273762767805167\n",
      "Epoch 2/25, Batch 61/119, Loss: 5.2912112028652425\n",
      "Epoch 2/25, Batch 62/119, Loss: 4.19176479488501\n",
      "Epoch 2/25, Batch 63/119, Loss: 6.459242121701632\n",
      "Epoch 2/25, Batch 64/119, Loss: 2.7057266678099703\n",
      "Epoch 2/25, Batch 65/119, Loss: 6.201905413239016\n",
      "Epoch 2/25, Batch 66/119, Loss: 6.291455601932934\n",
      "Epoch 2/25, Batch 67/119, Loss: 3.274429591909338\n",
      "Epoch 2/25, Batch 68/119, Loss: 4.675034680630709\n",
      "Epoch 2/25, Batch 69/119, Loss: 4.452275668748818\n",
      "Epoch 2/25, Batch 70/119, Loss: 3.4371747580901126\n",
      "Epoch 2/25, Batch 71/119, Loss: 3.4103635425749452\n",
      "Epoch 2/25, Batch 72/119, Loss: 4.568757037589302\n",
      "Epoch 2/25, Batch 73/119, Loss: 3.302888061773311\n",
      "Epoch 2/25, Batch 74/119, Loss: 4.739924306541979\n",
      "Epoch 2/25, Batch 75/119, Loss: 4.466912042765577\n",
      "Epoch 2/25, Batch 76/119, Loss: 4.6939653519616025\n",
      "Epoch 2/25, Batch 77/119, Loss: 4.5383248424770875\n",
      "Epoch 2/25, Batch 78/119, Loss: 4.02936690064222\n",
      "Epoch 2/25, Batch 79/119, Loss: 3.4456308611525617\n",
      "Epoch 2/25, Batch 80/119, Loss: 5.961106819389248\n",
      "Epoch 2/25, Batch 81/119, Loss: 5.280279365970917\n",
      "Epoch 2/25, Batch 82/119, Loss: 4.842957281870757\n",
      "Epoch 2/25, Batch 83/119, Loss: 4.818452798841298\n",
      "Epoch 2/25, Batch 84/119, Loss: 4.168611223553241\n",
      "Epoch 2/25, Batch 85/119, Loss: 4.058109231541488\n",
      "Epoch 2/25, Batch 86/119, Loss: 4.5434254401494245\n",
      "Epoch 2/25, Batch 87/119, Loss: 4.441463772530293\n",
      "Epoch 2/25, Batch 88/119, Loss: 4.938121248503847\n",
      "Epoch 2/25, Batch 89/119, Loss: 4.218904071804468\n",
      "Epoch 2/25, Batch 90/119, Loss: 3.064560081439394\n",
      "Epoch 2/25, Batch 91/119, Loss: 3.9336136224274254\n",
      "Epoch 2/25, Batch 92/119, Loss: 4.8876312571634255\n",
      "Epoch 2/25, Batch 93/119, Loss: 3.886866076899045\n",
      "Epoch 2/25, Batch 94/119, Loss: 5.140032165492814\n",
      "Epoch 2/25, Batch 95/119, Loss: 5.836912916693455\n",
      "Epoch 2/25, Batch 96/119, Loss: 3.5797549743801076\n",
      "Epoch 2/25, Batch 97/119, Loss: 5.133192302326385\n",
      "Epoch 2/25, Batch 98/119, Loss: 3.375416109096678\n",
      "Epoch 2/25, Batch 99/119, Loss: 7.240459121774633\n",
      "Epoch 2/25, Batch 100/119, Loss: 3.9307497917969405\n",
      "Epoch 2/25, Batch 101/119, Loss: 4.633749864861805\n",
      "Epoch 2/25, Batch 102/119, Loss: 4.4495151513543965\n",
      "Epoch 2/25, Batch 103/119, Loss: 5.768288057302392\n",
      "Epoch 2/25, Batch 104/119, Loss: 6.2911332202303525\n",
      "Epoch 2/25, Batch 105/119, Loss: 3.6994592199638356\n",
      "Epoch 2/25, Batch 106/119, Loss: 4.923937459206289\n",
      "Epoch 2/25, Batch 107/119, Loss: 3.8676523144589945\n",
      "Epoch 2/25, Batch 108/119, Loss: 4.462470000769987\n",
      "Epoch 2/25, Batch 109/119, Loss: 3.903404719978838\n",
      "Epoch 2/25, Batch 110/119, Loss: 4.76490201646057\n",
      "Epoch 2/25, Batch 111/119, Loss: 4.265419467349342\n",
      "Epoch 2/25, Batch 112/119, Loss: 3.883664800549132\n",
      "Epoch 2/25, Batch 113/119, Loss: 5.48415281098911\n",
      "Epoch 2/25, Batch 114/119, Loss: 4.167723435533475\n",
      "Epoch 2/25, Batch 115/119, Loss: 6.388967356804918\n",
      "Epoch 2/25, Batch 116/119, Loss: 4.270190791803143\n",
      "Epoch 2/25, Batch 117/119, Loss: 5.975177136958718\n",
      "Epoch 2/25, Batch 118/119, Loss: 6.676046032225566\n",
      "Epoch 2/25, Batch 119/119, Loss: 3.944520366318217\n",
      "Epoch 2/25, Batch 120/119, Loss: 6.084595256350973\n",
      "Epoch 3/25, Batch 1/119, Loss: 4.56311679052832\n",
      "Epoch 3/25, Batch 2/119, Loss: 3.987681731963821\n",
      "Epoch 3/25, Batch 3/119, Loss: 4.546041786661688\n",
      "Epoch 3/25, Batch 4/119, Loss: 3.953261235238776\n",
      "Epoch 3/25, Batch 5/119, Loss: 3.76649839891041\n",
      "Epoch 3/25, Batch 6/119, Loss: 4.059231889486564\n",
      "Epoch 3/25, Batch 7/119, Loss: 4.844946046390652\n",
      "Epoch 3/25, Batch 8/119, Loss: 4.530275480966679\n",
      "Epoch 3/25, Batch 9/119, Loss: 6.266191956396279\n",
      "Epoch 3/25, Batch 10/119, Loss: 4.419873125547336\n",
      "Epoch 3/25, Batch 11/119, Loss: 5.785841057210735\n",
      "Epoch 3/25, Batch 12/119, Loss: 5.892509783699718\n",
      "Epoch 3/25, Batch 13/119, Loss: 5.364341676312671\n",
      "Epoch 3/25, Batch 14/119, Loss: 6.469977493599329\n",
      "Epoch 3/25, Batch 15/119, Loss: 4.0376120950066925\n",
      "Epoch 3/25, Batch 16/119, Loss: 7.076985775738953\n",
      "Epoch 3/25, Batch 17/119, Loss: 4.226156908935739\n",
      "Epoch 3/25, Batch 18/119, Loss: 8.525396636452614\n",
      "Epoch 3/25, Batch 19/119, Loss: 5.033427054723377\n",
      "Epoch 3/25, Batch 20/119, Loss: 3.572499034806034\n",
      "Epoch 3/25, Batch 21/119, Loss: 5.204346018948124\n",
      "Epoch 3/25, Batch 22/119, Loss: 6.161209753766974\n",
      "Epoch 3/25, Batch 23/119, Loss: 3.622908728708453\n",
      "Epoch 3/25, Batch 24/119, Loss: 3.867356500965042\n",
      "Epoch 3/25, Batch 25/119, Loss: 3.995547695979617\n",
      "Epoch 3/25, Batch 26/119, Loss: 4.4619535026747466\n",
      "Epoch 3/25, Batch 27/119, Loss: 6.252718541214386\n",
      "Epoch 3/25, Batch 28/119, Loss: 6.384567531938189\n",
      "Epoch 3/25, Batch 29/119, Loss: 5.148750068870836\n",
      "Epoch 3/25, Batch 30/119, Loss: 5.238281223477052\n",
      "Epoch 3/25, Batch 31/119, Loss: 6.027535710919143\n",
      "Epoch 3/25, Batch 32/119, Loss: 4.11064857221987\n",
      "Epoch 3/25, Batch 33/119, Loss: 4.923120306836786\n",
      "Epoch 3/25, Batch 34/119, Loss: 4.415455033764766\n",
      "Epoch 3/25, Batch 35/119, Loss: 4.34524820218693\n",
      "Epoch 3/25, Batch 36/119, Loss: 5.000783525229137\n",
      "Epoch 3/25, Batch 37/119, Loss: 4.817106291962339\n",
      "Epoch 3/25, Batch 38/119, Loss: 4.9676877154673615\n",
      "Epoch 3/25, Batch 39/119, Loss: 4.238925152386593\n",
      "Epoch 3/25, Batch 40/119, Loss: 4.367102190365461\n",
      "Epoch 3/25, Batch 41/119, Loss: 3.901800520913151\n",
      "Epoch 3/25, Batch 42/119, Loss: 4.507581014746011\n",
      "Epoch 3/25, Batch 43/119, Loss: 3.500646875773682\n",
      "Epoch 3/25, Batch 44/119, Loss: 5.706311226867654\n",
      "Epoch 3/25, Batch 45/119, Loss: 6.219607878718803\n",
      "Epoch 3/25, Batch 46/119, Loss: 6.2537375075620485\n",
      "Epoch 3/25, Batch 47/119, Loss: 5.01769714141908\n",
      "Epoch 3/25, Batch 48/119, Loss: 4.7521692588005875\n",
      "Epoch 3/25, Batch 49/119, Loss: 4.068966277138263\n",
      "Epoch 3/25, Batch 50/119, Loss: 4.047041679526404\n",
      "Epoch 3/25, Batch 51/119, Loss: 4.098267527783451\n",
      "Epoch 3/25, Batch 52/119, Loss: 5.4457580091980455\n",
      "Epoch 3/25, Batch 53/119, Loss: 5.044358504177258\n",
      "Epoch 3/25, Batch 54/119, Loss: 6.605308526795068\n",
      "Epoch 3/25, Batch 55/119, Loss: 3.007451516578914\n",
      "Epoch 3/25, Batch 56/119, Loss: 6.556271892359882\n",
      "Epoch 3/25, Batch 57/119, Loss: 4.817079536846954\n",
      "Epoch 3/25, Batch 58/119, Loss: 5.940748220866459\n",
      "Epoch 3/25, Batch 59/119, Loss: 5.112646185241449\n",
      "Epoch 3/25, Batch 60/119, Loss: 4.000629057354679\n",
      "Epoch 3/25, Batch 61/119, Loss: 4.046039147617053\n",
      "Epoch 3/25, Batch 62/119, Loss: 4.10747317727584\n",
      "Epoch 3/25, Batch 63/119, Loss: 4.352413591142485\n",
      "Epoch 3/25, Batch 64/119, Loss: 4.860505832985153\n",
      "Epoch 3/25, Batch 65/119, Loss: 3.9244103877284426\n",
      "Epoch 3/25, Batch 66/119, Loss: 3.6209773290073612\n",
      "Epoch 3/25, Batch 67/119, Loss: 6.3384751910164\n",
      "Epoch 3/25, Batch 68/119, Loss: 4.85687996368312\n",
      "Epoch 3/25, Batch 69/119, Loss: 4.871267206665376\n",
      "Epoch 3/25, Batch 70/119, Loss: 6.348393122172694\n",
      "Epoch 3/25, Batch 71/119, Loss: 5.0108903098901445\n",
      "Epoch 3/25, Batch 72/119, Loss: 5.405154412332925\n",
      "Epoch 3/25, Batch 73/119, Loss: 5.6759938793449844\n",
      "Epoch 3/25, Batch 74/119, Loss: 5.948910472764196\n",
      "Epoch 3/25, Batch 75/119, Loss: 4.659410329178539\n",
      "Epoch 3/25, Batch 76/119, Loss: 5.019387567414332\n",
      "Epoch 3/25, Batch 77/119, Loss: 3.845297086360133\n",
      "Epoch 3/25, Batch 78/119, Loss: 3.660498125694914\n",
      "Epoch 3/25, Batch 79/119, Loss: 8.322000601942687\n",
      "Epoch 3/25, Batch 80/119, Loss: 3.7399294623846404\n",
      "Epoch 3/25, Batch 81/119, Loss: 5.889539376937869\n",
      "Epoch 3/25, Batch 82/119, Loss: 6.558915295290577\n",
      "Epoch 3/25, Batch 83/119, Loss: 6.724870252175949\n",
      "Epoch 3/25, Batch 84/119, Loss: 5.089617902919591\n",
      "Epoch 3/25, Batch 85/119, Loss: 4.554069045536049\n",
      "Epoch 3/25, Batch 86/119, Loss: 4.983454261539485\n",
      "Epoch 3/25, Batch 87/119, Loss: 5.045311682672375\n",
      "Epoch 3/25, Batch 88/119, Loss: 6.222688006277076\n",
      "Epoch 3/25, Batch 89/119, Loss: 5.359575898839112\n",
      "Epoch 3/25, Batch 90/119, Loss: 3.9688813348948715\n",
      "Epoch 3/25, Batch 91/119, Loss: 5.515515105922148\n",
      "Epoch 3/25, Batch 92/119, Loss: 4.853992264810476\n",
      "Epoch 3/25, Batch 93/119, Loss: 7.0240224567866685\n",
      "Epoch 3/25, Batch 94/119, Loss: 5.382679232382988\n",
      "Epoch 3/25, Batch 95/119, Loss: 3.746168574083203\n",
      "Epoch 3/25, Batch 96/119, Loss: 3.783503902164827\n",
      "Epoch 3/25, Batch 97/119, Loss: 4.286827360435406\n",
      "Epoch 3/25, Batch 98/119, Loss: 4.977251319141353\n",
      "Epoch 3/25, Batch 99/119, Loss: 4.63227646479822\n",
      "Epoch 3/25, Batch 100/119, Loss: 3.735176193744647\n",
      "Epoch 3/25, Batch 101/119, Loss: 3.451866947176004\n",
      "Epoch 3/25, Batch 102/119, Loss: 6.482317629401052\n",
      "Epoch 3/25, Batch 103/119, Loss: 7.08419153232928\n",
      "Epoch 3/25, Batch 104/119, Loss: 4.54163372665941\n",
      "Epoch 3/25, Batch 105/119, Loss: 4.63761954763066\n",
      "Epoch 3/25, Batch 106/119, Loss: 4.533688623609032\n",
      "Epoch 3/25, Batch 107/119, Loss: 4.78610419999236\n",
      "Epoch 3/25, Batch 108/119, Loss: 5.455089848933219\n",
      "Epoch 3/25, Batch 109/119, Loss: 4.4270846933267745\n",
      "Epoch 3/25, Batch 110/119, Loss: 6.353242781787395\n",
      "Epoch 3/25, Batch 111/119, Loss: 6.336460531632131\n",
      "Epoch 3/25, Batch 112/119, Loss: 3.8302960452347317\n",
      "Epoch 3/25, Batch 113/119, Loss: 4.440190801538885\n",
      "Epoch 3/25, Batch 114/119, Loss: 5.311310432068511\n",
      "Epoch 3/25, Batch 115/119, Loss: 3.5497623544535757\n",
      "Epoch 3/25, Batch 116/119, Loss: 5.981174907933989\n",
      "Epoch 3/25, Batch 117/119, Loss: 3.8613968581340234\n",
      "Epoch 3/25, Batch 118/119, Loss: 3.749060884668135\n",
      "Epoch 3/25, Batch 119/119, Loss: 5.399528033444706\n",
      "Epoch 3/25, Batch 120/119, Loss: 6.030012048874422\n",
      "Epoch 4/25, Batch 1/119, Loss: 6.798420665654468\n",
      "Epoch 4/25, Batch 2/119, Loss: 6.073512232492954\n",
      "Epoch 4/25, Batch 3/119, Loss: 6.027947021388365\n",
      "Epoch 4/25, Batch 4/119, Loss: 6.200915618562744\n",
      "Epoch 4/25, Batch 5/119, Loss: 2.848651699635348\n",
      "Epoch 4/25, Batch 6/119, Loss: 6.510671200835541\n",
      "Epoch 4/25, Batch 7/119, Loss: 4.784619253691428\n",
      "Epoch 4/25, Batch 8/119, Loss: 6.8188847225405205\n",
      "Epoch 4/25, Batch 9/119, Loss: 6.570184100347452\n",
      "Epoch 4/25, Batch 10/119, Loss: 5.047663423590801\n",
      "Epoch 4/25, Batch 11/119, Loss: 6.5485109853939445\n",
      "Epoch 4/25, Batch 12/119, Loss: 5.708924498518833\n",
      "Epoch 4/25, Batch 13/119, Loss: 5.77619630027944\n",
      "Epoch 4/25, Batch 14/119, Loss: 6.911959543923669\n",
      "Epoch 4/25, Batch 15/119, Loss: 5.3120011145993695\n",
      "Epoch 4/25, Batch 16/119, Loss: 5.879972914984855\n",
      "Epoch 4/25, Batch 17/119, Loss: 4.729063235700214\n",
      "Epoch 4/25, Batch 18/119, Loss: 5.438621292331372\n",
      "Epoch 4/25, Batch 19/119, Loss: 3.9129746283824507\n",
      "Epoch 4/25, Batch 20/119, Loss: 6.107529418587842\n",
      "Epoch 4/25, Batch 21/119, Loss: 5.8086383336253045\n",
      "Epoch 4/25, Batch 22/119, Loss: 5.841878555583542\n",
      "Epoch 4/25, Batch 23/119, Loss: 4.801198253538385\n",
      "Epoch 4/25, Batch 24/119, Loss: 4.7701996925126195\n",
      "Epoch 4/25, Batch 25/119, Loss: 4.641322386730363\n",
      "Epoch 4/25, Batch 26/119, Loss: 6.426244439059776\n",
      "Epoch 4/25, Batch 27/119, Loss: 5.739492224419198\n",
      "Epoch 4/25, Batch 28/119, Loss: 6.510461437050802\n",
      "Epoch 4/25, Batch 29/119, Loss: 3.946806830937006\n",
      "Epoch 4/25, Batch 30/119, Loss: 4.727376756623565\n",
      "Epoch 4/25, Batch 31/119, Loss: 5.209965775938356\n",
      "Epoch 4/25, Batch 32/119, Loss: 5.153476907800728\n",
      "Epoch 4/25, Batch 33/119, Loss: 5.915216695584006\n",
      "Epoch 4/25, Batch 34/119, Loss: 6.131608689692033\n",
      "Epoch 4/25, Batch 35/119, Loss: 6.443742458266756\n",
      "Epoch 4/25, Batch 36/119, Loss: 6.778481642900421\n",
      "Epoch 4/25, Batch 37/119, Loss: 6.526175302593057\n",
      "Epoch 4/25, Batch 38/119, Loss: 6.298607162206479\n",
      "Epoch 4/25, Batch 39/119, Loss: 6.8896198122023895\n",
      "Epoch 4/25, Batch 40/119, Loss: 7.688546096658731\n",
      "Epoch 4/25, Batch 41/119, Loss: 6.624239144051255\n",
      "Epoch 4/25, Batch 42/119, Loss: 3.7752309390198877\n",
      "Epoch 4/25, Batch 43/119, Loss: 4.316556256711384\n",
      "Epoch 4/25, Batch 44/119, Loss: 4.901510211929745\n",
      "Epoch 4/25, Batch 45/119, Loss: 5.8637770780757466\n",
      "Epoch 4/25, Batch 46/119, Loss: 4.309516094238122\n",
      "Epoch 4/25, Batch 47/119, Loss: 5.92530215442433\n",
      "Epoch 4/25, Batch 48/119, Loss: 5.484137619644445\n",
      "Epoch 4/25, Batch 49/119, Loss: 5.0471411982622545\n",
      "Epoch 4/25, Batch 50/119, Loss: 5.014489673136729\n",
      "Epoch 4/25, Batch 51/119, Loss: 5.888492290396415\n",
      "Epoch 4/25, Batch 52/119, Loss: 6.088560223574278\n",
      "Epoch 4/25, Batch 53/119, Loss: 6.959925213181551\n",
      "Epoch 4/25, Batch 54/119, Loss: 3.7561496445215927\n",
      "Epoch 4/25, Batch 55/119, Loss: 6.443714946832739\n",
      "Epoch 4/25, Batch 56/119, Loss: 5.197005934355082\n",
      "Epoch 4/25, Batch 57/119, Loss: 4.1254143272996755\n",
      "Epoch 4/25, Batch 58/119, Loss: 6.60999002808515\n",
      "Epoch 4/25, Batch 59/119, Loss: 6.124440630568252\n",
      "Epoch 4/25, Batch 60/119, Loss: 4.134937188419717\n",
      "Epoch 4/25, Batch 61/119, Loss: 6.154525626239847\n",
      "Epoch 4/25, Batch 62/119, Loss: 4.158705950796878\n",
      "Epoch 4/25, Batch 63/119, Loss: 6.255288487228989\n",
      "Epoch 4/25, Batch 64/119, Loss: 5.920749528661057\n",
      "Epoch 4/25, Batch 65/119, Loss: 5.296896700932658\n",
      "Epoch 4/25, Batch 66/119, Loss: 8.279628553118549\n",
      "Epoch 4/25, Batch 67/119, Loss: 3.6938171444084285\n",
      "Epoch 4/25, Batch 68/119, Loss: 5.739507703176417\n",
      "Epoch 4/25, Batch 69/119, Loss: 4.379657202676355\n",
      "Epoch 4/25, Batch 70/119, Loss: 4.2639730436041\n",
      "Epoch 4/25, Batch 71/119, Loss: 5.0683764137112695\n",
      "Epoch 4/25, Batch 72/119, Loss: 5.472614034180619\n",
      "Epoch 4/25, Batch 73/119, Loss: 4.816078604019735\n",
      "Epoch 4/25, Batch 74/119, Loss: 3.6975671235875267\n",
      "Epoch 4/25, Batch 75/119, Loss: 7.059808474073523\n",
      "Epoch 4/25, Batch 76/119, Loss: 5.650913964611313\n",
      "Epoch 4/25, Batch 77/119, Loss: 6.677400475121789\n",
      "Epoch 4/25, Batch 78/119, Loss: 4.493099994761579\n",
      "Epoch 4/25, Batch 79/119, Loss: 6.476303318466268\n",
      "Epoch 4/25, Batch 80/119, Loss: 5.243908127756252\n",
      "Epoch 4/25, Batch 81/119, Loss: 7.171330187930024\n",
      "Epoch 4/25, Batch 82/119, Loss: 6.3512629746211315\n",
      "Epoch 4/25, Batch 83/119, Loss: 6.62933096027162\n",
      "Epoch 4/25, Batch 84/119, Loss: 4.086864708495873\n",
      "Epoch 4/25, Batch 85/119, Loss: 8.432703529037305\n",
      "Epoch 4/25, Batch 86/119, Loss: 3.797298673883628\n",
      "Epoch 4/25, Batch 87/119, Loss: 5.952178748683169\n",
      "Epoch 4/25, Batch 88/119, Loss: 3.7759605037724695\n",
      "Epoch 4/25, Batch 89/119, Loss: 5.64642513602957\n",
      "Epoch 4/25, Batch 90/119, Loss: 4.0504277808292795\n",
      "Epoch 4/25, Batch 91/119, Loss: 4.782498870229746\n",
      "Epoch 4/25, Batch 92/119, Loss: 4.246111373303395\n",
      "Epoch 4/25, Batch 93/119, Loss: 5.651702717957354\n",
      "Epoch 4/25, Batch 94/119, Loss: 4.0270915867241\n",
      "Epoch 4/25, Batch 95/119, Loss: 5.577304192687607\n",
      "Epoch 4/25, Batch 96/119, Loss: 5.594067797919563\n",
      "Epoch 4/25, Batch 97/119, Loss: 4.029342178253692\n",
      "Epoch 4/25, Batch 98/119, Loss: 5.1684374353499924\n",
      "Epoch 4/25, Batch 99/119, Loss: 7.041059401840593\n",
      "Epoch 4/25, Batch 100/119, Loss: 6.279955395669628\n",
      "Epoch 4/25, Batch 101/119, Loss: 5.728597393375087\n",
      "Epoch 4/25, Batch 102/119, Loss: 6.833544353135617\n",
      "Epoch 4/25, Batch 103/119, Loss: 5.340980643710503\n",
      "Epoch 4/25, Batch 104/119, Loss: 6.198573748033102\n",
      "Epoch 4/25, Batch 105/119, Loss: 3.7668079235022374\n",
      "Epoch 4/25, Batch 106/119, Loss: 4.240052756838776\n",
      "Epoch 4/25, Batch 107/119, Loss: 6.904936681685355\n",
      "Epoch 4/25, Batch 108/119, Loss: 5.212298398772902\n",
      "Epoch 4/25, Batch 109/119, Loss: 6.4137953735021345\n",
      "Epoch 4/25, Batch 110/119, Loss: 4.563036417843153\n",
      "Epoch 4/25, Batch 111/119, Loss: 6.453283934640629\n",
      "Epoch 4/25, Batch 112/119, Loss: 5.6590065723153495\n",
      "Epoch 4/25, Batch 113/119, Loss: 5.0373726960413805\n",
      "Epoch 4/25, Batch 114/119, Loss: 5.881410614938297\n",
      "Epoch 4/25, Batch 115/119, Loss: 3.6885456550425357\n",
      "Epoch 4/25, Batch 116/119, Loss: 5.3835231987284855\n",
      "Epoch 4/25, Batch 117/119, Loss: 7.578331500564505\n",
      "Epoch 4/25, Batch 118/119, Loss: 6.284841630397617\n",
      "Epoch 4/25, Batch 119/119, Loss: 4.017487960895208\n",
      "Epoch 4/25, Batch 120/119, Loss: 5.353796528038882\n",
      "Epoch 5/25, Batch 1/119, Loss: 6.296330632396203\n",
      "Epoch 5/25, Batch 2/119, Loss: 6.512493880833529\n",
      "Epoch 5/25, Batch 3/119, Loss: 7.028859881491275\n",
      "Epoch 5/25, Batch 4/119, Loss: 6.577016899220044\n",
      "Epoch 5/25, Batch 5/119, Loss: 6.31814017093141\n",
      "Epoch 5/25, Batch 6/119, Loss: 4.33915801172925\n",
      "Epoch 5/25, Batch 7/119, Loss: 6.062628840359954\n",
      "Epoch 5/25, Batch 8/119, Loss: 7.034655456815322\n",
      "Epoch 5/25, Batch 9/119, Loss: 5.740871395437527\n",
      "Epoch 5/25, Batch 10/119, Loss: 6.777325516109671\n",
      "Epoch 5/25, Batch 11/119, Loss: 5.180305113994527\n",
      "Epoch 5/25, Batch 12/119, Loss: 6.162065868984867\n",
      "Epoch 5/25, Batch 13/119, Loss: 7.7436502837920855\n",
      "Epoch 5/25, Batch 14/119, Loss: 5.212770834908904\n",
      "Epoch 5/25, Batch 15/119, Loss: 6.898202150194344\n",
      "Epoch 5/25, Batch 16/119, Loss: 4.886511814396694\n",
      "Epoch 5/25, Batch 17/119, Loss: 6.973710575457333\n",
      "Epoch 5/25, Batch 18/119, Loss: 7.021844886171173\n",
      "Epoch 5/25, Batch 19/119, Loss: 6.242745580588313\n",
      "Epoch 5/25, Batch 20/119, Loss: 7.0257771165124\n",
      "Epoch 5/25, Batch 21/119, Loss: 5.79175519553896\n",
      "Epoch 5/25, Batch 22/119, Loss: 5.933528443093087\n",
      "Epoch 5/25, Batch 23/119, Loss: 5.395315849557421\n",
      "Epoch 5/25, Batch 24/119, Loss: 7.659193452238557\n",
      "Epoch 5/25, Batch 25/119, Loss: 4.981936376241904\n",
      "Epoch 5/25, Batch 26/119, Loss: 6.204862782240454\n",
      "Epoch 5/25, Batch 27/119, Loss: 6.539655921428793\n",
      "Epoch 5/25, Batch 28/119, Loss: 7.105476744889999\n",
      "Epoch 5/25, Batch 29/119, Loss: 5.232697133816801\n",
      "Epoch 5/25, Batch 30/119, Loss: 3.868780283520321\n",
      "Epoch 5/25, Batch 31/119, Loss: 5.8008715073450725\n",
      "Epoch 5/25, Batch 32/119, Loss: 6.652165474742047\n",
      "Epoch 5/25, Batch 33/119, Loss: 6.997806918421268\n",
      "Epoch 5/25, Batch 34/119, Loss: 5.866386217138108\n",
      "Epoch 5/25, Batch 35/119, Loss: 4.430776594479573\n",
      "Epoch 5/25, Batch 36/119, Loss: 4.94014187895502\n",
      "Epoch 5/25, Batch 37/119, Loss: 6.669815058098597\n",
      "Epoch 5/25, Batch 38/119, Loss: 6.5910763903931\n",
      "Epoch 5/25, Batch 39/119, Loss: 4.804313203124364\n",
      "Epoch 5/25, Batch 40/119, Loss: 5.029613719571109\n",
      "Epoch 5/25, Batch 41/119, Loss: 6.371260952082662\n",
      "Epoch 5/25, Batch 42/119, Loss: 6.504224749342169\n",
      "Epoch 5/25, Batch 43/119, Loss: 5.268033645946478\n",
      "Epoch 5/25, Batch 44/119, Loss: 5.256120321876714\n",
      "Epoch 5/25, Batch 45/119, Loss: 6.605681075139487\n",
      "Epoch 5/25, Batch 46/119, Loss: 4.844362716699487\n",
      "Epoch 5/25, Batch 47/119, Loss: 9.504367088113103\n",
      "Epoch 5/25, Batch 48/119, Loss: 6.0342476052892975\n",
      "Epoch 5/25, Batch 49/119, Loss: 4.460105700430787\n",
      "Epoch 5/25, Batch 50/119, Loss: 4.281108435363083\n",
      "Epoch 5/25, Batch 51/119, Loss: 6.293915853210337\n",
      "Epoch 5/25, Batch 52/119, Loss: 6.768607690913188\n",
      "Epoch 5/25, Batch 53/119, Loss: 6.766583319036542\n",
      "Epoch 5/25, Batch 54/119, Loss: 4.8891175624659065\n",
      "Epoch 5/25, Batch 55/119, Loss: 5.68204163575801\n",
      "Epoch 5/25, Batch 56/119, Loss: 5.1883172504518535\n",
      "Epoch 5/25, Batch 57/119, Loss: 4.352228418317206\n",
      "Epoch 5/25, Batch 58/119, Loss: 5.486808353598817\n",
      "Epoch 5/25, Batch 59/119, Loss: 5.730738919346693\n",
      "Epoch 5/25, Batch 60/119, Loss: 5.721783426674445\n",
      "Epoch 5/25, Batch 61/119, Loss: 3.2244312149701537\n",
      "Epoch 5/25, Batch 62/119, Loss: 6.173241146781823\n",
      "Epoch 5/25, Batch 63/119, Loss: 6.986425652835372\n",
      "Epoch 5/25, Batch 64/119, Loss: 5.267577726871401\n",
      "Epoch 5/25, Batch 65/119, Loss: 6.828140509251539\n",
      "Epoch 5/25, Batch 66/119, Loss: 4.501434345005426\n",
      "Epoch 5/25, Batch 67/119, Loss: 5.695003190797725\n",
      "Epoch 5/25, Batch 68/119, Loss: 4.968142109785515\n",
      "Epoch 5/25, Batch 69/119, Loss: 6.2038821916975\n",
      "Epoch 5/25, Batch 70/119, Loss: 4.698379634304118\n",
      "Epoch 5/25, Batch 71/119, Loss: 3.942003513513033\n",
      "Epoch 5/25, Batch 72/119, Loss: 5.757156316596496\n",
      "Epoch 5/25, Batch 73/119, Loss: 5.107615867822964\n",
      "Epoch 5/25, Batch 74/119, Loss: 5.4195274225842365\n",
      "Epoch 5/25, Batch 75/119, Loss: 5.333486145061654\n",
      "Epoch 5/25, Batch 76/119, Loss: 4.968162401999673\n",
      "Epoch 5/25, Batch 77/119, Loss: 3.7430617642082695\n",
      "Epoch 5/25, Batch 78/119, Loss: 6.852150517515951\n",
      "Epoch 5/25, Batch 79/119, Loss: 6.935988321771337\n",
      "Epoch 5/25, Batch 80/119, Loss: 7.335537555994733\n",
      "Epoch 5/25, Batch 81/119, Loss: 6.207593690282357\n",
      "Epoch 5/25, Batch 82/119, Loss: 7.773172457325708\n",
      "Epoch 5/25, Batch 83/119, Loss: 4.503324815825445\n",
      "Epoch 5/25, Batch 84/119, Loss: 5.856042093791739\n",
      "Epoch 5/25, Batch 85/119, Loss: 4.312296887381103\n",
      "Epoch 5/25, Batch 86/119, Loss: 4.661636513380849\n",
      "Epoch 5/25, Batch 87/119, Loss: 3.7702140294523496\n",
      "Epoch 5/25, Batch 88/119, Loss: 7.728021168137092\n",
      "Epoch 5/25, Batch 89/119, Loss: 8.258313139422539\n",
      "Epoch 5/25, Batch 90/119, Loss: 5.278580362457958\n",
      "Epoch 5/25, Batch 91/119, Loss: 4.704924557358033\n",
      "Epoch 5/25, Batch 92/119, Loss: 4.044041645637968\n",
      "Epoch 5/25, Batch 93/119, Loss: 6.982866555310674\n",
      "Epoch 5/25, Batch 94/119, Loss: 4.636404300834735\n",
      "Epoch 5/25, Batch 95/119, Loss: 7.319289556105701\n",
      "Epoch 5/25, Batch 96/119, Loss: 3.57808608959576\n",
      "Epoch 5/25, Batch 97/119, Loss: 6.509869316114154\n",
      "Epoch 5/25, Batch 98/119, Loss: 6.401814756323204\n",
      "Epoch 5/25, Batch 99/119, Loss: 6.319874649524644\n",
      "Epoch 5/25, Batch 100/119, Loss: 4.078888418976481\n",
      "Epoch 5/25, Batch 101/119, Loss: 5.05400411662087\n",
      "Epoch 5/25, Batch 102/119, Loss: 4.711352954967291\n",
      "Epoch 5/25, Batch 103/119, Loss: 6.86403516196409\n",
      "Epoch 5/25, Batch 104/119, Loss: 5.6893336099346925\n",
      "Epoch 5/25, Batch 105/119, Loss: 4.082904484835553\n",
      "Epoch 5/25, Batch 106/119, Loss: 5.150922272632965\n",
      "Epoch 5/25, Batch 107/119, Loss: 4.577332012692733\n",
      "Epoch 5/25, Batch 108/119, Loss: 6.941072751504644\n",
      "Epoch 5/25, Batch 109/119, Loss: 4.696691536448223\n",
      "Epoch 5/25, Batch 110/119, Loss: 5.233370461614317\n",
      "Epoch 5/25, Batch 111/119, Loss: 5.692311566257265\n",
      "Epoch 5/25, Batch 112/119, Loss: 6.024035211947365\n",
      "Epoch 5/25, Batch 113/119, Loss: 6.31996873528276\n",
      "Epoch 5/25, Batch 114/119, Loss: 6.604694810526804\n",
      "Epoch 5/25, Batch 115/119, Loss: 5.621086667297175\n",
      "Epoch 5/25, Batch 116/119, Loss: 5.760875691643687\n",
      "Epoch 5/25, Batch 117/119, Loss: 5.5280151413556595\n",
      "Epoch 5/25, Batch 118/119, Loss: 5.479661081305703\n",
      "Epoch 5/25, Batch 119/119, Loss: 5.758147849793714\n",
      "Epoch 5/25, Batch 120/119, Loss: 5.865955395542726\n",
      "Epoch 6/25, Batch 1/119, Loss: 5.4096582246733895\n",
      "Epoch 6/25, Batch 2/119, Loss: 6.416813038514547\n",
      "Epoch 6/25, Batch 3/119, Loss: 5.446933843419096\n",
      "Epoch 6/25, Batch 4/119, Loss: 7.126031217937601\n",
      "Epoch 6/25, Batch 5/119, Loss: 8.667004971060722\n",
      "Epoch 6/25, Batch 6/119, Loss: 6.011109948225131\n",
      "Epoch 6/25, Batch 7/119, Loss: 5.050382271686828\n",
      "Epoch 6/25, Batch 8/119, Loss: 6.409024671834519\n",
      "Epoch 6/25, Batch 9/119, Loss: 4.403300200394312\n",
      "Epoch 6/25, Batch 10/119, Loss: 5.42539895251257\n",
      "Epoch 6/25, Batch 11/119, Loss: 7.6321993282558065\n",
      "Epoch 6/25, Batch 12/119, Loss: 3.225223717375766\n",
      "Epoch 6/25, Batch 13/119, Loss: 5.787125210262766\n",
      "Epoch 6/25, Batch 14/119, Loss: 6.085461961638177\n",
      "Epoch 6/25, Batch 15/119, Loss: 6.554199900155789\n",
      "Epoch 6/25, Batch 16/119, Loss: 5.597258538613673\n",
      "Epoch 6/25, Batch 17/119, Loss: 5.638745559112015\n",
      "Epoch 6/25, Batch 18/119, Loss: 7.2622217526749315\n",
      "Epoch 6/25, Batch 19/119, Loss: 7.027846776021622\n",
      "Epoch 6/25, Batch 20/119, Loss: 5.891855408383911\n",
      "Epoch 6/25, Batch 21/119, Loss: 4.943865725122369\n",
      "Epoch 6/25, Batch 22/119, Loss: 4.030749106224592\n",
      "Epoch 6/25, Batch 23/119, Loss: 5.1321987882338265\n",
      "Epoch 6/25, Batch 24/119, Loss: 6.313379085264391\n",
      "Epoch 6/25, Batch 25/119, Loss: 7.353333095947664\n",
      "Epoch 6/25, Batch 26/119, Loss: 4.884589257870789\n",
      "Epoch 6/25, Batch 27/119, Loss: 7.107023048378809\n",
      "Epoch 6/25, Batch 28/119, Loss: 6.823120396891347\n",
      "Epoch 6/25, Batch 29/119, Loss: 6.827695770446371\n",
      "Epoch 6/25, Batch 30/119, Loss: 6.034418097668225\n",
      "Epoch 6/25, Batch 31/119, Loss: 7.306937587353461\n",
      "Epoch 6/25, Batch 32/119, Loss: 6.062828496298642\n",
      "Epoch 6/25, Batch 33/119, Loss: 7.250980511454394\n",
      "Epoch 6/25, Batch 34/119, Loss: 7.8616684430109816\n",
      "Epoch 6/25, Batch 35/119, Loss: 4.7974355309720655\n",
      "Epoch 6/25, Batch 36/119, Loss: 6.524219706235461\n",
      "Epoch 6/25, Batch 37/119, Loss: 5.196751051249164\n",
      "Epoch 6/25, Batch 38/119, Loss: 3.6932789024499386\n",
      "Epoch 6/25, Batch 39/119, Loss: 4.188037194485317\n",
      "Epoch 6/25, Batch 40/119, Loss: 8.187397639235007\n",
      "Epoch 6/25, Batch 41/119, Loss: 6.690744696454306\n",
      "Epoch 6/25, Batch 42/119, Loss: 5.633048454513841\n",
      "Epoch 6/25, Batch 43/119, Loss: 4.527241533000985\n",
      "Epoch 6/25, Batch 44/119, Loss: 5.784711418425192\n",
      "Epoch 6/25, Batch 45/119, Loss: 7.327315626873252\n",
      "Epoch 6/25, Batch 46/119, Loss: 5.421030194031886\n",
      "Epoch 6/25, Batch 47/119, Loss: 3.5803517057856555\n",
      "Epoch 6/25, Batch 48/119, Loss: 6.522215710061175\n",
      "Epoch 6/25, Batch 49/119, Loss: 5.8138647316824486\n",
      "Epoch 6/25, Batch 50/119, Loss: 6.274849265999018\n",
      "Epoch 6/25, Batch 51/119, Loss: 4.048956446802829\n",
      "Epoch 6/25, Batch 52/119, Loss: 6.403294685074091\n",
      "Epoch 6/25, Batch 53/119, Loss: 7.522788445600639\n",
      "Epoch 6/25, Batch 54/119, Loss: 5.047054168743147\n",
      "Epoch 6/25, Batch 55/119, Loss: 6.339690436074782\n",
      "Epoch 6/25, Batch 56/119, Loss: 3.984493846683321\n",
      "Epoch 6/25, Batch 57/119, Loss: 7.786431600095846\n",
      "Epoch 6/25, Batch 58/119, Loss: 3.9153003176604795\n",
      "Epoch 6/25, Batch 59/119, Loss: 5.432860428111371\n",
      "Epoch 6/25, Batch 60/119, Loss: 6.111359474805003\n",
      "Epoch 6/25, Batch 61/119, Loss: 4.971824694371325\n",
      "Epoch 6/25, Batch 62/119, Loss: 6.354011892564257\n",
      "Epoch 6/25, Batch 63/119, Loss: 8.133142220704928\n",
      "Epoch 6/25, Batch 64/119, Loss: 4.15548637553375\n",
      "Epoch 6/25, Batch 65/119, Loss: 5.172830083317362\n",
      "Epoch 6/25, Batch 66/119, Loss: 6.335872806729791\n",
      "Epoch 6/25, Batch 67/119, Loss: 5.025973334147215\n",
      "Epoch 6/25, Batch 68/119, Loss: 6.995679920821135\n",
      "Epoch 6/25, Batch 69/119, Loss: 5.538854438757223\n",
      "Epoch 6/25, Batch 70/119, Loss: 6.923075443223669\n",
      "Epoch 6/25, Batch 71/119, Loss: 4.803309265699612\n",
      "Epoch 6/25, Batch 72/119, Loss: 3.216435276930763\n",
      "Epoch 6/25, Batch 73/119, Loss: 3.8799087584220526\n",
      "Epoch 6/25, Batch 74/119, Loss: 6.524478317549656\n",
      "Epoch 6/25, Batch 75/119, Loss: 4.427936625301377\n",
      "Epoch 6/25, Batch 76/119, Loss: 5.466667342156272\n",
      "Epoch 6/25, Batch 77/119, Loss: 7.9547601860232255\n",
      "Epoch 6/25, Batch 78/119, Loss: 6.6700806933145484\n",
      "Epoch 6/25, Batch 79/119, Loss: 5.024585697709535\n",
      "Epoch 6/25, Batch 80/119, Loss: 7.896093656376839\n",
      "Epoch 6/25, Batch 81/119, Loss: 8.359613290829456\n",
      "Epoch 6/25, Batch 82/119, Loss: 6.468928447131118\n",
      "Epoch 6/25, Batch 83/119, Loss: 4.8132791811671485\n",
      "Epoch 6/25, Batch 84/119, Loss: 5.951153894135278\n",
      "Epoch 6/25, Batch 85/119, Loss: 7.551262322165243\n",
      "Epoch 6/25, Batch 86/119, Loss: 4.3506420932242\n",
      "Epoch 6/25, Batch 87/119, Loss: 4.212039317381808\n",
      "Epoch 6/25, Batch 88/119, Loss: 4.8116875920882025\n",
      "Epoch 6/25, Batch 89/119, Loss: 5.262550277953757\n",
      "Epoch 6/25, Batch 90/119, Loss: 5.613952946864435\n",
      "Epoch 6/25, Batch 91/119, Loss: 5.128044166414815\n",
      "Epoch 6/25, Batch 92/119, Loss: 6.244871775326944\n",
      "Epoch 6/25, Batch 93/119, Loss: 7.640075368493605\n",
      "Epoch 6/25, Batch 94/119, Loss: 5.234860829487531\n",
      "Epoch 6/25, Batch 95/119, Loss: 5.953217791047541\n",
      "Epoch 6/25, Batch 96/119, Loss: 7.867140919745635\n",
      "Epoch 6/25, Batch 97/119, Loss: 4.993311687280761\n",
      "Epoch 6/25, Batch 98/119, Loss: 6.309683686938898\n",
      "Epoch 6/25, Batch 99/119, Loss: 6.141438825709507\n",
      "Epoch 6/25, Batch 100/119, Loss: 6.263547158814465\n",
      "Epoch 6/25, Batch 101/119, Loss: 5.637630971396468\n",
      "Epoch 6/25, Batch 102/119, Loss: 5.808491046602686\n",
      "Epoch 6/25, Batch 103/119, Loss: 6.513710368448839\n",
      "Epoch 6/25, Batch 104/119, Loss: 6.094301468329257\n",
      "Epoch 6/25, Batch 105/119, Loss: 6.182779934742639\n",
      "Epoch 6/25, Batch 106/119, Loss: 6.63109408207227\n",
      "Epoch 6/25, Batch 107/119, Loss: 5.429576927509435\n",
      "Epoch 6/25, Batch 108/119, Loss: 6.950738308541521\n",
      "Epoch 6/25, Batch 109/119, Loss: 5.765285688344984\n",
      "Epoch 6/25, Batch 110/119, Loss: 6.2675372163893615\n",
      "Epoch 6/25, Batch 111/119, Loss: 6.92751681653036\n",
      "Epoch 6/25, Batch 112/119, Loss: 7.855338490538687\n",
      "Epoch 6/25, Batch 113/119, Loss: 4.05436973423248\n",
      "Epoch 6/25, Batch 114/119, Loss: 5.237530298948688\n",
      "Epoch 6/25, Batch 115/119, Loss: 6.791738414202265\n",
      "Epoch 6/25, Batch 116/119, Loss: 7.555123878352174\n",
      "Epoch 6/25, Batch 117/119, Loss: 5.274556316781325\n",
      "Epoch 6/25, Batch 118/119, Loss: 8.133517127298948\n",
      "Epoch 6/25, Batch 119/119, Loss: 5.798943875724064\n",
      "Epoch 6/25, Batch 120/119, Loss: 4.399388547119913\n",
      "Epoch 7/25, Batch 1/119, Loss: 4.002582656664642\n",
      "Epoch 7/25, Batch 2/119, Loss: 6.093218122727713\n",
      "Epoch 7/25, Batch 3/119, Loss: 5.3712604016469285\n",
      "Epoch 7/25, Batch 4/119, Loss: 6.229520504183325\n",
      "Epoch 7/25, Batch 5/119, Loss: 3.873616270254963\n",
      "Epoch 7/25, Batch 6/119, Loss: 7.882449330870969\n",
      "Epoch 7/25, Batch 7/119, Loss: 8.112679531628514\n",
      "Epoch 7/25, Batch 8/119, Loss: 5.883578009891538\n",
      "Epoch 7/25, Batch 9/119, Loss: 4.617779101685382\n",
      "Epoch 7/25, Batch 10/119, Loss: 3.463957801655227\n",
      "Epoch 7/25, Batch 11/119, Loss: 5.432871933006271\n",
      "Epoch 7/25, Batch 12/119, Loss: 3.865572654117727\n",
      "Epoch 7/25, Batch 13/119, Loss: 5.498296741250907\n",
      "Epoch 7/25, Batch 14/119, Loss: 7.439957549590084\n",
      "Epoch 7/25, Batch 15/119, Loss: 4.259370330031122\n",
      "Epoch 7/25, Batch 16/119, Loss: 6.058787955448508\n",
      "Epoch 7/25, Batch 17/119, Loss: 5.258105965230656\n",
      "Epoch 7/25, Batch 18/119, Loss: 6.0740600421834205\n",
      "Epoch 7/25, Batch 19/119, Loss: 6.817552978115272\n",
      "Epoch 7/25, Batch 20/119, Loss: 5.622042197547739\n",
      "Epoch 7/25, Batch 21/119, Loss: 4.645382783239803\n",
      "Epoch 7/25, Batch 22/119, Loss: 5.821548806375929\n",
      "Epoch 7/25, Batch 23/119, Loss: 5.55782639744715\n",
      "Epoch 7/25, Batch 24/119, Loss: 6.232824526872428\n",
      "Epoch 7/25, Batch 25/119, Loss: 5.728064395190599\n",
      "Epoch 7/25, Batch 26/119, Loss: 5.05988749110691\n",
      "Epoch 7/25, Batch 27/119, Loss: 6.21223400017209\n",
      "Epoch 7/25, Batch 28/119, Loss: 4.179661686121831\n",
      "Epoch 7/25, Batch 29/119, Loss: 5.3316584629097745\n",
      "Epoch 7/25, Batch 30/119, Loss: 4.998046359508676\n",
      "Epoch 7/25, Batch 31/119, Loss: 8.46033794825367\n",
      "Epoch 7/25, Batch 32/119, Loss: 5.2787914530723485\n",
      "Epoch 7/25, Batch 33/119, Loss: 6.415271543826386\n",
      "Epoch 7/25, Batch 34/119, Loss: 5.778460850961045\n",
      "Epoch 7/25, Batch 35/119, Loss: 3.764842371223924\n",
      "Epoch 7/25, Batch 36/119, Loss: 4.716498791380241\n",
      "Epoch 7/25, Batch 37/119, Loss: 7.855615723965461\n",
      "Epoch 7/25, Batch 38/119, Loss: 6.9802259506901585\n",
      "Epoch 7/25, Batch 39/119, Loss: 4.3714253238589285\n",
      "Epoch 7/25, Batch 40/119, Loss: 4.713591948673097\n",
      "Epoch 7/25, Batch 41/119, Loss: 6.05572923739081\n",
      "Epoch 7/25, Batch 42/119, Loss: 5.286567612608408\n",
      "Epoch 7/25, Batch 43/119, Loss: 6.924779949326633\n",
      "Epoch 7/25, Batch 44/119, Loss: 3.709741163062959\n",
      "Epoch 7/25, Batch 45/119, Loss: 8.285951294408932\n",
      "Epoch 7/25, Batch 46/119, Loss: 4.097212816231541\n",
      "Epoch 7/25, Batch 47/119, Loss: 4.974313459453345\n",
      "Epoch 7/25, Batch 48/119, Loss: 4.8151849730350875\n",
      "Epoch 7/25, Batch 49/119, Loss: 5.7731548020270695\n",
      "Epoch 7/25, Batch 50/119, Loss: 8.328548438000457\n",
      "Epoch 7/25, Batch 51/119, Loss: 7.1197879375420845\n",
      "Epoch 7/25, Batch 52/119, Loss: 7.9813421560504025\n",
      "Epoch 7/25, Batch 53/119, Loss: 5.705748467022271\n",
      "Epoch 7/25, Batch 54/119, Loss: 6.136269175275613\n",
      "Epoch 7/25, Batch 55/119, Loss: 5.284776109530617\n",
      "Epoch 7/25, Batch 56/119, Loss: 5.603412227335777\n",
      "Epoch 7/25, Batch 57/119, Loss: 4.963645851442593\n",
      "Epoch 7/25, Batch 58/119, Loss: 5.888569995472678\n",
      "Epoch 7/25, Batch 59/119, Loss: 6.46085107401745\n",
      "Epoch 7/25, Batch 60/119, Loss: 6.041506442539775\n",
      "Epoch 7/25, Batch 61/119, Loss: 6.272769057959301\n",
      "Epoch 7/25, Batch 62/119, Loss: 8.821807707995195\n",
      "Epoch 7/25, Batch 63/119, Loss: 6.037370011136174\n",
      "Epoch 7/25, Batch 64/119, Loss: 8.655545815229438\n",
      "Epoch 7/25, Batch 65/119, Loss: 5.415089250997259\n",
      "Epoch 7/25, Batch 66/119, Loss: 3.397558292209407\n",
      "Epoch 7/25, Batch 67/119, Loss: 8.082553089650222\n",
      "Epoch 7/25, Batch 68/119, Loss: 4.10979659499593\n",
      "Epoch 7/25, Batch 69/119, Loss: 6.712105209949561\n",
      "Epoch 7/25, Batch 70/119, Loss: 5.676566084645376\n",
      "Epoch 7/25, Batch 71/119, Loss: 7.117963153074105\n",
      "Epoch 7/25, Batch 72/119, Loss: 4.7592189176035395\n",
      "Epoch 7/25, Batch 73/119, Loss: 7.457408281663709\n",
      "Epoch 7/25, Batch 74/119, Loss: 6.276454612759701\n",
      "Epoch 7/25, Batch 75/119, Loss: 4.831614677184671\n",
      "Epoch 7/25, Batch 76/119, Loss: 6.521057134755143\n",
      "Epoch 7/25, Batch 77/119, Loss: 4.95067349549485\n",
      "Epoch 7/25, Batch 78/119, Loss: 5.836648269778255\n",
      "Epoch 7/25, Batch 79/119, Loss: 6.40267422572148\n",
      "Epoch 7/25, Batch 80/119, Loss: 5.544013752230754\n",
      "Epoch 7/25, Batch 81/119, Loss: 4.6623317792367835\n",
      "Epoch 7/25, Batch 82/119, Loss: 4.374387378286669\n",
      "Epoch 7/25, Batch 83/119, Loss: 7.203914542344987\n",
      "Epoch 7/25, Batch 84/119, Loss: 5.929682348698522\n",
      "Epoch 7/25, Batch 85/119, Loss: 7.794600622512809\n",
      "Epoch 7/25, Batch 86/119, Loss: 6.646932425209045\n",
      "Epoch 7/25, Batch 87/119, Loss: 6.053149476587642\n",
      "Epoch 7/25, Batch 88/119, Loss: 5.782986565584992\n",
      "Epoch 7/25, Batch 89/119, Loss: 6.879582838939546\n",
      "Epoch 7/25, Batch 90/119, Loss: 4.097718159379594\n",
      "Epoch 7/25, Batch 91/119, Loss: 7.0912314303795005\n",
      "Epoch 7/25, Batch 92/119, Loss: 6.453606223263242\n",
      "Epoch 7/25, Batch 93/119, Loss: 7.215036164295125\n",
      "Epoch 7/25, Batch 94/119, Loss: 5.109396768845914\n",
      "Epoch 7/25, Batch 95/119, Loss: 6.1230235447195005\n",
      "Epoch 7/25, Batch 96/119, Loss: 7.4984323867559155\n",
      "Epoch 7/25, Batch 97/119, Loss: 6.515088848704704\n",
      "Epoch 7/25, Batch 98/119, Loss: 5.4494423127554334\n",
      "Epoch 7/25, Batch 99/119, Loss: 4.667495215924211\n",
      "Epoch 7/25, Batch 100/119, Loss: 6.746561430915414\n",
      "Epoch 7/25, Batch 101/119, Loss: 3.6278027358409286\n",
      "Epoch 7/25, Batch 102/119, Loss: 5.718691646586663\n",
      "Epoch 7/25, Batch 103/119, Loss: 5.627804916056963\n",
      "Epoch 7/25, Batch 104/119, Loss: 4.41286559732649\n",
      "Epoch 7/25, Batch 105/119, Loss: 4.950015558665828\n",
      "Epoch 7/25, Batch 106/119, Loss: 5.664409399342382\n",
      "Epoch 7/25, Batch 107/119, Loss: 7.209634143480026\n",
      "Epoch 7/25, Batch 108/119, Loss: 7.118380975475723\n",
      "Epoch 7/25, Batch 109/119, Loss: 6.248932420266705\n",
      "Epoch 7/25, Batch 110/119, Loss: 7.932009432001847\n",
      "Epoch 7/25, Batch 111/119, Loss: 5.465719325691458\n",
      "Epoch 7/25, Batch 112/119, Loss: 4.712986169908162\n",
      "Epoch 7/25, Batch 113/119, Loss: 6.9713398309282155\n",
      "Epoch 7/25, Batch 114/119, Loss: 7.157602686671488\n",
      "Epoch 7/25, Batch 115/119, Loss: 5.723327336319524\n",
      "Epoch 7/25, Batch 116/119, Loss: 5.886552702562856\n",
      "Epoch 7/25, Batch 117/119, Loss: 7.499308828094111\n",
      "Epoch 7/25, Batch 118/119, Loss: 5.8153994143636485\n",
      "Epoch 7/25, Batch 119/119, Loss: 5.9218284797203555\n",
      "Epoch 7/25, Batch 120/119, Loss: 5.416526571705004\n",
      "Epoch 8/25, Batch 1/119, Loss: 6.24452529697861\n",
      "Epoch 8/25, Batch 2/119, Loss: 6.764889528467759\n",
      "Epoch 8/25, Batch 3/119, Loss: 6.051161605652827\n",
      "Epoch 8/25, Batch 4/119, Loss: 7.502111646129959\n",
      "Epoch 8/25, Batch 5/119, Loss: 5.416940115510932\n",
      "Epoch 8/25, Batch 6/119, Loss: 5.50906840475229\n",
      "Epoch 8/25, Batch 7/119, Loss: 4.842583395025971\n",
      "Epoch 8/25, Batch 8/119, Loss: 6.49110189410708\n",
      "Epoch 8/25, Batch 9/119, Loss: 4.7178212927008465\n",
      "Epoch 8/25, Batch 10/119, Loss: 8.80441528958233\n",
      "Epoch 8/25, Batch 11/119, Loss: 4.976198005014128\n",
      "Epoch 8/25, Batch 12/119, Loss: 7.123401387231215\n",
      "Epoch 8/25, Batch 13/119, Loss: 6.985069563634565\n",
      "Epoch 8/25, Batch 14/119, Loss: 3.9839630283722656\n",
      "Epoch 8/25, Batch 15/119, Loss: 4.671713008196178\n",
      "Epoch 8/25, Batch 16/119, Loss: 7.645584662881767\n",
      "Epoch 8/25, Batch 17/119, Loss: 6.568324022927628\n",
      "Epoch 8/25, Batch 18/119, Loss: 6.539879734369127\n",
      "Epoch 8/25, Batch 19/119, Loss: 7.3670079765144205\n",
      "Epoch 8/25, Batch 20/119, Loss: 7.686573935238002\n",
      "Epoch 8/25, Batch 21/119, Loss: 6.061707933410339\n",
      "Epoch 8/25, Batch 22/119, Loss: 7.397739292691466\n",
      "Epoch 8/25, Batch 23/119, Loss: 7.70061972441598\n",
      "Epoch 8/25, Batch 24/119, Loss: 5.190598011596606\n",
      "Epoch 8/25, Batch 25/119, Loss: 5.251344868389283\n",
      "Epoch 8/25, Batch 26/119, Loss: 7.328578486615515\n",
      "Epoch 8/25, Batch 27/119, Loss: 4.846926904796691\n",
      "Epoch 8/25, Batch 28/119, Loss: 6.770529947439067\n",
      "Epoch 8/25, Batch 29/119, Loss: 7.400111935172902\n",
      "Epoch 8/25, Batch 30/119, Loss: 5.7826342319511435\n",
      "Epoch 8/25, Batch 31/119, Loss: 5.883013922428678\n",
      "Epoch 8/25, Batch 32/119, Loss: 7.501112791782142\n",
      "Epoch 8/25, Batch 33/119, Loss: 5.209236289805189\n",
      "Epoch 8/25, Batch 34/119, Loss: 7.355240747279499\n",
      "Epoch 8/25, Batch 35/119, Loss: 6.589928096326933\n",
      "Epoch 8/25, Batch 36/119, Loss: 5.570426227234869\n",
      "Epoch 8/25, Batch 37/119, Loss: 8.636484439585436\n",
      "Epoch 8/25, Batch 38/119, Loss: 4.765243187918136\n",
      "Epoch 8/25, Batch 39/119, Loss: 6.870680732868732\n",
      "Epoch 8/25, Batch 40/119, Loss: 5.8071916199323255\n",
      "Epoch 8/25, Batch 41/119, Loss: 8.738728092997038\n",
      "Epoch 8/25, Batch 42/119, Loss: 4.0421134465905935\n",
      "Epoch 8/25, Batch 43/119, Loss: 3.90093832813505\n",
      "Epoch 8/25, Batch 44/119, Loss: 7.1555050308728125\n",
      "Epoch 8/25, Batch 45/119, Loss: 8.050957357875012\n",
      "Epoch 8/25, Batch 46/119, Loss: 3.596709399058814\n",
      "Epoch 8/25, Batch 47/119, Loss: 8.421657806361186\n",
      "Epoch 8/25, Batch 48/119, Loss: 6.022494613404497\n",
      "Epoch 8/25, Batch 49/119, Loss: 7.644505274057045\n",
      "Epoch 8/25, Batch 50/119, Loss: 5.33507435860322\n",
      "Epoch 8/25, Batch 51/119, Loss: 4.438175946507132\n",
      "Epoch 8/25, Batch 52/119, Loss: 4.530373982307283\n",
      "Epoch 8/25, Batch 53/119, Loss: 6.412985527530969\n",
      "Epoch 8/25, Batch 54/119, Loss: 6.379623381486215\n",
      "Epoch 8/25, Batch 55/119, Loss: 5.3431067516937425\n",
      "Epoch 8/25, Batch 56/119, Loss: 7.710034366746351\n",
      "Epoch 8/25, Batch 57/119, Loss: 5.169071563695236\n",
      "Epoch 8/25, Batch 58/119, Loss: 5.422958793185627\n",
      "Epoch 8/25, Batch 59/119, Loss: 7.614955324194044\n",
      "Epoch 8/25, Batch 60/119, Loss: 4.886312483617658\n",
      "Epoch 8/25, Batch 61/119, Loss: 6.578369049059009\n",
      "Epoch 8/25, Batch 62/119, Loss: 5.0752991445903755\n",
      "Epoch 8/25, Batch 63/119, Loss: 7.525902201317174\n",
      "Epoch 8/25, Batch 64/119, Loss: 5.698648782180891\n",
      "Epoch 8/25, Batch 65/119, Loss: 7.199046284275518\n",
      "Epoch 8/25, Batch 66/119, Loss: 6.018733160128457\n",
      "Epoch 8/25, Batch 67/119, Loss: 3.8258619638406417\n",
      "Epoch 8/25, Batch 68/119, Loss: 6.041352756177035\n",
      "Epoch 8/25, Batch 69/119, Loss: 6.906660449821653\n",
      "Epoch 8/25, Batch 70/119, Loss: 6.390357959799852\n",
      "Epoch 8/25, Batch 71/119, Loss: 7.849491928582859\n",
      "Epoch 8/25, Batch 72/119, Loss: 7.496613752918287\n",
      "Epoch 8/25, Batch 73/119, Loss: 6.592537412614358\n",
      "Epoch 8/25, Batch 74/119, Loss: 3.6488496874236653\n",
      "Epoch 8/25, Batch 75/119, Loss: 6.084272909515695\n",
      "Epoch 8/25, Batch 76/119, Loss: 5.4759336233049405\n",
      "Epoch 8/25, Batch 77/119, Loss: 3.6064559321714493\n",
      "Epoch 8/25, Batch 78/119, Loss: 6.361016295256656\n",
      "Epoch 8/25, Batch 79/119, Loss: 4.1408895314433645\n",
      "Epoch 8/25, Batch 80/119, Loss: 6.034636446015166\n",
      "Epoch 8/25, Batch 81/119, Loss: 5.77358693351149\n",
      "Epoch 8/25, Batch 82/119, Loss: 6.140218394523576\n",
      "Epoch 8/25, Batch 83/119, Loss: 5.150321999949422\n",
      "Epoch 8/25, Batch 84/119, Loss: 6.142763244448574\n",
      "Epoch 8/25, Batch 85/119, Loss: 7.635699985485052\n",
      "Epoch 8/25, Batch 86/119, Loss: 4.783151400860887\n",
      "Epoch 8/25, Batch 87/119, Loss: 7.006126122355386\n",
      "Epoch 8/25, Batch 88/119, Loss: 6.129751789299715\n",
      "Epoch 8/25, Batch 89/119, Loss: 7.336821532314822\n",
      "Epoch 8/25, Batch 90/119, Loss: 5.829242655238311\n",
      "Epoch 8/25, Batch 91/119, Loss: 6.183396840993487\n",
      "Epoch 8/25, Batch 92/119, Loss: 6.942912971835251\n",
      "Epoch 8/25, Batch 93/119, Loss: 8.116962002701754\n",
      "Epoch 8/25, Batch 94/119, Loss: 8.419323953580003\n",
      "Epoch 8/25, Batch 95/119, Loss: 4.371963741454267\n",
      "Epoch 8/25, Batch 96/119, Loss: 8.054976949158787\n",
      "Epoch 8/25, Batch 97/119, Loss: 4.877555187905333\n",
      "Epoch 8/25, Batch 98/119, Loss: 9.32652444700214\n",
      "Epoch 8/25, Batch 99/119, Loss: 6.908132917329874\n",
      "Epoch 8/25, Batch 100/119, Loss: 6.037401910599\n",
      "Epoch 8/25, Batch 101/119, Loss: 6.264959094175224\n",
      "Epoch 8/25, Batch 102/119, Loss: 5.276890413390029\n",
      "Epoch 8/25, Batch 103/119, Loss: 6.252917020821118\n",
      "Epoch 8/25, Batch 104/119, Loss: 9.113666276575712\n",
      "Epoch 8/25, Batch 105/119, Loss: 3.7030488151287706\n",
      "Epoch 8/25, Batch 106/119, Loss: 5.39511352118233\n",
      "Epoch 8/25, Batch 107/119, Loss: 5.374282559008655\n",
      "Epoch 8/25, Batch 108/119, Loss: 6.556659153221135\n",
      "Epoch 8/25, Batch 109/119, Loss: 8.726168806615876\n",
      "Epoch 8/25, Batch 110/119, Loss: 6.6494045579345995\n",
      "Epoch 8/25, Batch 111/119, Loss: 6.094987883200555\n",
      "Epoch 8/25, Batch 112/119, Loss: 8.596335527559406\n",
      "Epoch 8/25, Batch 113/119, Loss: 7.114753021273605\n",
      "Epoch 8/25, Batch 114/119, Loss: 4.198335005869416\n",
      "Epoch 8/25, Batch 115/119, Loss: 6.901689290820236\n",
      "Epoch 8/25, Batch 116/119, Loss: 5.348346360734816\n",
      "Epoch 8/25, Batch 117/119, Loss: 5.255026507720628\n",
      "Epoch 8/25, Batch 118/119, Loss: 7.02872874417288\n",
      "Epoch 8/25, Batch 119/119, Loss: 7.605528706603441\n",
      "Epoch 8/25, Batch 120/119, Loss: 6.797905746738891\n",
      "Epoch 9/25, Batch 1/119, Loss: 4.597167502466913\n",
      "Epoch 9/25, Batch 2/119, Loss: 7.597741535329894\n",
      "Epoch 9/25, Batch 3/119, Loss: 7.384312844543127\n",
      "Epoch 9/25, Batch 4/119, Loss: 8.161217652356717\n",
      "Epoch 9/25, Batch 5/119, Loss: 7.652655225971853\n",
      "Epoch 9/25, Batch 6/119, Loss: 7.8572630806302275\n",
      "Epoch 9/25, Batch 7/119, Loss: 4.756407075417524\n",
      "Epoch 9/25, Batch 8/119, Loss: 5.523456624026303\n",
      "Epoch 9/25, Batch 9/119, Loss: 5.133345287032272\n",
      "Epoch 9/25, Batch 10/119, Loss: 8.871930311858277\n",
      "Epoch 9/25, Batch 11/119, Loss: 5.7423954178008705\n",
      "Epoch 9/25, Batch 12/119, Loss: 7.8770097938018395\n",
      "Epoch 9/25, Batch 13/119, Loss: 8.197191839358617\n",
      "Epoch 9/25, Batch 14/119, Loss: 7.471090161073348\n",
      "Epoch 9/25, Batch 15/119, Loss: 6.321331299930449\n",
      "Epoch 9/25, Batch 16/119, Loss: 6.667562921915223\n",
      "Epoch 9/25, Batch 17/119, Loss: 7.769928994787304\n",
      "Epoch 9/25, Batch 18/119, Loss: 6.439672304299889\n",
      "Epoch 9/25, Batch 19/119, Loss: 5.7741364350845545\n",
      "Epoch 9/25, Batch 20/119, Loss: 8.701421954680145\n",
      "Epoch 9/25, Batch 21/119, Loss: 8.709544192449986\n",
      "Epoch 9/25, Batch 22/119, Loss: 5.243276548046148\n",
      "Epoch 9/25, Batch 23/119, Loss: 6.021864057224636\n",
      "Epoch 9/25, Batch 24/119, Loss: 7.424796263778159\n",
      "Epoch 9/25, Batch 25/119, Loss: 5.051228546956209\n",
      "Epoch 9/25, Batch 26/119, Loss: 7.180863953026065\n",
      "Epoch 9/25, Batch 27/119, Loss: 8.129065401097973\n",
      "Epoch 9/25, Batch 28/119, Loss: 7.154726987241398\n",
      "Epoch 9/25, Batch 29/119, Loss: 5.120434566848035\n",
      "Epoch 9/25, Batch 30/119, Loss: 5.754038663395743\n",
      "Epoch 9/25, Batch 31/119, Loss: 6.693419240371756\n",
      "Epoch 9/25, Batch 32/119, Loss: 8.658561550376202\n",
      "Epoch 9/25, Batch 33/119, Loss: 4.434713358800728\n",
      "Epoch 9/25, Batch 34/119, Loss: 7.396288730457947\n",
      "Epoch 9/25, Batch 35/119, Loss: 4.504935388278436\n",
      "Epoch 9/25, Batch 36/119, Loss: 4.202455817013988\n",
      "Epoch 9/25, Batch 37/119, Loss: 8.430660750374534\n",
      "Epoch 9/25, Batch 38/119, Loss: 8.183010012612307\n",
      "Epoch 9/25, Batch 39/119, Loss: 3.7379930636635628\n",
      "Epoch 9/25, Batch 40/119, Loss: 4.122192024649774\n",
      "Epoch 9/25, Batch 41/119, Loss: 5.393542656239726\n",
      "Epoch 9/25, Batch 42/119, Loss: 5.171802101644143\n",
      "Epoch 9/25, Batch 43/119, Loss: 6.447265886565357\n",
      "Epoch 9/25, Batch 44/119, Loss: 6.746709682180982\n",
      "Epoch 9/25, Batch 45/119, Loss: 7.628696970420206\n",
      "Epoch 9/25, Batch 46/119, Loss: 3.921481541473225\n",
      "Epoch 9/25, Batch 47/119, Loss: 7.989375978619497\n",
      "Epoch 9/25, Batch 48/119, Loss: 8.64517204505523\n",
      "Epoch 9/25, Batch 49/119, Loss: 4.0922629200245755\n",
      "Epoch 9/25, Batch 50/119, Loss: 8.241987727786952\n",
      "Epoch 9/25, Batch 51/119, Loss: 3.380546670373195\n",
      "Epoch 9/25, Batch 52/119, Loss: 7.557403887837929\n",
      "Epoch 9/25, Batch 53/119, Loss: 9.08111166381821\n",
      "Epoch 9/25, Batch 54/119, Loss: 5.363563634051276\n",
      "Epoch 9/25, Batch 55/119, Loss: 7.047309813234299\n",
      "Epoch 9/25, Batch 56/119, Loss: 6.497608532859742\n",
      "Epoch 9/25, Batch 57/119, Loss: 6.992753544836029\n",
      "Epoch 9/25, Batch 58/119, Loss: 5.651702805587167\n",
      "Epoch 9/25, Batch 59/119, Loss: 5.234499865504309\n",
      "Epoch 9/25, Batch 60/119, Loss: 7.580434607449855\n",
      "Epoch 9/25, Batch 61/119, Loss: 5.7755957744479085\n",
      "Epoch 9/25, Batch 62/119, Loss: 3.487513378951645\n",
      "Epoch 9/25, Batch 63/119, Loss: 7.034863872966104\n",
      "Epoch 9/25, Batch 64/119, Loss: 4.774534985133414\n",
      "Epoch 9/25, Batch 65/119, Loss: 3.991402853085804\n",
      "Epoch 9/25, Batch 66/119, Loss: 6.2243147811723425\n",
      "Epoch 9/25, Batch 67/119, Loss: 7.087303464533338\n",
      "Epoch 9/25, Batch 68/119, Loss: 5.567927533901958\n",
      "Epoch 9/25, Batch 69/119, Loss: 5.171229366863104\n",
      "Epoch 9/25, Batch 70/119, Loss: 6.348676005746576\n",
      "Epoch 9/25, Batch 71/119, Loss: 7.797634642280011\n",
      "Epoch 9/25, Batch 72/119, Loss: 8.634908080469767\n",
      "Epoch 9/25, Batch 73/119, Loss: 3.4459684909637827\n",
      "Epoch 9/25, Batch 74/119, Loss: 4.7416955995893115\n",
      "Epoch 9/25, Batch 75/119, Loss: 7.771779251379828\n",
      "Epoch 9/25, Batch 76/119, Loss: 7.324038914063062\n",
      "Epoch 9/25, Batch 77/119, Loss: 6.366907218162902\n",
      "Epoch 9/25, Batch 78/119, Loss: 4.764927158820037\n",
      "Epoch 9/25, Batch 79/119, Loss: 4.443188647459548\n",
      "Epoch 9/25, Batch 80/119, Loss: 7.594081879790187\n",
      "Epoch 9/25, Batch 81/119, Loss: 6.981905647449659\n",
      "Epoch 9/25, Batch 82/119, Loss: 7.2846620688560355\n",
      "Epoch 9/25, Batch 83/119, Loss: 5.585310076991888\n",
      "Epoch 9/25, Batch 84/119, Loss: 6.61774267999541\n",
      "Epoch 9/25, Batch 85/119, Loss: 4.4873020604550184\n",
      "Epoch 9/25, Batch 86/119, Loss: 4.858338941272845\n",
      "Epoch 9/25, Batch 87/119, Loss: 6.8767596444807\n",
      "Epoch 9/25, Batch 88/119, Loss: 6.243766177503035\n",
      "Epoch 9/25, Batch 89/119, Loss: 6.197788108055334\n",
      "Epoch 9/25, Batch 90/119, Loss: 8.495624701508094\n",
      "Epoch 9/25, Batch 91/119, Loss: 5.969076336418545\n",
      "Epoch 9/25, Batch 92/119, Loss: 4.997745683265373\n",
      "Epoch 9/25, Batch 93/119, Loss: 6.717553066546464\n",
      "Epoch 9/25, Batch 94/119, Loss: 8.077217963080194\n",
      "Epoch 9/25, Batch 95/119, Loss: 5.240009725580453\n",
      "Epoch 9/25, Batch 96/119, Loss: 7.472251522646768\n",
      "Epoch 9/25, Batch 97/119, Loss: 6.7686429593151\n",
      "Epoch 9/25, Batch 98/119, Loss: 5.137287132389513\n",
      "Epoch 9/25, Batch 99/119, Loss: 7.932092811398212\n",
      "Epoch 9/25, Batch 100/119, Loss: 4.433132024822888\n",
      "Epoch 9/25, Batch 101/119, Loss: 7.448063806945804\n",
      "Epoch 9/25, Batch 102/119, Loss: 4.57949092037979\n",
      "Epoch 9/25, Batch 103/119, Loss: 7.821615625715019\n",
      "Epoch 9/25, Batch 104/119, Loss: 6.049401691387562\n",
      "Epoch 9/25, Batch 105/119, Loss: 5.428532856085909\n",
      "Epoch 9/25, Batch 106/119, Loss: 5.6255719067022\n",
      "Epoch 9/25, Batch 107/119, Loss: 6.738246945817204\n",
      "Epoch 9/25, Batch 108/119, Loss: 6.6071037032263655\n",
      "Epoch 9/25, Batch 109/119, Loss: 6.642959730216798\n",
      "Epoch 9/25, Batch 110/119, Loss: 5.154888940974561\n",
      "Epoch 9/25, Batch 111/119, Loss: 5.124967579704885\n",
      "Epoch 9/25, Batch 112/119, Loss: 7.605933759100078\n",
      "Epoch 9/25, Batch 113/119, Loss: 7.720067886459583\n",
      "Epoch 9/25, Batch 114/119, Loss: 6.142526842303534\n",
      "Epoch 9/25, Batch 115/119, Loss: 3.9482994927243458\n",
      "Epoch 9/25, Batch 116/119, Loss: 5.58457429311635\n",
      "Epoch 9/25, Batch 117/119, Loss: 6.58340219786588\n",
      "Epoch 9/25, Batch 118/119, Loss: 9.157007204659068\n",
      "Epoch 9/25, Batch 119/119, Loss: 7.089758199965912\n",
      "Epoch 9/25, Batch 120/119, Loss: 7.238826068312182\n",
      "Epoch 10/25, Batch 1/119, Loss: 5.563096481317184\n",
      "Epoch 10/25, Batch 2/119, Loss: 7.0785137599072305\n",
      "Epoch 10/25, Batch 3/119, Loss: 6.478273190144205\n",
      "Epoch 10/25, Batch 4/119, Loss: 6.878621207470273\n",
      "Epoch 10/25, Batch 5/119, Loss: 8.089993673119842\n",
      "Epoch 10/25, Batch 6/119, Loss: 7.92678387949171\n",
      "Epoch 10/25, Batch 7/119, Loss: 7.218800004279894\n",
      "Epoch 10/25, Batch 8/119, Loss: 5.445831156235096\n",
      "Epoch 10/25, Batch 9/119, Loss: 6.907747211997031\n",
      "Epoch 10/25, Batch 10/119, Loss: 6.376951737254245\n",
      "Epoch 10/25, Batch 11/119, Loss: 8.23013825880029\n",
      "Epoch 10/25, Batch 12/119, Loss: 6.1226338260810556\n",
      "Epoch 10/25, Batch 13/119, Loss: 5.759517819267182\n",
      "Epoch 10/25, Batch 14/119, Loss: 7.518812894174607\n",
      "Epoch 10/25, Batch 15/119, Loss: 6.819637793008068\n",
      "Epoch 10/25, Batch 16/119, Loss: 4.627518919421483\n",
      "Epoch 10/25, Batch 17/119, Loss: 5.635093250237981\n",
      "Epoch 10/25, Batch 18/119, Loss: 6.680578308509707\n",
      "Epoch 10/25, Batch 19/119, Loss: 5.189111360490981\n",
      "Epoch 10/25, Batch 20/119, Loss: 5.356819565750829\n",
      "Epoch 10/25, Batch 21/119, Loss: 9.009707755307106\n",
      "Epoch 10/25, Batch 22/119, Loss: 8.86976214620287\n",
      "Epoch 10/25, Batch 23/119, Loss: 5.16221994068093\n",
      "Epoch 10/25, Batch 24/119, Loss: 5.895294504912176\n",
      "Epoch 10/25, Batch 25/119, Loss: 4.542652604226274\n",
      "Epoch 10/25, Batch 26/119, Loss: 6.111542302317943\n",
      "Epoch 10/25, Batch 27/119, Loss: 6.420430446509221\n",
      "Epoch 10/25, Batch 28/119, Loss: 5.569210795551748\n",
      "Epoch 10/25, Batch 29/119, Loss: 7.861656444166407\n",
      "Epoch 10/25, Batch 30/119, Loss: 9.165486443320003\n",
      "Epoch 10/25, Batch 31/119, Loss: 6.619104510059584\n",
      "Epoch 10/25, Batch 32/119, Loss: 6.6460395224659194\n",
      "Epoch 10/25, Batch 33/119, Loss: 7.429868436853289\n",
      "Epoch 10/25, Batch 34/119, Loss: 5.51026473711298\n",
      "Epoch 10/25, Batch 35/119, Loss: 8.627351573795046\n",
      "Epoch 10/25, Batch 36/119, Loss: 7.507788837809789\n",
      "Epoch 10/25, Batch 37/119, Loss: 5.918248022719307\n",
      "Epoch 10/25, Batch 38/119, Loss: 7.724055941935643\n",
      "Epoch 10/25, Batch 39/119, Loss: 6.785130373944241\n",
      "Epoch 10/25, Batch 40/119, Loss: 7.379889766389573\n",
      "Epoch 10/25, Batch 41/119, Loss: 9.087287384994434\n",
      "Epoch 10/25, Batch 42/119, Loss: 3.69683845071128\n",
      "Epoch 10/25, Batch 43/119, Loss: 7.72006266407808\n",
      "Epoch 10/25, Batch 44/119, Loss: 7.500517611747066\n",
      "Epoch 10/25, Batch 45/119, Loss: 6.00790569593951\n",
      "Epoch 10/25, Batch 46/119, Loss: 3.58797318365334\n",
      "Epoch 10/25, Batch 47/119, Loss: 3.783291011225373\n",
      "Epoch 10/25, Batch 48/119, Loss: 5.896703768408769\n",
      "Epoch 10/25, Batch 49/119, Loss: 6.354654618240521\n",
      "Epoch 10/25, Batch 50/119, Loss: 6.350269010383036\n",
      "Epoch 10/25, Batch 51/119, Loss: 8.267066005286619\n",
      "Epoch 10/25, Batch 52/119, Loss: 5.6595239659153105\n",
      "Epoch 10/25, Batch 53/119, Loss: 5.250414652319097\n",
      "Epoch 10/25, Batch 54/119, Loss: 8.550969377167487\n",
      "Epoch 10/25, Batch 55/119, Loss: 5.7810590356492915\n",
      "Epoch 10/25, Batch 56/119, Loss: 8.547521440664303\n",
      "Epoch 10/25, Batch 57/119, Loss: 6.484883746950866\n",
      "Epoch 10/25, Batch 58/119, Loss: 6.752744291848623\n",
      "Epoch 10/25, Batch 59/119, Loss: 9.495371420695024\n",
      "Epoch 10/25, Batch 60/119, Loss: 6.121669693303649\n",
      "Epoch 10/25, Batch 61/119, Loss: 6.167345845077145\n",
      "Epoch 10/25, Batch 62/119, Loss: 5.679532769137077\n",
      "Epoch 10/25, Batch 63/119, Loss: 7.161102510603822\n",
      "Epoch 10/25, Batch 64/119, Loss: 7.348869027262082\n",
      "Epoch 10/25, Batch 65/119, Loss: 5.352970945149224\n",
      "Epoch 10/25, Batch 66/119, Loss: 7.845971822483362\n",
      "Epoch 10/25, Batch 67/119, Loss: 4.6702989019099315\n",
      "Epoch 10/25, Batch 68/119, Loss: 5.711347794374325\n",
      "Epoch 10/25, Batch 69/119, Loss: 7.520590361906595\n",
      "Epoch 10/25, Batch 70/119, Loss: 5.762555131764507\n",
      "Epoch 10/25, Batch 71/119, Loss: 6.733785720466592\n",
      "Epoch 10/25, Batch 72/119, Loss: 7.074117483709282\n",
      "Epoch 10/25, Batch 73/119, Loss: 3.328222465276083\n",
      "Epoch 10/25, Batch 74/119, Loss: 5.08786828675301\n",
      "Epoch 10/25, Batch 75/119, Loss: 5.53646094177096\n",
      "Epoch 10/25, Batch 76/119, Loss: 5.070555982029666\n",
      "Epoch 10/25, Batch 77/119, Loss: 8.485328856985808\n",
      "Epoch 10/25, Batch 78/119, Loss: 7.133934587574883\n",
      "Epoch 10/25, Batch 79/119, Loss: 7.521694767098693\n",
      "Epoch 10/25, Batch 80/119, Loss: 7.5974198702900155\n",
      "Epoch 10/25, Batch 81/119, Loss: 7.2524654523991945\n",
      "Epoch 10/25, Batch 82/119, Loss: 4.048831177628772\n",
      "Epoch 10/25, Batch 83/119, Loss: 6.600225663877913\n",
      "Epoch 10/25, Batch 84/119, Loss: 9.513317738448281\n",
      "Epoch 10/25, Batch 85/119, Loss: 6.973710121848101\n",
      "Epoch 10/25, Batch 86/119, Loss: 6.425098832440269\n",
      "Epoch 10/25, Batch 87/119, Loss: 5.3957312676981335\n",
      "Epoch 10/25, Batch 88/119, Loss: 6.772283133517349\n",
      "Epoch 10/25, Batch 89/119, Loss: 6.986277670030805\n",
      "Epoch 10/25, Batch 90/119, Loss: 5.711648978816614\n",
      "Epoch 10/25, Batch 91/119, Loss: 8.689577084836042\n",
      "Epoch 10/25, Batch 92/119, Loss: 4.417431359571411\n",
      "Epoch 10/25, Batch 93/119, Loss: 5.922436456335554\n",
      "Epoch 10/25, Batch 94/119, Loss: 5.440627355276228\n",
      "Epoch 10/25, Batch 95/119, Loss: 5.633452258427069\n",
      "Epoch 10/25, Batch 96/119, Loss: 6.072440048811214\n",
      "Epoch 10/25, Batch 97/119, Loss: 7.831288151618564\n",
      "Epoch 10/25, Batch 98/119, Loss: 8.419067084561537\n",
      "Epoch 10/25, Batch 99/119, Loss: 6.808518062985312\n",
      "Epoch 10/25, Batch 100/119, Loss: 8.22866292088242\n",
      "Epoch 10/25, Batch 101/119, Loss: 9.08513262766445\n",
      "Epoch 10/25, Batch 102/119, Loss: 6.082129667980731\n",
      "Epoch 10/25, Batch 103/119, Loss: 6.564608960034405\n",
      "Epoch 10/25, Batch 104/119, Loss: 5.2462344055536745\n",
      "Epoch 10/25, Batch 105/119, Loss: 5.084192023864156\n",
      "Epoch 10/25, Batch 106/119, Loss: 6.077365097994679\n",
      "Epoch 10/25, Batch 107/119, Loss: 7.843875220397388\n",
      "Epoch 10/25, Batch 108/119, Loss: 6.065782814024781\n",
      "Epoch 10/25, Batch 109/119, Loss: 5.632073995007254\n",
      "Epoch 10/25, Batch 110/119, Loss: 6.671727257930577\n",
      "Epoch 10/25, Batch 111/119, Loss: 5.91447611735294\n",
      "Epoch 10/25, Batch 112/119, Loss: 5.558246803861965\n",
      "Epoch 10/25, Batch 113/119, Loss: 10.286737211808894\n",
      "Epoch 10/25, Batch 114/119, Loss: 7.882939441454699\n",
      "Epoch 10/25, Batch 115/119, Loss: 6.228327783926661\n",
      "Epoch 10/25, Batch 116/119, Loss: 5.379543956283432\n",
      "Epoch 10/25, Batch 117/119, Loss: 7.529818901105263\n",
      "Epoch 10/25, Batch 118/119, Loss: 4.455415877816461\n",
      "Epoch 10/25, Batch 119/119, Loss: 9.03655916538183\n",
      "Epoch 10/25, Batch 120/119, Loss: 4.948026867010482\n",
      "Epoch 11/25, Batch 1/119, Loss: 8.006712951803857\n",
      "Epoch 11/25, Batch 2/119, Loss: 5.542652249889014\n",
      "Epoch 11/25, Batch 3/119, Loss: 5.531305424541121\n",
      "Epoch 11/25, Batch 4/119, Loss: 8.017376385582217\n",
      "Epoch 11/25, Batch 5/119, Loss: 8.939509184079494\n",
      "Epoch 11/25, Batch 6/119, Loss: 5.727387883803168\n",
      "Epoch 11/25, Batch 7/119, Loss: 4.310845913982897\n",
      "Epoch 11/25, Batch 8/119, Loss: 7.100727504301145\n",
      "Epoch 11/25, Batch 9/119, Loss: 7.667896443693635\n",
      "Epoch 11/25, Batch 10/119, Loss: 6.44014750201923\n",
      "Epoch 11/25, Batch 11/119, Loss: 7.7736908386503885\n",
      "Epoch 11/25, Batch 12/119, Loss: 5.222611165282444\n",
      "Epoch 11/25, Batch 13/119, Loss: 7.976630909932557\n",
      "Epoch 11/25, Batch 14/119, Loss: 5.776167702935853\n",
      "Epoch 11/25, Batch 15/119, Loss: 5.058715066204069\n",
      "Epoch 11/25, Batch 16/119, Loss: 5.214663908884316\n",
      "Epoch 11/25, Batch 17/119, Loss: 7.344139871578802\n",
      "Epoch 11/25, Batch 18/119, Loss: 10.178460381369604\n",
      "Epoch 11/25, Batch 19/119, Loss: 6.8859928083751605\n",
      "Epoch 11/25, Batch 20/119, Loss: 7.847550244642703\n",
      "Epoch 11/25, Batch 21/119, Loss: 6.6297948759719985\n",
      "Epoch 11/25, Batch 22/119, Loss: 5.578381575325862\n",
      "Epoch 11/25, Batch 23/119, Loss: 4.549061449129816\n",
      "Epoch 11/25, Batch 24/119, Loss: 8.568757523905143\n",
      "Epoch 11/25, Batch 25/119, Loss: 9.33259440050686\n",
      "Epoch 11/25, Batch 26/119, Loss: 5.547332045533894\n",
      "Epoch 11/25, Batch 27/119, Loss: 6.811091869475341\n",
      "Epoch 11/25, Batch 28/119, Loss: 9.132788234080508\n",
      "Epoch 11/25, Batch 29/119, Loss: 7.617969301801513\n",
      "Epoch 11/25, Batch 30/119, Loss: 4.2833326125877536\n",
      "Epoch 11/25, Batch 31/119, Loss: 9.298272611472207\n",
      "Epoch 11/25, Batch 32/119, Loss: 4.597899149129237\n",
      "Epoch 11/25, Batch 33/119, Loss: 4.398932955021567\n",
      "Epoch 11/25, Batch 34/119, Loss: 5.633856096169824\n",
      "Epoch 11/25, Batch 35/119, Loss: 7.836722189027263\n",
      "Epoch 11/25, Batch 36/119, Loss: 9.756062573153478\n",
      "Epoch 11/25, Batch 37/119, Loss: 7.488352499519025\n",
      "Epoch 11/25, Batch 38/119, Loss: 8.143391950532694\n",
      "Epoch 11/25, Batch 39/119, Loss: 6.125870895262056\n",
      "Epoch 11/25, Batch 40/119, Loss: 8.696995102024646\n",
      "Epoch 11/25, Batch 41/119, Loss: 5.2400490372852\n",
      "Epoch 11/25, Batch 42/119, Loss: 9.626412276495115\n",
      "Epoch 11/25, Batch 43/119, Loss: 6.438825329585725\n",
      "Epoch 11/25, Batch 44/119, Loss: 8.28889784746761\n",
      "Epoch 11/25, Batch 45/119, Loss: 6.398168945778178\n",
      "Epoch 11/25, Batch 46/119, Loss: 6.35515512808045\n",
      "Epoch 11/25, Batch 47/119, Loss: 6.211215834214323\n",
      "Epoch 11/25, Batch 48/119, Loss: 3.9260254062188507\n",
      "Epoch 11/25, Batch 49/119, Loss: 6.340408950932869\n",
      "Epoch 11/25, Batch 50/119, Loss: 7.998575464584921\n",
      "Epoch 11/25, Batch 51/119, Loss: 7.580405939648541\n",
      "Epoch 11/25, Batch 52/119, Loss: 7.538808194874864\n",
      "Epoch 11/25, Batch 53/119, Loss: 6.820698182008147\n",
      "Epoch 11/25, Batch 54/119, Loss: 6.975414366691004\n",
      "Epoch 11/25, Batch 55/119, Loss: 7.40800290877779\n",
      "Epoch 11/25, Batch 56/119, Loss: 8.814340964475441\n",
      "Epoch 11/25, Batch 57/119, Loss: 6.664601646748818\n",
      "Epoch 11/25, Batch 58/119, Loss: 9.343266897096086\n",
      "Epoch 11/25, Batch 59/119, Loss: 6.274650411950137\n",
      "Epoch 11/25, Batch 60/119, Loss: 6.730075773597392\n",
      "Epoch 11/25, Batch 61/119, Loss: 5.06510438327296\n",
      "Epoch 11/25, Batch 62/119, Loss: 8.978526421846999\n",
      "Epoch 11/25, Batch 63/119, Loss: 5.899878375904176\n",
      "Epoch 11/25, Batch 64/119, Loss: 5.508868220475873\n",
      "Epoch 11/25, Batch 65/119, Loss: 9.72334263599611\n",
      "Epoch 11/25, Batch 66/119, Loss: 3.9694369489337267\n",
      "Epoch 11/25, Batch 67/119, Loss: 9.019458426694449\n",
      "Epoch 11/25, Batch 68/119, Loss: 5.775154513500772\n",
      "Epoch 11/25, Batch 69/119, Loss: 4.534687778667867\n",
      "Epoch 11/25, Batch 70/119, Loss: 6.790693359748258\n",
      "Epoch 11/25, Batch 71/119, Loss: 6.3217230912771285\n",
      "Epoch 11/25, Batch 72/119, Loss: 6.434051315472656\n",
      "Epoch 11/25, Batch 73/119, Loss: 8.412027862351808\n",
      "Epoch 11/25, Batch 74/119, Loss: 6.407756282062572\n",
      "Epoch 11/25, Batch 75/119, Loss: 5.849222150307723\n",
      "Epoch 11/25, Batch 76/119, Loss: 7.3227423106548715\n",
      "Epoch 11/25, Batch 77/119, Loss: 5.54839196648919\n",
      "Epoch 11/25, Batch 78/119, Loss: 6.800103889019132\n",
      "Epoch 11/25, Batch 79/119, Loss: 4.926046838388061\n",
      "Epoch 11/25, Batch 80/119, Loss: 3.8758264956589095\n",
      "Epoch 11/25, Batch 81/119, Loss: 7.720697459134959\n",
      "Epoch 11/25, Batch 82/119, Loss: 7.687027593550937\n",
      "Epoch 11/25, Batch 83/119, Loss: 5.092752043436455\n",
      "Epoch 11/25, Batch 84/119, Loss: 7.964188913865986\n",
      "Epoch 11/25, Batch 85/119, Loss: 6.7241621711503585\n",
      "Epoch 11/25, Batch 86/119, Loss: 7.115444631243871\n",
      "Epoch 11/25, Batch 87/119, Loss: 7.727235762660368\n",
      "Epoch 11/25, Batch 88/119, Loss: 7.710307805499223\n",
      "Epoch 11/25, Batch 89/119, Loss: 7.472260675151482\n",
      "Epoch 11/25, Batch 90/119, Loss: 6.78697007833554\n",
      "Epoch 11/25, Batch 91/119, Loss: 8.881538029819165\n",
      "Epoch 11/25, Batch 92/119, Loss: 6.120868804536478\n",
      "Epoch 11/25, Batch 93/119, Loss: 6.440548550641693\n",
      "Epoch 11/25, Batch 94/119, Loss: 3.1226648275565982\n",
      "Epoch 11/25, Batch 95/119, Loss: 7.5070409847189765\n",
      "Epoch 11/25, Batch 96/119, Loss: 4.1465830642477\n",
      "Epoch 11/25, Batch 97/119, Loss: 7.453692714265864\n",
      "Epoch 11/25, Batch 98/119, Loss: 9.08159656809249\n",
      "Epoch 11/25, Batch 99/119, Loss: 7.697701260714528\n",
      "Epoch 11/25, Batch 100/119, Loss: 7.634596171628524\n",
      "Epoch 11/25, Batch 101/119, Loss: 4.357418967733844\n",
      "Epoch 11/25, Batch 102/119, Loss: 5.135103116068119\n",
      "Epoch 11/25, Batch 103/119, Loss: 7.539413773407157\n",
      "Epoch 11/25, Batch 104/119, Loss: 7.236614975203578\n",
      "Epoch 11/25, Batch 105/119, Loss: 8.289883516287299\n",
      "Epoch 11/25, Batch 106/119, Loss: 7.645526817876694\n",
      "Epoch 11/25, Batch 107/119, Loss: 6.628356237747711\n",
      "Epoch 11/25, Batch 108/119, Loss: 6.968034449090741\n",
      "Epoch 11/25, Batch 109/119, Loss: 7.9329838524904766\n",
      "Epoch 11/25, Batch 110/119, Loss: 7.443792658827519\n",
      "Epoch 11/25, Batch 111/119, Loss: 3.806888976903299\n",
      "Epoch 11/25, Batch 112/119, Loss: 7.652632171487326\n",
      "Epoch 11/25, Batch 113/119, Loss: 6.4288607347798585\n",
      "Epoch 11/25, Batch 114/119, Loss: 5.301758114761786\n",
      "Epoch 11/25, Batch 115/119, Loss: 6.668353433575995\n",
      "Epoch 11/25, Batch 116/119, Loss: 5.458233921728929\n",
      "Epoch 11/25, Batch 117/119, Loss: 5.440805822506379\n",
      "Epoch 11/25, Batch 118/119, Loss: 9.089496477169387\n",
      "Epoch 11/25, Batch 119/119, Loss: 5.590857636432409\n",
      "Epoch 11/25, Batch 120/119, Loss: 7.822955061446195\n",
      "Epoch 12/25, Batch 1/119, Loss: 7.260250621516868\n",
      "Epoch 12/25, Batch 2/119, Loss: 6.331854735508023\n",
      "Epoch 12/25, Batch 3/119, Loss: 5.334715752321407\n",
      "Epoch 12/25, Batch 4/119, Loss: 6.527139478765502\n",
      "Epoch 12/25, Batch 5/119, Loss: 6.286596832810795\n",
      "Epoch 12/25, Batch 6/119, Loss: 6.228393862710038\n",
      "Epoch 12/25, Batch 7/119, Loss: 6.922052508017068\n",
      "Epoch 12/25, Batch 8/119, Loss: 6.034601004610158\n",
      "Epoch 12/25, Batch 9/119, Loss: 7.4398364148838105\n",
      "Epoch 12/25, Batch 10/119, Loss: 5.396241065278425\n",
      "Epoch 12/25, Batch 11/119, Loss: 6.139574981389903\n",
      "Epoch 12/25, Batch 12/119, Loss: 7.57727459339576\n",
      "Epoch 12/25, Batch 13/119, Loss: 8.560461429112003\n",
      "Epoch 12/25, Batch 14/119, Loss: 8.940288981822055\n",
      "Epoch 12/25, Batch 15/119, Loss: 6.557914950311062\n",
      "Epoch 12/25, Batch 16/119, Loss: 6.2734206877634895\n",
      "Epoch 12/25, Batch 17/119, Loss: 4.456370985608483\n",
      "Epoch 12/25, Batch 18/119, Loss: 6.9846450461218\n",
      "Epoch 12/25, Batch 19/119, Loss: 6.672562676558498\n",
      "Epoch 12/25, Batch 20/119, Loss: 6.621327975156161\n",
      "Epoch 12/25, Batch 21/119, Loss: 5.598308706169492\n",
      "Epoch 12/25, Batch 22/119, Loss: 8.71210574479089\n",
      "Epoch 12/25, Batch 23/119, Loss: 8.352837773670538\n",
      "Epoch 12/25, Batch 24/119, Loss: 4.915560144504114\n",
      "Epoch 12/25, Batch 25/119, Loss: 3.8932744712299456\n",
      "Epoch 12/25, Batch 26/119, Loss: 6.205660961520036\n",
      "Epoch 12/25, Batch 27/119, Loss: 7.951061027827246\n",
      "Epoch 12/25, Batch 28/119, Loss: 7.682183091205994\n",
      "Epoch 12/25, Batch 29/119, Loss: 6.060836233102431\n",
      "Epoch 12/25, Batch 30/119, Loss: 6.890257900494144\n",
      "Epoch 12/25, Batch 31/119, Loss: 5.8484145816504505\n",
      "Epoch 12/25, Batch 32/119, Loss: 6.90495576092251\n",
      "Epoch 12/25, Batch 33/119, Loss: 6.934805283663266\n",
      "Epoch 12/25, Batch 34/119, Loss: 6.666891324124266\n",
      "Epoch 12/25, Batch 35/119, Loss: 6.245114469065076\n",
      "Epoch 12/25, Batch 36/119, Loss: 5.157795148692576\n",
      "Epoch 12/25, Batch 37/119, Loss: 5.946434392594435\n",
      "Epoch 12/25, Batch 38/119, Loss: 6.184949966243981\n",
      "Epoch 12/25, Batch 39/119, Loss: 9.019258307940687\n",
      "Epoch 12/25, Batch 40/119, Loss: 7.794587129971806\n",
      "Epoch 12/25, Batch 41/119, Loss: 4.374629170164406\n",
      "Epoch 12/25, Batch 42/119, Loss: 7.943977260587693\n",
      "Epoch 12/25, Batch 43/119, Loss: 6.671074448087032\n",
      "Epoch 12/25, Batch 44/119, Loss: 7.428188374756876\n",
      "Epoch 12/25, Batch 45/119, Loss: 5.577780059555448\n",
      "Epoch 12/25, Batch 46/119, Loss: 6.5409557274211005\n",
      "Epoch 12/25, Batch 47/119, Loss: 6.889722623248125\n",
      "Epoch 12/25, Batch 48/119, Loss: 8.190306277940763\n",
      "Epoch 12/25, Batch 49/119, Loss: 5.852105762554523\n",
      "Epoch 12/25, Batch 50/119, Loss: 5.413089015613944\n",
      "Epoch 12/25, Batch 51/119, Loss: 8.863125282853996\n",
      "Epoch 12/25, Batch 52/119, Loss: 5.542209221144655\n",
      "Epoch 12/25, Batch 53/119, Loss: 10.18178244290664\n",
      "Epoch 12/25, Batch 54/119, Loss: 5.541230575008529\n",
      "Epoch 12/25, Batch 55/119, Loss: 8.108476846335781\n",
      "Epoch 12/25, Batch 56/119, Loss: 5.973641955263997\n",
      "Epoch 12/25, Batch 57/119, Loss: 5.3021522138710155\n",
      "Epoch 12/25, Batch 58/119, Loss: 8.702134654652577\n",
      "Epoch 12/25, Batch 59/119, Loss: 9.104848536493776\n",
      "Epoch 12/25, Batch 60/119, Loss: 7.114786875141291\n",
      "Epoch 12/25, Batch 61/119, Loss: 5.033562131328989\n",
      "Epoch 12/25, Batch 62/119, Loss: 5.31085848851333\n",
      "Epoch 12/25, Batch 63/119, Loss: 4.028215506347993\n",
      "Epoch 12/25, Batch 64/119, Loss: 7.471995026408554\n",
      "Epoch 12/25, Batch 65/119, Loss: 4.76946169953815\n",
      "Epoch 12/25, Batch 66/119, Loss: 8.035780431513734\n",
      "Epoch 12/25, Batch 67/119, Loss: 7.983874534925363\n",
      "Epoch 12/25, Batch 68/119, Loss: 7.412812483507167\n",
      "Epoch 12/25, Batch 69/119, Loss: 8.009213667742726\n",
      "Epoch 12/25, Batch 70/119, Loss: 7.648711746125178\n",
      "Epoch 12/25, Batch 71/119, Loss: 6.126991596934245\n",
      "Epoch 12/25, Batch 72/119, Loss: 5.211717514859263\n",
      "Epoch 12/25, Batch 73/119, Loss: 8.618237171733046\n",
      "Epoch 12/25, Batch 74/119, Loss: 6.121838714430687\n",
      "Epoch 12/25, Batch 75/119, Loss: 7.6577399671334625\n",
      "Epoch 12/25, Batch 76/119, Loss: 5.343048946404931\n",
      "Epoch 12/25, Batch 77/119, Loss: 7.896160354637075\n",
      "Epoch 12/25, Batch 78/119, Loss: 6.9503104536737395\n",
      "Epoch 12/25, Batch 79/119, Loss: 7.855418139381438\n",
      "Epoch 12/25, Batch 80/119, Loss: 7.78565795690295\n",
      "Epoch 12/25, Batch 81/119, Loss: 6.490456561591633\n",
      "Epoch 12/25, Batch 82/119, Loss: 8.034731881990263\n",
      "Epoch 12/25, Batch 83/119, Loss: 6.483649941663421\n",
      "Epoch 12/25, Batch 84/119, Loss: 9.120511260373885\n",
      "Epoch 12/25, Batch 85/119, Loss: 7.781343675168308\n",
      "Epoch 12/25, Batch 86/119, Loss: 6.798462893123663\n",
      "Epoch 12/25, Batch 87/119, Loss: 7.000950803070861\n",
      "Epoch 12/25, Batch 88/119, Loss: 8.310661721429634\n",
      "Epoch 12/25, Batch 89/119, Loss: 6.82587959819493\n",
      "Epoch 12/25, Batch 90/119, Loss: 8.788422952056415\n",
      "Epoch 12/25, Batch 91/119, Loss: 8.456251203164332\n",
      "Epoch 12/25, Batch 92/119, Loss: 7.061351047563341\n",
      "Epoch 12/25, Batch 93/119, Loss: 5.392414324142498\n",
      "Epoch 12/25, Batch 94/119, Loss: 4.840207565447429\n",
      "Epoch 12/25, Batch 95/119, Loss: 7.17525974536439\n",
      "Epoch 12/25, Batch 96/119, Loss: 6.589115803135664\n",
      "Epoch 12/25, Batch 97/119, Loss: 5.94678201418536\n",
      "Epoch 12/25, Batch 98/119, Loss: 7.354971775673631\n",
      "Epoch 12/25, Batch 99/119, Loss: 3.7034898961572655\n",
      "Epoch 12/25, Batch 100/119, Loss: 4.884220132581764\n",
      "Epoch 12/25, Batch 101/119, Loss: 5.365946394525972\n",
      "Epoch 12/25, Batch 102/119, Loss: 5.805630934501449\n",
      "Epoch 12/25, Batch 103/119, Loss: 8.647210509284223\n",
      "Epoch 12/25, Batch 104/119, Loss: 6.073939867030219\n",
      "Epoch 12/25, Batch 105/119, Loss: 7.108913669419667\n",
      "Epoch 12/25, Batch 106/119, Loss: 9.648301310810373\n",
      "Epoch 12/25, Batch 107/119, Loss: 7.060074344359804\n",
      "Epoch 12/25, Batch 108/119, Loss: 3.9895452113072563\n",
      "Epoch 12/25, Batch 109/119, Loss: 9.45112051154839\n",
      "Epoch 12/25, Batch 110/119, Loss: 7.532724755808975\n",
      "Epoch 12/25, Batch 111/119, Loss: 6.026688034946827\n",
      "Epoch 12/25, Batch 112/119, Loss: 7.669325926456406\n",
      "Epoch 12/25, Batch 113/119, Loss: 7.511846508302668\n",
      "Epoch 12/25, Batch 114/119, Loss: 6.966012375400913\n",
      "Epoch 12/25, Batch 115/119, Loss: 5.634865885334875\n",
      "Epoch 12/25, Batch 116/119, Loss: 5.831433389448838\n",
      "Epoch 12/25, Batch 117/119, Loss: 6.16322094727127\n",
      "Epoch 12/25, Batch 118/119, Loss: 8.381542199261666\n",
      "Epoch 12/25, Batch 119/119, Loss: 6.976392873361462\n",
      "Epoch 12/25, Batch 120/119, Loss: 6.390950108291694\n",
      "Epoch 13/25, Batch 1/119, Loss: 5.581400810396344\n",
      "Epoch 13/25, Batch 2/119, Loss: 3.733372926418755\n",
      "Epoch 13/25, Batch 3/119, Loss: 7.639853094672626\n",
      "Epoch 13/25, Batch 4/119, Loss: 7.272782813603742\n",
      "Epoch 13/25, Batch 5/119, Loss: 7.706477736809686\n",
      "Epoch 13/25, Batch 6/119, Loss: 4.953805536571724\n",
      "Epoch 13/25, Batch 7/119, Loss: 8.31447081729832\n",
      "Epoch 13/25, Batch 8/119, Loss: 6.41761983508974\n",
      "Epoch 13/25, Batch 9/119, Loss: 8.244967883329386\n",
      "Epoch 13/25, Batch 10/119, Loss: 5.951078331576185\n",
      "Epoch 13/25, Batch 11/119, Loss: 5.674553932207555\n",
      "Epoch 13/25, Batch 12/119, Loss: 5.909220422654286\n",
      "Epoch 13/25, Batch 13/119, Loss: 6.086291895682079\n",
      "Epoch 13/25, Batch 14/119, Loss: 4.117502076432537\n",
      "Epoch 13/25, Batch 15/119, Loss: 6.119509728442259\n",
      "Epoch 13/25, Batch 16/119, Loss: 8.610552868928817\n",
      "Epoch 13/25, Batch 17/119, Loss: 8.046341669045551\n",
      "Epoch 13/25, Batch 18/119, Loss: 7.970376102433956\n",
      "Epoch 13/25, Batch 19/119, Loss: 7.705323860357315\n",
      "Epoch 13/25, Batch 20/119, Loss: 5.289530471684672\n",
      "Epoch 13/25, Batch 21/119, Loss: 8.079473283406358\n",
      "Epoch 13/25, Batch 22/119, Loss: 5.285785258465248\n",
      "Epoch 13/25, Batch 23/119, Loss: 8.37701434340395\n",
      "Epoch 13/25, Batch 24/119, Loss: 4.8517301860513715\n",
      "Epoch 13/25, Batch 25/119, Loss: 9.056503440805907\n",
      "Epoch 13/25, Batch 26/119, Loss: 7.386251352077354\n",
      "Epoch 13/25, Batch 27/119, Loss: 5.840763329625001\n",
      "Epoch 13/25, Batch 28/119, Loss: 7.476059917305847\n",
      "Epoch 13/25, Batch 29/119, Loss: 7.7784351490479064\n",
      "Epoch 13/25, Batch 30/119, Loss: 5.550857616595856\n",
      "Epoch 13/25, Batch 31/119, Loss: 5.012026427092988\n",
      "Epoch 13/25, Batch 32/119, Loss: 9.45071620128039\n",
      "Epoch 13/25, Batch 33/119, Loss: 8.171257211939832\n",
      "Epoch 13/25, Batch 34/119, Loss: 7.561753078924232\n",
      "Epoch 13/25, Batch 35/119, Loss: 4.4946799004695945\n",
      "Epoch 13/25, Batch 36/119, Loss: 7.239814219325844\n",
      "Epoch 13/25, Batch 37/119, Loss: 7.6897904825398795\n",
      "Epoch 13/25, Batch 38/119, Loss: 7.801858065082933\n",
      "Epoch 13/25, Batch 39/119, Loss: 6.850260070736245\n",
      "Epoch 13/25, Batch 40/119, Loss: 7.982777255862338\n",
      "Epoch 13/25, Batch 41/119, Loss: 7.24616905391696\n",
      "Epoch 13/25, Batch 42/119, Loss: 3.7251119461889632\n",
      "Epoch 13/25, Batch 43/119, Loss: 6.541898942308502\n",
      "Epoch 13/25, Batch 44/119, Loss: 7.899881870529596\n",
      "Epoch 13/25, Batch 45/119, Loss: 4.394004080219837\n",
      "Epoch 13/25, Batch 46/119, Loss: 5.51826482084708\n",
      "Epoch 13/25, Batch 47/119, Loss: 8.788330841498656\n",
      "Epoch 13/25, Batch 48/119, Loss: 6.439815080648704\n",
      "Epoch 13/25, Batch 49/119, Loss: 8.268680879417483\n",
      "Epoch 13/25, Batch 50/119, Loss: 8.625484118309327\n",
      "Epoch 13/25, Batch 51/119, Loss: 6.476054329973788\n",
      "Epoch 13/25, Batch 52/119, Loss: 5.921151530746666\n",
      "Epoch 13/25, Batch 53/119, Loss: 6.392620265665981\n",
      "Epoch 13/25, Batch 54/119, Loss: 6.5396939699128955\n",
      "Epoch 13/25, Batch 55/119, Loss: 5.9800257958507155\n",
      "Epoch 13/25, Batch 56/119, Loss: 6.153854743574592\n",
      "Epoch 13/25, Batch 57/119, Loss: 7.354567986406151\n",
      "Epoch 13/25, Batch 58/119, Loss: 6.445708199199755\n",
      "Epoch 13/25, Batch 59/119, Loss: 7.256716206773744\n",
      "Epoch 13/25, Batch 60/119, Loss: 5.643423944145263\n",
      "Epoch 13/25, Batch 61/119, Loss: 5.492429267376782\n",
      "Epoch 13/25, Batch 62/119, Loss: 5.504219561621437\n",
      "Epoch 13/25, Batch 63/119, Loss: 7.044801756776585\n",
      "Epoch 13/25, Batch 64/119, Loss: 10.10957382618895\n",
      "Epoch 13/25, Batch 65/119, Loss: 3.8320712560023993\n",
      "Epoch 13/25, Batch 66/119, Loss: 9.88857151215735\n",
      "Epoch 13/25, Batch 67/119, Loss: 6.112556591505784\n",
      "Epoch 13/25, Batch 68/119, Loss: 7.544197737515409\n",
      "Epoch 13/25, Batch 69/119, Loss: 8.121433038566552\n",
      "Epoch 13/25, Batch 70/119, Loss: 7.717049522700881\n",
      "Epoch 13/25, Batch 71/119, Loss: 5.8756986938557825\n",
      "Epoch 13/25, Batch 72/119, Loss: 7.359852397599226\n",
      "Epoch 13/25, Batch 73/119, Loss: 7.000808884524937\n",
      "Epoch 13/25, Batch 74/119, Loss: 8.318740386168939\n",
      "Epoch 13/25, Batch 75/119, Loss: 9.463328631912788\n",
      "Epoch 13/25, Batch 76/119, Loss: 8.683493606215777\n",
      "Epoch 13/25, Batch 77/119, Loss: 5.775825302224377\n",
      "Epoch 13/25, Batch 78/119, Loss: 8.067574010908602\n",
      "Epoch 13/25, Batch 79/119, Loss: 3.469359269204718\n",
      "Epoch 13/25, Batch 80/119, Loss: 8.435900919896037\n",
      "Epoch 13/25, Batch 81/119, Loss: 6.70046127878292\n",
      "Epoch 13/25, Batch 82/119, Loss: 8.151844040033696\n",
      "Epoch 13/25, Batch 83/119, Loss: 5.155953841959931\n",
      "Epoch 13/25, Batch 84/119, Loss: 9.694544787135357\n",
      "Epoch 13/25, Batch 85/119, Loss: 7.388305701290844\n",
      "Epoch 13/25, Batch 86/119, Loss: 5.4629382890309515\n",
      "Epoch 13/25, Batch 87/119, Loss: 7.788076421088573\n",
      "Epoch 13/25, Batch 88/119, Loss: 5.2674571999472155\n",
      "Epoch 13/25, Batch 89/119, Loss: 4.6060231521831\n",
      "Epoch 13/25, Batch 90/119, Loss: 6.5576900681554005\n",
      "Epoch 13/25, Batch 91/119, Loss: 9.44332963807598\n",
      "Epoch 13/25, Batch 92/119, Loss: 4.457694185211851\n",
      "Epoch 13/25, Batch 93/119, Loss: 7.505197395760192\n",
      "Epoch 13/25, Batch 94/119, Loss: 7.700806102445482\n",
      "Epoch 13/25, Batch 95/119, Loss: 6.887535779976921\n",
      "Epoch 13/25, Batch 96/119, Loss: 7.107070076424692\n",
      "Epoch 13/25, Batch 97/119, Loss: 8.198535452786752\n",
      "Epoch 13/25, Batch 98/119, Loss: 7.544104770626606\n",
      "Epoch 13/25, Batch 99/119, Loss: 7.337051998462753\n",
      "Epoch 13/25, Batch 100/119, Loss: 7.98036966266835\n",
      "Epoch 13/25, Batch 101/119, Loss: 8.57928886030081\n",
      "Epoch 13/25, Batch 102/119, Loss: 7.737842908582142\n",
      "Epoch 13/25, Batch 103/119, Loss: 8.859551131668137\n",
      "Epoch 13/25, Batch 104/119, Loss: 6.3813545831161145\n",
      "Epoch 13/25, Batch 105/119, Loss: 6.79027225179284\n",
      "Epoch 13/25, Batch 106/119, Loss: 6.261961400292351\n",
      "Epoch 13/25, Batch 107/119, Loss: 8.106433241404988\n",
      "Epoch 13/25, Batch 108/119, Loss: 9.046541585663583\n",
      "Epoch 13/25, Batch 109/119, Loss: 4.7750386794281745\n",
      "Epoch 13/25, Batch 110/119, Loss: 6.183133032734914\n",
      "Epoch 13/25, Batch 111/119, Loss: 4.900602159803737\n",
      "Epoch 13/25, Batch 112/119, Loss: 7.41456165652015\n",
      "Epoch 13/25, Batch 113/119, Loss: 5.985095439504013\n",
      "Epoch 13/25, Batch 114/119, Loss: 8.738986385144157\n",
      "Epoch 13/25, Batch 115/119, Loss: 8.231291099811843\n",
      "Epoch 13/25, Batch 116/119, Loss: 5.478366598202205\n",
      "Epoch 13/25, Batch 117/119, Loss: 8.002205135598798\n",
      "Epoch 13/25, Batch 118/119, Loss: 5.687648367297673\n",
      "Epoch 13/25, Batch 119/119, Loss: 4.819929295173058\n",
      "Epoch 13/25, Batch 120/119, Loss: 5.470665510466955\n",
      "Epoch 14/25, Batch 1/119, Loss: 8.108036001270476\n",
      "Epoch 14/25, Batch 2/119, Loss: 5.474644337780751\n",
      "Epoch 14/25, Batch 3/119, Loss: 5.535034563440487\n",
      "Epoch 14/25, Batch 4/119, Loss: 7.171711593808415\n",
      "Epoch 14/25, Batch 5/119, Loss: 9.198814183561618\n",
      "Epoch 14/25, Batch 6/119, Loss: 5.191132228544537\n",
      "Epoch 14/25, Batch 7/119, Loss: 7.430540943005588\n",
      "Epoch 14/25, Batch 8/119, Loss: 5.078923470870285\n",
      "Epoch 14/25, Batch 9/119, Loss: 5.594796627915491\n",
      "Epoch 14/25, Batch 10/119, Loss: 9.962489062400586\n",
      "Epoch 14/25, Batch 11/119, Loss: 9.389740838686867\n",
      "Epoch 14/25, Batch 12/119, Loss: 7.390437525416071\n",
      "Epoch 14/25, Batch 13/119, Loss: 9.052273001111924\n",
      "Epoch 14/25, Batch 14/119, Loss: 7.838134102791881\n",
      "Epoch 14/25, Batch 15/119, Loss: 7.283290353195809\n",
      "Epoch 14/25, Batch 16/119, Loss: 9.194000381155549\n",
      "Epoch 14/25, Batch 17/119, Loss: 9.739820282479194\n",
      "Epoch 14/25, Batch 18/119, Loss: 6.941409622037765\n",
      "Epoch 14/25, Batch 19/119, Loss: 6.0020557813778215\n",
      "Epoch 14/25, Batch 20/119, Loss: 7.747216741709795\n",
      "Epoch 14/25, Batch 21/119, Loss: 7.517260172826209\n",
      "Epoch 14/25, Batch 22/119, Loss: 4.750478418636495\n",
      "Epoch 14/25, Batch 23/119, Loss: 4.353573427763171\n",
      "Epoch 14/25, Batch 24/119, Loss: 7.795607612305491\n",
      "Epoch 14/25, Batch 25/119, Loss: 4.9624064829536065\n",
      "Epoch 14/25, Batch 26/119, Loss: 8.894036321144391\n",
      "Epoch 14/25, Batch 27/119, Loss: 8.574512848973892\n",
      "Epoch 14/25, Batch 28/119, Loss: 5.812022327199148\n",
      "Epoch 14/25, Batch 29/119, Loss: 5.399167996830675\n",
      "Epoch 14/25, Batch 30/119, Loss: 6.0586990118869\n",
      "Epoch 14/25, Batch 31/119, Loss: 7.1626975757183375\n",
      "Epoch 14/25, Batch 32/119, Loss: 6.697225120464299\n",
      "Epoch 14/25, Batch 33/119, Loss: 6.48675241313882\n",
      "Epoch 14/25, Batch 34/119, Loss: 8.280911514230784\n",
      "Epoch 14/25, Batch 35/119, Loss: 6.878403059632028\n",
      "Epoch 14/25, Batch 36/119, Loss: 8.041581109163191\n",
      "Epoch 14/25, Batch 37/119, Loss: 5.145589641122712\n",
      "Epoch 14/25, Batch 38/119, Loss: 6.156313444998868\n",
      "Epoch 14/25, Batch 39/119, Loss: 7.541870841772012\n",
      "Epoch 14/25, Batch 40/119, Loss: 6.440894282467126\n",
      "Epoch 14/25, Batch 41/119, Loss: 6.876636432587699\n",
      "Epoch 14/25, Batch 42/119, Loss: 8.60547588407874\n",
      "Epoch 14/25, Batch 43/119, Loss: 7.311324250077597\n",
      "Epoch 14/25, Batch 44/119, Loss: 7.713616184099165\n",
      "Epoch 14/25, Batch 45/119, Loss: 3.567085666787233\n",
      "Epoch 14/25, Batch 46/119, Loss: 5.9279179864516545\n",
      "Epoch 14/25, Batch 47/119, Loss: 8.11945105329956\n",
      "Epoch 14/25, Batch 48/119, Loss: 4.430119020304406\n",
      "Epoch 14/25, Batch 49/119, Loss: 7.226594291277188\n",
      "Epoch 14/25, Batch 50/119, Loss: 6.78313104241067\n",
      "Epoch 14/25, Batch 51/119, Loss: 7.760493737223232\n",
      "Epoch 14/25, Batch 52/119, Loss: 6.881736209028915\n",
      "Epoch 14/25, Batch 53/119, Loss: 5.89207774745235\n",
      "Epoch 14/25, Batch 54/119, Loss: 7.922520245429392\n",
      "Epoch 14/25, Batch 55/119, Loss: 7.930461877056032\n",
      "Epoch 14/25, Batch 56/119, Loss: 6.817994010770846\n",
      "Epoch 14/25, Batch 57/119, Loss: 3.700475926032174\n",
      "Epoch 14/25, Batch 58/119, Loss: 8.004723129339256\n",
      "Epoch 14/25, Batch 59/119, Loss: 7.626549499162307\n",
      "Epoch 14/25, Batch 60/119, Loss: 7.182228088678994\n",
      "Epoch 14/25, Batch 61/119, Loss: 5.192558534281612\n",
      "Epoch 14/25, Batch 62/119, Loss: 6.794469838611637\n",
      "Epoch 14/25, Batch 63/119, Loss: 8.30341574101936\n",
      "Epoch 14/25, Batch 64/119, Loss: 9.907620474570495\n",
      "Epoch 14/25, Batch 65/119, Loss: 10.32817384603021\n",
      "Epoch 14/25, Batch 66/119, Loss: 7.575047682329188\n",
      "Epoch 14/25, Batch 67/119, Loss: 5.881098031136883\n",
      "Epoch 14/25, Batch 68/119, Loss: 7.754571740825541\n",
      "Epoch 14/25, Batch 69/119, Loss: 4.128297887171484\n",
      "Epoch 14/25, Batch 70/119, Loss: 8.04250681986634\n",
      "Epoch 14/25, Batch 71/119, Loss: 7.415807540898785\n",
      "Epoch 14/25, Batch 72/119, Loss: 8.308905059218619\n",
      "Epoch 14/25, Batch 73/119, Loss: 6.145315386875242\n",
      "Epoch 14/25, Batch 74/119, Loss: 7.65118416939562\n",
      "Epoch 14/25, Batch 75/119, Loss: 7.870898946756794\n",
      "Epoch 14/25, Batch 76/119, Loss: 7.0041133767075765\n",
      "Epoch 14/25, Batch 77/119, Loss: 5.881338748682856\n",
      "Epoch 14/25, Batch 78/119, Loss: 3.93327142029101\n",
      "Epoch 14/25, Batch 79/119, Loss: 7.209122862966155\n",
      "Epoch 14/25, Batch 80/119, Loss: 8.206796989923737\n",
      "Epoch 14/25, Batch 81/119, Loss: 3.585717450701188\n",
      "Epoch 14/25, Batch 82/119, Loss: 6.2907583152444\n",
      "Epoch 14/25, Batch 83/119, Loss: 4.823565052564716\n",
      "Epoch 14/25, Batch 84/119, Loss: 4.494658255496681\n",
      "Epoch 14/25, Batch 85/119, Loss: 7.171587135361783\n",
      "Epoch 14/25, Batch 86/119, Loss: 7.299862322967249\n",
      "Epoch 14/25, Batch 87/119, Loss: 8.882598382091192\n",
      "Epoch 14/25, Batch 88/119, Loss: 8.5394850942929\n",
      "Epoch 14/25, Batch 89/119, Loss: 7.7971861886905245\n",
      "Epoch 14/25, Batch 90/119, Loss: 5.255573916336038\n",
      "Epoch 14/25, Batch 91/119, Loss: 7.447876272200579\n",
      "Epoch 14/25, Batch 92/119, Loss: 4.529666916531406\n",
      "Epoch 14/25, Batch 93/119, Loss: 4.427996010845091\n",
      "Epoch 14/25, Batch 94/119, Loss: 4.79121440688542\n",
      "Epoch 14/25, Batch 95/119, Loss: 7.534826943937131\n",
      "Epoch 14/25, Batch 96/119, Loss: 7.650767560057004\n",
      "Epoch 14/25, Batch 97/119, Loss: 9.2831595268915\n",
      "Epoch 14/25, Batch 98/119, Loss: 5.894635156136919\n",
      "Epoch 14/25, Batch 99/119, Loss: 6.652091410147873\n",
      "Epoch 14/25, Batch 100/119, Loss: 8.013581611071073\n",
      "Epoch 14/25, Batch 101/119, Loss: 9.104107914340082\n",
      "Epoch 14/25, Batch 102/119, Loss: 8.375831412231244\n",
      "Epoch 14/25, Batch 103/119, Loss: 6.08565620358159\n",
      "Epoch 14/25, Batch 104/119, Loss: 7.532957906061557\n",
      "Epoch 14/25, Batch 105/119, Loss: 7.948359176357475\n",
      "Epoch 14/25, Batch 106/119, Loss: 8.077236115458376\n",
      "Epoch 14/25, Batch 107/119, Loss: 8.172955287852204\n",
      "Epoch 14/25, Batch 108/119, Loss: 9.03210115586156\n",
      "Epoch 14/25, Batch 109/119, Loss: 6.500040075696833\n",
      "Epoch 14/25, Batch 110/119, Loss: 6.238451121120313\n",
      "Epoch 14/25, Batch 111/119, Loss: 6.8934561628719235\n",
      "Epoch 14/25, Batch 112/119, Loss: 6.732217165261543\n",
      "Epoch 14/25, Batch 113/119, Loss: 9.103619670458261\n",
      "Epoch 14/25, Batch 114/119, Loss: 7.780765311517839\n",
      "Epoch 14/25, Batch 115/119, Loss: 4.943133407992359\n",
      "Epoch 14/25, Batch 116/119, Loss: 9.027809341773645\n",
      "Epoch 14/25, Batch 117/119, Loss: 7.478533967819044\n",
      "Epoch 14/25, Batch 118/119, Loss: 7.387985557176227\n",
      "Epoch 14/25, Batch 119/119, Loss: 9.487048186494974\n",
      "Epoch 14/25, Batch 120/119, Loss: 8.739679548006267\n",
      "Epoch 15/25, Batch 1/119, Loss: 5.5666418996000315\n",
      "Epoch 15/25, Batch 2/119, Loss: 4.763892674761269\n",
      "Epoch 15/25, Batch 3/119, Loss: 6.147652100407683\n",
      "Epoch 15/25, Batch 4/119, Loss: 6.8842272643045685\n",
      "Epoch 15/25, Batch 5/119, Loss: 7.615817385908118\n",
      "Epoch 15/25, Batch 6/119, Loss: 8.378071999697003\n",
      "Epoch 15/25, Batch 7/119, Loss: 6.252353062686651\n",
      "Epoch 15/25, Batch 8/119, Loss: 8.052808502572764\n",
      "Epoch 15/25, Batch 9/119, Loss: 5.854231468075825\n",
      "Epoch 15/25, Batch 10/119, Loss: 6.0954262398896635\n",
      "Epoch 15/25, Batch 11/119, Loss: 7.349532736020121\n",
      "Epoch 15/25, Batch 12/119, Loss: 9.202108215336951\n",
      "Epoch 15/25, Batch 13/119, Loss: 5.4798567059926775\n",
      "Epoch 15/25, Batch 14/119, Loss: 6.803518757630991\n",
      "Epoch 15/25, Batch 15/119, Loss: 7.871802954052729\n",
      "Epoch 15/25, Batch 16/119, Loss: 7.147910575544791\n",
      "Epoch 15/25, Batch 17/119, Loss: 8.055508221784505\n",
      "Epoch 15/25, Batch 18/119, Loss: 6.035912893812661\n",
      "Epoch 15/25, Batch 19/119, Loss: 8.035518264288676\n",
      "Epoch 15/25, Batch 20/119, Loss: 5.856925811629464\n",
      "Epoch 15/25, Batch 21/119, Loss: 8.47442325905212\n",
      "Epoch 15/25, Batch 22/119, Loss: 7.550280188425714\n",
      "Epoch 15/25, Batch 23/119, Loss: 8.214219264483278\n",
      "Epoch 15/25, Batch 24/119, Loss: 6.337665683770682\n",
      "Epoch 15/25, Batch 25/119, Loss: 8.49259619977963\n",
      "Epoch 15/25, Batch 26/119, Loss: 6.859411899251448\n",
      "Epoch 15/25, Batch 27/119, Loss: 7.2229177849257695\n",
      "Epoch 15/25, Batch 28/119, Loss: 8.857379342656039\n",
      "Epoch 15/25, Batch 29/119, Loss: 7.989411295394932\n",
      "Epoch 15/25, Batch 30/119, Loss: 4.386098047090421\n",
      "Epoch 15/25, Batch 31/119, Loss: 6.9762279228195245\n",
      "Epoch 15/25, Batch 32/119, Loss: 6.955289571041985\n",
      "Epoch 15/25, Batch 33/119, Loss: 5.07274084122563\n",
      "Epoch 15/25, Batch 34/119, Loss: 8.424522261548502\n",
      "Epoch 15/25, Batch 35/119, Loss: 7.541733566694891\n",
      "Epoch 15/25, Batch 36/119, Loss: 8.754213900561542\n",
      "Epoch 15/25, Batch 37/119, Loss: 5.7264889928073615\n",
      "Epoch 15/25, Batch 38/119, Loss: 7.717653977664274\n",
      "Epoch 15/25, Batch 39/119, Loss: 6.967591574948483\n",
      "Epoch 15/25, Batch 40/119, Loss: 6.803126130130951\n",
      "Epoch 15/25, Batch 41/119, Loss: 8.435417280990709\n",
      "Epoch 15/25, Batch 42/119, Loss: 7.02508042163102\n",
      "Epoch 15/25, Batch 43/119, Loss: 4.924358138965763\n",
      "Epoch 15/25, Batch 44/119, Loss: 7.329156362150735\n",
      "Epoch 15/25, Batch 45/119, Loss: 5.6401188097261645\n",
      "Epoch 15/25, Batch 46/119, Loss: 5.655397028388133\n",
      "Epoch 15/25, Batch 47/119, Loss: 7.214739845436755\n",
      "Epoch 15/25, Batch 48/119, Loss: 5.381870628265143\n",
      "Epoch 15/25, Batch 49/119, Loss: 8.131413205082286\n",
      "Epoch 15/25, Batch 50/119, Loss: 6.486264897659756\n",
      "Epoch 15/25, Batch 51/119, Loss: 5.660448917188858\n",
      "Epoch 15/25, Batch 52/119, Loss: 4.204556242329203\n",
      "Epoch 15/25, Batch 53/119, Loss: 8.553681357780015\n",
      "Epoch 15/25, Batch 54/119, Loss: 7.942490747778527\n",
      "Epoch 15/25, Batch 55/119, Loss: 6.163184119772629\n",
      "Epoch 15/25, Batch 56/119, Loss: 9.010191219467941\n",
      "Epoch 15/25, Batch 57/119, Loss: 6.723313644564189\n",
      "Epoch 15/25, Batch 58/119, Loss: 7.338298941322044\n",
      "Epoch 15/25, Batch 59/119, Loss: 9.585399589785586\n",
      "Epoch 15/25, Batch 60/119, Loss: 6.996375076309136\n",
      "Epoch 15/25, Batch 61/119, Loss: 3.752817464102295\n",
      "Epoch 15/25, Batch 62/119, Loss: 5.807754259216167\n",
      "Epoch 15/25, Batch 63/119, Loss: 6.276749959015175\n",
      "Epoch 15/25, Batch 64/119, Loss: 8.218630046327116\n",
      "Epoch 15/25, Batch 65/119, Loss: 6.386604051344255\n",
      "Epoch 15/25, Batch 66/119, Loss: 6.881848397816887\n",
      "Epoch 15/25, Batch 67/119, Loss: 4.877029264988003\n",
      "Epoch 15/25, Batch 68/119, Loss: 7.046080464391587\n",
      "Epoch 15/25, Batch 69/119, Loss: 7.487622910010662\n",
      "Epoch 15/25, Batch 70/119, Loss: 7.037591649977509\n",
      "Epoch 15/25, Batch 71/119, Loss: 7.404827343993052\n",
      "Epoch 15/25, Batch 72/119, Loss: 6.029689389344178\n",
      "Epoch 15/25, Batch 73/119, Loss: 5.264019518749881\n",
      "Epoch 15/25, Batch 74/119, Loss: 6.183768885581015\n",
      "Epoch 15/25, Batch 75/119, Loss: 6.2572571370089225\n",
      "Epoch 15/25, Batch 76/119, Loss: 9.00210721801933\n",
      "Epoch 15/25, Batch 77/119, Loss: 5.736396713454085\n",
      "Epoch 15/25, Batch 78/119, Loss: 4.195603196959229\n",
      "Epoch 15/25, Batch 79/119, Loss: 5.025551876922626\n",
      "Epoch 15/25, Batch 80/119, Loss: 8.552134835905347\n",
      "Epoch 15/25, Batch 81/119, Loss: 6.0527923860146995\n",
      "Epoch 15/25, Batch 82/119, Loss: 5.537650999954481\n",
      "Epoch 15/25, Batch 83/119, Loss: 5.531806713001667\n",
      "Epoch 15/25, Batch 84/119, Loss: 5.370212209922675\n",
      "Epoch 15/25, Batch 85/119, Loss: 7.903968916615377\n",
      "Epoch 15/25, Batch 86/119, Loss: 8.49601643248929\n",
      "Epoch 15/25, Batch 87/119, Loss: 7.7402696088945895\n",
      "Epoch 15/25, Batch 88/119, Loss: 7.667291265423375\n",
      "Epoch 15/25, Batch 89/119, Loss: 9.505420239942124\n",
      "Epoch 15/25, Batch 90/119, Loss: 5.927422821523984\n",
      "Epoch 15/25, Batch 91/119, Loss: 6.644077900610773\n",
      "Epoch 15/25, Batch 92/119, Loss: 7.555448316195665\n",
      "Epoch 15/25, Batch 93/119, Loss: 7.791058959405554\n",
      "Epoch 15/25, Batch 94/119, Loss: 7.912641023527045\n",
      "Epoch 15/25, Batch 95/119, Loss: 8.820129189714654\n",
      "Epoch 15/25, Batch 96/119, Loss: 5.6941750832973765\n",
      "Epoch 15/25, Batch 97/119, Loss: 9.391773426569081\n",
      "Epoch 15/25, Batch 98/119, Loss: 9.612859628439745\n",
      "Epoch 15/25, Batch 99/119, Loss: 4.389379971762275\n",
      "Epoch 15/25, Batch 100/119, Loss: 5.337868752136892\n",
      "Epoch 15/25, Batch 101/119, Loss: 8.451038093383094\n",
      "Epoch 15/25, Batch 102/119, Loss: 7.244389569940127\n",
      "Epoch 15/25, Batch 103/119, Loss: 5.502173016652946\n",
      "Epoch 15/25, Batch 104/119, Loss: 6.332930286294115\n",
      "Epoch 15/25, Batch 105/119, Loss: 7.737711491444243\n",
      "Epoch 15/25, Batch 106/119, Loss: 5.879331261698941\n",
      "Epoch 15/25, Batch 107/119, Loss: 7.498656964769952\n",
      "Epoch 15/25, Batch 108/119, Loss: 7.416933261056108\n",
      "Epoch 15/25, Batch 109/119, Loss: 4.922865927520896\n",
      "Epoch 15/25, Batch 110/119, Loss: 5.025028003706322\n",
      "Epoch 15/25, Batch 111/119, Loss: 9.265237220390723\n",
      "Epoch 15/25, Batch 112/119, Loss: 5.5769073470399935\n",
      "Epoch 15/25, Batch 113/119, Loss: 7.9137501648003346\n",
      "Epoch 15/25, Batch 114/119, Loss: 4.757734763824985\n",
      "Epoch 15/25, Batch 115/119, Loss: 8.678184150284345\n",
      "Epoch 15/25, Batch 116/119, Loss: 10.42937016025746\n",
      "Epoch 15/25, Batch 117/119, Loss: 5.870434999554427\n",
      "Epoch 15/25, Batch 118/119, Loss: 8.479475772328254\n",
      "Epoch 15/25, Batch 119/119, Loss: 7.3513866851432565\n",
      "Epoch 15/25, Batch 120/119, Loss: 7.283639629189798\n",
      "Epoch 16/25, Batch 1/119, Loss: 9.530816070061823\n",
      "Epoch 16/25, Batch 2/119, Loss: 5.979637636119271\n",
      "Epoch 16/25, Batch 3/119, Loss: 5.381399271596015\n",
      "Epoch 16/25, Batch 4/119, Loss: 6.511385980738562\n",
      "Epoch 16/25, Batch 5/119, Loss: 6.668694628686982\n",
      "Epoch 16/25, Batch 6/119, Loss: 6.99395948451658\n",
      "Epoch 16/25, Batch 7/119, Loss: 8.02852617524479\n",
      "Epoch 16/25, Batch 8/119, Loss: 5.377237942703725\n",
      "Epoch 16/25, Batch 9/119, Loss: 5.350505166708299\n",
      "Epoch 16/25, Batch 10/119, Loss: 4.442142651555196\n",
      "Epoch 16/25, Batch 11/119, Loss: 7.71317340099642\n",
      "Epoch 16/25, Batch 12/119, Loss: 6.153203925520377\n",
      "Epoch 16/25, Batch 13/119, Loss: 7.730397173835322\n",
      "Epoch 16/25, Batch 14/119, Loss: 8.857644330309512\n",
      "Epoch 16/25, Batch 15/119, Loss: 6.841093788556366\n",
      "Epoch 16/25, Batch 16/119, Loss: 7.02513937081576\n",
      "Epoch 16/25, Batch 17/119, Loss: 8.04350274087611\n",
      "Epoch 16/25, Batch 18/119, Loss: 5.924505441433725\n",
      "Epoch 16/25, Batch 19/119, Loss: 8.208049728743708\n",
      "Epoch 16/25, Batch 20/119, Loss: 6.3810870960382635\n",
      "Epoch 16/25, Batch 21/119, Loss: 7.372919632233972\n",
      "Epoch 16/25, Batch 22/119, Loss: 7.204566938339458\n",
      "Epoch 16/25, Batch 23/119, Loss: 7.75120036807186\n",
      "Epoch 16/25, Batch 24/119, Loss: 9.323584692926472\n",
      "Epoch 16/25, Batch 25/119, Loss: 6.748192915208003\n",
      "Epoch 16/25, Batch 26/119, Loss: 6.535143697830221\n",
      "Epoch 16/25, Batch 27/119, Loss: 9.754594281474935\n",
      "Epoch 16/25, Batch 28/119, Loss: 7.87615199518036\n",
      "Epoch 16/25, Batch 29/119, Loss: 7.970704876283042\n",
      "Epoch 16/25, Batch 30/119, Loss: 5.900632675854397\n",
      "Epoch 16/25, Batch 31/119, Loss: 8.176436266209024\n",
      "Epoch 16/25, Batch 32/119, Loss: 5.392451128689972\n",
      "Epoch 16/25, Batch 33/119, Loss: 4.659583851322529\n",
      "Epoch 16/25, Batch 34/119, Loss: 7.927009960565725\n",
      "Epoch 16/25, Batch 35/119, Loss: 9.255926356821105\n",
      "Epoch 16/25, Batch 36/119, Loss: 4.9366416880888\n",
      "Epoch 16/25, Batch 37/119, Loss: 8.025866250946931\n",
      "Epoch 16/25, Batch 38/119, Loss: 6.138193579290565\n",
      "Epoch 16/25, Batch 39/119, Loss: 6.1825404752458235\n",
      "Epoch 16/25, Batch 40/119, Loss: 6.349337559309096\n",
      "Epoch 16/25, Batch 41/119, Loss: 6.562246549258982\n",
      "Epoch 16/25, Batch 42/119, Loss: 7.4700903836804535\n",
      "Epoch 16/25, Batch 43/119, Loss: 9.15256377728629\n",
      "Epoch 16/25, Batch 44/119, Loss: 4.747007551583961\n",
      "Epoch 16/25, Batch 45/119, Loss: 6.88259208029805\n",
      "Epoch 16/25, Batch 46/119, Loss: 7.0152656886007065\n",
      "Epoch 16/25, Batch 47/119, Loss: 6.158094453789661\n",
      "Epoch 16/25, Batch 48/119, Loss: 7.704576757675898\n",
      "Epoch 16/25, Batch 49/119, Loss: 6.173776646478259\n",
      "Epoch 16/25, Batch 50/119, Loss: 8.364033149418475\n",
      "Epoch 16/25, Batch 51/119, Loss: 9.02731749800318\n",
      "Epoch 16/25, Batch 52/119, Loss: 8.417967323133755\n",
      "Epoch 16/25, Batch 53/119, Loss: 8.328888030865127\n",
      "Epoch 16/25, Batch 54/119, Loss: 9.085926343901159\n",
      "Epoch 16/25, Batch 55/119, Loss: 6.083509346760535\n",
      "Epoch 16/25, Batch 56/119, Loss: 7.276210120272844\n",
      "Epoch 16/25, Batch 57/119, Loss: 7.9744325317192395\n",
      "Epoch 16/25, Batch 58/119, Loss: 9.315152540676474\n",
      "Epoch 16/25, Batch 59/119, Loss: 8.226956690282654\n",
      "Epoch 16/25, Batch 60/119, Loss: 7.4568375718378865\n",
      "Epoch 16/25, Batch 61/119, Loss: 6.979039795811603\n",
      "Epoch 16/25, Batch 62/119, Loss: 7.398917010915848\n",
      "Epoch 16/25, Batch 63/119, Loss: 7.663748419201071\n",
      "Epoch 16/25, Batch 64/119, Loss: 6.171269943408675\n",
      "Epoch 16/25, Batch 65/119, Loss: 8.28355014312935\n",
      "Epoch 16/25, Batch 66/119, Loss: 7.444170888850262\n",
      "Epoch 16/25, Batch 67/119, Loss: 6.694717009863137\n",
      "Epoch 16/25, Batch 68/119, Loss: 9.099914715984301\n",
      "Epoch 16/25, Batch 69/119, Loss: 7.35283225423973\n",
      "Epoch 16/25, Batch 70/119, Loss: 8.371362458242748\n",
      "Epoch 16/25, Batch 71/119, Loss: 6.700049831375108\n",
      "Epoch 16/25, Batch 72/119, Loss: 6.968691163346743\n",
      "Epoch 16/25, Batch 73/119, Loss: 8.495205397797426\n",
      "Epoch 16/25, Batch 74/119, Loss: 8.528883878067992\n",
      "Epoch 16/25, Batch 75/119, Loss: 5.574866257147482\n",
      "Epoch 16/25, Batch 76/119, Loss: 7.86481554987126\n",
      "Epoch 16/25, Batch 77/119, Loss: 4.794078126810769\n",
      "Epoch 16/25, Batch 78/119, Loss: 9.212889468592307\n",
      "Epoch 16/25, Batch 79/119, Loss: 5.945852362138386\n",
      "Epoch 16/25, Batch 80/119, Loss: 4.737204050686997\n",
      "Epoch 16/25, Batch 81/119, Loss: 7.944530165242796\n",
      "Epoch 16/25, Batch 82/119, Loss: 9.690537986795407\n",
      "Epoch 16/25, Batch 83/119, Loss: 7.685752169234107\n",
      "Epoch 16/25, Batch 84/119, Loss: 6.622466254384296\n",
      "Epoch 16/25, Batch 85/119, Loss: 7.111708677175246\n",
      "Epoch 16/25, Batch 86/119, Loss: 6.496062828305478\n",
      "Epoch 16/25, Batch 87/119, Loss: 4.824103494262331\n",
      "Epoch 16/25, Batch 88/119, Loss: 3.550076455290149\n",
      "Epoch 16/25, Batch 89/119, Loss: 7.997572025781784\n",
      "Epoch 16/25, Batch 90/119, Loss: 9.33314063351059\n",
      "Epoch 16/25, Batch 91/119, Loss: 7.239280092381482\n",
      "Epoch 16/25, Batch 92/119, Loss: 4.673244710853765\n",
      "Epoch 16/25, Batch 93/119, Loss: 5.554831087671279\n",
      "Epoch 16/25, Batch 94/119, Loss: 5.879544909381972\n",
      "Epoch 16/25, Batch 95/119, Loss: 5.236806632866845\n",
      "Epoch 16/25, Batch 96/119, Loss: 5.057181437640236\n",
      "Epoch 16/25, Batch 97/119, Loss: 5.489480873038393\n",
      "Epoch 16/25, Batch 98/119, Loss: 5.908844130361623\n",
      "Epoch 16/25, Batch 99/119, Loss: 6.495025305736156\n",
      "Epoch 16/25, Batch 100/119, Loss: 4.420067438287456\n",
      "Epoch 16/25, Batch 101/119, Loss: 5.493198751821321\n",
      "Epoch 16/25, Batch 102/119, Loss: 9.750433815311725\n",
      "Epoch 16/25, Batch 103/119, Loss: 6.765259337170939\n",
      "Epoch 16/25, Batch 104/119, Loss: 4.3840575445394245\n",
      "Epoch 16/25, Batch 105/119, Loss: 5.717798678876756\n",
      "Epoch 16/25, Batch 106/119, Loss: 8.754547962759608\n",
      "Epoch 16/25, Batch 107/119, Loss: 8.264487895522777\n",
      "Epoch 16/25, Batch 108/119, Loss: 7.803313373607083\n",
      "Epoch 16/25, Batch 109/119, Loss: 7.8715935565858155\n",
      "Epoch 16/25, Batch 110/119, Loss: 6.398995611837902\n",
      "Epoch 16/25, Batch 111/119, Loss: 7.915393483077891\n",
      "Epoch 16/25, Batch 112/119, Loss: 7.079837706608107\n",
      "Epoch 16/25, Batch 113/119, Loss: 5.55808056368775\n",
      "Epoch 16/25, Batch 114/119, Loss: 5.6724314696272575\n",
      "Epoch 16/25, Batch 115/119, Loss: 6.1426677592195\n",
      "Epoch 16/25, Batch 116/119, Loss: 8.361882665251178\n",
      "Epoch 16/25, Batch 117/119, Loss: 6.347932238177062\n",
      "Epoch 16/25, Batch 118/119, Loss: 8.468022964568156\n",
      "Epoch 16/25, Batch 119/119, Loss: 7.2615699096712305\n",
      "Epoch 16/25, Batch 120/119, Loss: 6.418246021512132\n",
      "Epoch 17/25, Batch 1/119, Loss: 7.104948559505153\n",
      "Epoch 17/25, Batch 2/119, Loss: 5.679313642992491\n",
      "Epoch 17/25, Batch 3/119, Loss: 4.574343038582193\n",
      "Epoch 17/25, Batch 4/119, Loss: 7.96607873806407\n",
      "Epoch 17/25, Batch 5/119, Loss: 9.852010136079596\n",
      "Epoch 17/25, Batch 6/119, Loss: 4.805910149750538\n",
      "Epoch 17/25, Batch 7/119, Loss: 6.523231804770096\n",
      "Epoch 17/25, Batch 8/119, Loss: 7.493000517843688\n",
      "Epoch 17/25, Batch 9/119, Loss: 8.10505069239193\n",
      "Epoch 17/25, Batch 10/119, Loss: 7.87912072323947\n",
      "Epoch 17/25, Batch 11/119, Loss: 7.893557299380416\n",
      "Epoch 17/25, Batch 12/119, Loss: 4.6585547084318355\n",
      "Epoch 17/25, Batch 13/119, Loss: 8.142777579080168\n",
      "Epoch 17/25, Batch 14/119, Loss: 3.9254862294322757\n",
      "Epoch 17/25, Batch 15/119, Loss: 7.659243979897843\n",
      "Epoch 17/25, Batch 16/119, Loss: 6.3201128656213506\n",
      "Epoch 17/25, Batch 17/119, Loss: 6.8907482817069905\n",
      "Epoch 17/25, Batch 18/119, Loss: 7.171235261560461\n",
      "Epoch 17/25, Batch 19/119, Loss: 4.698655525383551\n",
      "Epoch 17/25, Batch 20/119, Loss: 8.484671470213144\n",
      "Epoch 17/25, Batch 21/119, Loss: 7.125693185055696\n",
      "Epoch 17/25, Batch 22/119, Loss: 7.506986234964593\n",
      "Epoch 17/25, Batch 23/119, Loss: 7.522105685747313\n",
      "Epoch 17/25, Batch 24/119, Loss: 7.012714236908288\n",
      "Epoch 17/25, Batch 25/119, Loss: 6.610043185640037\n",
      "Epoch 17/25, Batch 26/119, Loss: 6.713201658972828\n",
      "Epoch 17/25, Batch 27/119, Loss: 7.460943143487412\n",
      "Epoch 17/25, Batch 28/119, Loss: 5.5729686674085634\n",
      "Epoch 17/25, Batch 29/119, Loss: 7.7297770722635395\n",
      "Epoch 17/25, Batch 30/119, Loss: 6.563517602852632\n",
      "Epoch 17/25, Batch 31/119, Loss: 7.510146697916774\n",
      "Epoch 17/25, Batch 32/119, Loss: 8.36367111128843\n",
      "Epoch 17/25, Batch 33/119, Loss: 7.777067970419492\n",
      "Epoch 17/25, Batch 34/119, Loss: 6.765802857701472\n",
      "Epoch 17/25, Batch 35/119, Loss: 7.53694735459616\n",
      "Epoch 17/25, Batch 36/119, Loss: 7.157820762787072\n",
      "Epoch 17/25, Batch 37/119, Loss: 8.410805337749895\n",
      "Epoch 17/25, Batch 38/119, Loss: 10.750492239249622\n",
      "Epoch 17/25, Batch 39/119, Loss: 8.519296135124796\n",
      "Epoch 17/25, Batch 40/119, Loss: 7.699154729422044\n",
      "Epoch 17/25, Batch 41/119, Loss: 5.348632943498105\n",
      "Epoch 17/25, Batch 42/119, Loss: 8.09322596970474\n",
      "Epoch 17/25, Batch 43/119, Loss: 5.845327668016498\n",
      "Epoch 17/25, Batch 44/119, Loss: 6.566674953814107\n",
      "Epoch 17/25, Batch 45/119, Loss: 9.83376449846146\n",
      "Epoch 17/25, Batch 46/119, Loss: 7.636502653428733\n",
      "Epoch 17/25, Batch 47/119, Loss: 5.72966633192207\n",
      "Epoch 17/25, Batch 48/119, Loss: 5.115305993474322\n",
      "Epoch 17/25, Batch 49/119, Loss: 4.79751583411718\n",
      "Epoch 17/25, Batch 50/119, Loss: 6.804276171960464\n",
      "Epoch 17/25, Batch 51/119, Loss: 8.169046445663648\n",
      "Epoch 17/25, Batch 52/119, Loss: 6.835332200054298\n",
      "Epoch 17/25, Batch 53/119, Loss: 6.36944617870996\n",
      "Epoch 17/25, Batch 54/119, Loss: 6.934420776864353\n",
      "Epoch 17/25, Batch 55/119, Loss: 4.612587460774438\n",
      "Epoch 17/25, Batch 56/119, Loss: 8.413283780246635\n",
      "Epoch 17/25, Batch 57/119, Loss: 6.880728695308207\n",
      "Epoch 17/25, Batch 58/119, Loss: 6.032999307545185\n",
      "Epoch 17/25, Batch 59/119, Loss: 10.346723244939529\n",
      "Epoch 17/25, Batch 60/119, Loss: 5.53581067309703\n",
      "Epoch 17/25, Batch 61/119, Loss: 7.570115772460097\n",
      "Epoch 17/25, Batch 62/119, Loss: 7.474838190213994\n",
      "Epoch 17/25, Batch 63/119, Loss: 7.161862674099998\n",
      "Epoch 17/25, Batch 64/119, Loss: 7.103137643698321\n",
      "Epoch 17/25, Batch 65/119, Loss: 5.745156561025464\n",
      "Epoch 17/25, Batch 66/119, Loss: 5.153841451149946\n",
      "Epoch 17/25, Batch 67/119, Loss: 5.915130528616071\n",
      "Epoch 17/25, Batch 68/119, Loss: 6.283539574343716\n",
      "Epoch 17/25, Batch 69/119, Loss: 9.843502678429095\n",
      "Epoch 17/25, Batch 70/119, Loss: 6.8099333481025806\n",
      "Epoch 17/25, Batch 71/119, Loss: 6.834637840719868\n",
      "Epoch 17/25, Batch 72/119, Loss: 5.481916062178291\n",
      "Epoch 17/25, Batch 73/119, Loss: 5.330537980527574\n",
      "Epoch 17/25, Batch 74/119, Loss: 3.4466707633915243\n",
      "Epoch 17/25, Batch 75/119, Loss: 6.308740914377636\n",
      "Epoch 17/25, Batch 76/119, Loss: 7.625173287206806\n",
      "Epoch 17/25, Batch 77/119, Loss: 9.9806516238991\n",
      "Epoch 17/25, Batch 78/119, Loss: 8.948152745477492\n",
      "Epoch 17/25, Batch 79/119, Loss: 6.9970613707046505\n",
      "Epoch 17/25, Batch 80/119, Loss: 7.260063730124463\n",
      "Epoch 17/25, Batch 81/119, Loss: 7.735095340043276\n",
      "Epoch 17/25, Batch 82/119, Loss: 6.1352113122630705\n",
      "Epoch 17/25, Batch 83/119, Loss: 4.454908680114715\n",
      "Epoch 17/25, Batch 84/119, Loss: 9.816431695718462\n",
      "Epoch 17/25, Batch 85/119, Loss: 8.069253251021264\n",
      "Epoch 17/25, Batch 86/119, Loss: 8.273974492784456\n",
      "Epoch 17/25, Batch 87/119, Loss: 5.922170817228258\n",
      "Epoch 17/25, Batch 88/119, Loss: 7.331039590418267\n",
      "Epoch 17/25, Batch 89/119, Loss: 4.643985872718802\n",
      "Epoch 17/25, Batch 90/119, Loss: 4.468294704601881\n",
      "Epoch 17/25, Batch 91/119, Loss: 8.386530250125716\n",
      "Epoch 17/25, Batch 92/119, Loss: 6.5557980200444\n",
      "Epoch 17/25, Batch 93/119, Loss: 7.8145000176921995\n",
      "Epoch 17/25, Batch 94/119, Loss: 7.00405528854112\n",
      "Epoch 17/25, Batch 95/119, Loss: 6.076821336469436\n",
      "Epoch 17/25, Batch 96/119, Loss: 5.078007297276848\n",
      "Epoch 17/25, Batch 97/119, Loss: 5.710538682373587\n",
      "Epoch 17/25, Batch 98/119, Loss: 7.396659157952972\n",
      "Epoch 17/25, Batch 99/119, Loss: 6.829497466431663\n",
      "Epoch 17/25, Batch 100/119, Loss: 6.821691507601927\n",
      "Epoch 17/25, Batch 101/119, Loss: 6.464558587198402\n",
      "Epoch 17/25, Batch 102/119, Loss: 9.772389309194377\n",
      "Epoch 17/25, Batch 103/119, Loss: 8.505444712341246\n",
      "Epoch 17/25, Batch 104/119, Loss: 10.235672485730701\n",
      "Epoch 17/25, Batch 105/119, Loss: 6.441303543002762\n",
      "Epoch 17/25, Batch 106/119, Loss: 9.593621370108695\n",
      "Epoch 17/25, Batch 107/119, Loss: 7.393327849935102\n",
      "Epoch 17/25, Batch 108/119, Loss: 6.191406740566205\n",
      "Epoch 17/25, Batch 109/119, Loss: 5.478900177364853\n",
      "Epoch 17/25, Batch 110/119, Loss: 8.27298382098149\n",
      "Epoch 17/25, Batch 111/119, Loss: 6.600017394159488\n",
      "Epoch 17/25, Batch 112/119, Loss: 8.53992481538075\n",
      "Epoch 17/25, Batch 113/119, Loss: 7.961086358314969\n",
      "Epoch 17/25, Batch 114/119, Loss: 10.394658124293723\n",
      "Epoch 17/25, Batch 115/119, Loss: 7.9669747962716055\n",
      "Epoch 17/25, Batch 116/119, Loss: 7.3514991767251585\n",
      "Epoch 17/25, Batch 117/119, Loss: 9.133214251934424\n",
      "Epoch 17/25, Batch 118/119, Loss: 7.690927154781096\n",
      "Epoch 17/25, Batch 119/119, Loss: 8.966002732402647\n",
      "Epoch 17/25, Batch 120/119, Loss: 5.43594105173995\n",
      "Epoch 18/25, Batch 1/119, Loss: 8.037495579971297\n",
      "Epoch 18/25, Batch 2/119, Loss: 5.925153655832572\n",
      "Epoch 18/25, Batch 3/119, Loss: 9.452796289583965\n",
      "Epoch 18/25, Batch 4/119, Loss: 7.410068005478834\n",
      "Epoch 18/25, Batch 5/119, Loss: 6.662706587166271\n",
      "Epoch 18/25, Batch 6/119, Loss: 6.895166442463867\n",
      "Epoch 18/25, Batch 7/119, Loss: 8.287278488329196\n",
      "Epoch 18/25, Batch 8/119, Loss: 6.920854284475975\n",
      "Epoch 18/25, Batch 9/119, Loss: 6.785482246766211\n",
      "Epoch 18/25, Batch 10/119, Loss: 8.737319229156903\n",
      "Epoch 18/25, Batch 11/119, Loss: 9.175289975878007\n",
      "Epoch 18/25, Batch 12/119, Loss: 7.901890018948653\n",
      "Epoch 18/25, Batch 13/119, Loss: 5.545359281122962\n",
      "Epoch 18/25, Batch 14/119, Loss: 6.287902131573512\n",
      "Epoch 18/25, Batch 15/119, Loss: 7.348796940963835\n",
      "Epoch 18/25, Batch 16/119, Loss: 7.8610106161469675\n",
      "Epoch 18/25, Batch 17/119, Loss: 7.7122779341594665\n",
      "Epoch 18/25, Batch 18/119, Loss: 8.387158899614304\n",
      "Epoch 18/25, Batch 19/119, Loss: 6.285979086885617\n",
      "Epoch 18/25, Batch 20/119, Loss: 7.464004490692879\n",
      "Epoch 18/25, Batch 21/119, Loss: 7.888275244546945\n",
      "Epoch 18/25, Batch 22/119, Loss: 5.46669974799279\n",
      "Epoch 18/25, Batch 23/119, Loss: 5.914536048896768\n",
      "Epoch 18/25, Batch 24/119, Loss: 4.961126048102288\n",
      "Epoch 18/25, Batch 25/119, Loss: 6.082869155908049\n",
      "Epoch 18/25, Batch 26/119, Loss: 7.517464415472395\n",
      "Epoch 18/25, Batch 27/119, Loss: 7.311083519389186\n",
      "Epoch 18/25, Batch 28/119, Loss: 6.385317820456278\n",
      "Epoch 18/25, Batch 29/119, Loss: 4.543593791248344\n",
      "Epoch 18/25, Batch 30/119, Loss: 5.578310285883978\n",
      "Epoch 18/25, Batch 31/119, Loss: 6.679965407919958\n",
      "Epoch 18/25, Batch 32/119, Loss: 6.309423711633649\n",
      "Epoch 18/25, Batch 33/119, Loss: 8.378057942211962\n",
      "Epoch 18/25, Batch 34/119, Loss: 9.652801869142483\n",
      "Epoch 18/25, Batch 35/119, Loss: 5.744442990743189\n",
      "Epoch 18/25, Batch 36/119, Loss: 4.439034268379365\n",
      "Epoch 18/25, Batch 37/119, Loss: 7.104976148300101\n",
      "Epoch 18/25, Batch 38/119, Loss: 6.83265659999338\n",
      "Epoch 18/25, Batch 39/119, Loss: 6.334584717963152\n",
      "Epoch 18/25, Batch 40/119, Loss: 8.328750420350277\n",
      "Epoch 18/25, Batch 41/119, Loss: 8.0509056335933\n",
      "Epoch 18/25, Batch 42/119, Loss: 7.749656260935156\n",
      "Epoch 18/25, Batch 43/119, Loss: 7.951868364935419\n",
      "Epoch 18/25, Batch 44/119, Loss: 8.888186518307752\n",
      "Epoch 18/25, Batch 45/119, Loss: 6.415304862900214\n",
      "Epoch 18/25, Batch 46/119, Loss: 8.556125848791684\n",
      "Epoch 18/25, Batch 47/119, Loss: 7.379863960240474\n",
      "Epoch 18/25, Batch 48/119, Loss: 7.8868438850646845\n",
      "Epoch 18/25, Batch 49/119, Loss: 5.375769787981986\n",
      "Epoch 18/25, Batch 50/119, Loss: 6.983527751178357\n",
      "Epoch 18/25, Batch 51/119, Loss: 7.185173421645858\n",
      "Epoch 18/25, Batch 52/119, Loss: 6.77397221571619\n",
      "Epoch 18/25, Batch 53/119, Loss: 8.318833099595823\n",
      "Epoch 18/25, Batch 54/119, Loss: 6.788444154329241\n",
      "Epoch 18/25, Batch 55/119, Loss: 8.989382741649166\n",
      "Epoch 18/25, Batch 56/119, Loss: 6.333643806648811\n",
      "Epoch 18/25, Batch 57/119, Loss: 7.07816668770076\n",
      "Epoch 18/25, Batch 58/119, Loss: 7.277296780743215\n",
      "Epoch 18/25, Batch 59/119, Loss: 6.843245613608112\n",
      "Epoch 18/25, Batch 60/119, Loss: 8.007796868125354\n",
      "Epoch 18/25, Batch 61/119, Loss: 5.852646531828165\n",
      "Epoch 18/25, Batch 62/119, Loss: 8.018190388752288\n",
      "Epoch 18/25, Batch 63/119, Loss: 10.799674061047261\n",
      "Epoch 18/25, Batch 64/119, Loss: 5.371661113305428\n",
      "Epoch 18/25, Batch 65/119, Loss: 6.898690757332518\n",
      "Epoch 18/25, Batch 66/119, Loss: 4.685034165026173\n",
      "Epoch 18/25, Batch 67/119, Loss: 8.586838162419747\n",
      "Epoch 18/25, Batch 68/119, Loss: 5.698755878936748\n",
      "Epoch 18/25, Batch 69/119, Loss: 7.505703967609902\n",
      "Epoch 18/25, Batch 70/119, Loss: 8.338016424614919\n",
      "Epoch 18/25, Batch 71/119, Loss: 8.400526362474759\n",
      "Epoch 18/25, Batch 72/119, Loss: 8.194566024360281\n",
      "Epoch 18/25, Batch 73/119, Loss: 5.780241951930589\n",
      "Epoch 18/25, Batch 74/119, Loss: 5.276334780295247\n",
      "Epoch 18/25, Batch 75/119, Loss: 7.989660246902827\n",
      "Epoch 18/25, Batch 76/119, Loss: 9.008790465308957\n",
      "Epoch 18/25, Batch 77/119, Loss: 6.527389894311081\n",
      "Epoch 18/25, Batch 78/119, Loss: 8.473720723301605\n",
      "Epoch 18/25, Batch 79/119, Loss: 9.178471472682835\n",
      "Epoch 18/25, Batch 80/119, Loss: 8.5607534538054\n",
      "Epoch 18/25, Batch 81/119, Loss: 7.012351910289329\n",
      "Epoch 18/25, Batch 82/119, Loss: 9.48029072390127\n",
      "Epoch 18/25, Batch 83/119, Loss: 8.329422406630128\n",
      "Epoch 18/25, Batch 84/119, Loss: 10.247758943900164\n",
      "Epoch 18/25, Batch 85/119, Loss: 10.299147411537781\n",
      "Epoch 18/25, Batch 86/119, Loss: 4.598040194057609\n",
      "Epoch 18/25, Batch 87/119, Loss: 9.124881164482348\n",
      "Epoch 18/25, Batch 88/119, Loss: 8.199224840214551\n",
      "Epoch 18/25, Batch 89/119, Loss: 9.894761706678121\n",
      "Epoch 18/25, Batch 90/119, Loss: 8.23853073138875\n",
      "Epoch 18/25, Batch 91/119, Loss: 10.687145934331461\n",
      "Epoch 18/25, Batch 92/119, Loss: 6.820757470382658\n",
      "Epoch 18/25, Batch 93/119, Loss: 10.204756142891968\n",
      "Epoch 18/25, Batch 94/119, Loss: 8.429525337824654\n",
      "Epoch 18/25, Batch 95/119, Loss: 4.132548348047551\n",
      "Epoch 18/25, Batch 96/119, Loss: 4.430143837222211\n",
      "Epoch 18/25, Batch 97/119, Loss: 9.291560207784084\n",
      "Epoch 18/25, Batch 98/119, Loss: 5.967365076041618\n",
      "Epoch 18/25, Batch 99/119, Loss: 7.563041643037579\n",
      "Epoch 18/25, Batch 100/119, Loss: 4.71389937384405\n",
      "Epoch 18/25, Batch 101/119, Loss: 7.045074687292476\n",
      "Epoch 18/25, Batch 102/119, Loss: 5.544882305903318\n",
      "Epoch 18/25, Batch 103/119, Loss: 6.849502155381839\n",
      "Epoch 18/25, Batch 104/119, Loss: 7.508323846108357\n",
      "Epoch 18/25, Batch 105/119, Loss: 5.689712839304305\n",
      "Epoch 18/25, Batch 106/119, Loss: 5.456092180599663\n",
      "Epoch 18/25, Batch 107/119, Loss: 7.91566001200601\n",
      "Epoch 18/25, Batch 108/119, Loss: 8.031488826063535\n",
      "Epoch 18/25, Batch 109/119, Loss: 8.199526917488566\n",
      "Epoch 18/25, Batch 110/119, Loss: 7.1875951839801635\n",
      "Epoch 18/25, Batch 111/119, Loss: 7.140413489808652\n",
      "Epoch 18/25, Batch 112/119, Loss: 5.293513050080182\n",
      "Epoch 18/25, Batch 113/119, Loss: 6.276225640793935\n",
      "Epoch 18/25, Batch 114/119, Loss: 8.484734441658459\n",
      "Epoch 18/25, Batch 115/119, Loss: 5.523552776504906\n",
      "Epoch 18/25, Batch 116/119, Loss: 7.550548597333172\n",
      "Epoch 18/25, Batch 117/119, Loss: 7.489551851014135\n",
      "Epoch 18/25, Batch 118/119, Loss: 5.392420247906578\n",
      "Epoch 18/25, Batch 119/119, Loss: 7.939831154942715\n",
      "Epoch 18/25, Batch 120/119, Loss: 7.861783880689029\n",
      "Epoch 19/25, Batch 1/119, Loss: 6.269231800566589\n",
      "Epoch 19/25, Batch 2/119, Loss: 7.089361630120701\n",
      "Epoch 19/25, Batch 3/119, Loss: 6.167483957610073\n",
      "Epoch 19/25, Batch 4/119, Loss: 9.192951734235159\n",
      "Epoch 19/25, Batch 5/119, Loss: 5.781219061757081\n",
      "Epoch 19/25, Batch 6/119, Loss: 7.632013846778008\n",
      "Epoch 19/25, Batch 7/119, Loss: 7.867006314021274\n",
      "Epoch 19/25, Batch 8/119, Loss: 11.221543449935776\n",
      "Epoch 19/25, Batch 9/119, Loss: 5.343893275603114\n",
      "Epoch 19/25, Batch 10/119, Loss: 10.024094917567744\n",
      "Epoch 19/25, Batch 11/119, Loss: 7.083931485745062\n",
      "Epoch 19/25, Batch 12/119, Loss: 6.3492956637372435\n",
      "Epoch 19/25, Batch 13/119, Loss: 8.900469539238744\n",
      "Epoch 19/25, Batch 14/119, Loss: 10.374889701178269\n",
      "Epoch 19/25, Batch 15/119, Loss: 8.715211528341243\n",
      "Epoch 19/25, Batch 16/119, Loss: 6.06158064485833\n",
      "Epoch 19/25, Batch 17/119, Loss: 7.262171913600651\n",
      "Epoch 19/25, Batch 18/119, Loss: 7.336426833215273\n",
      "Epoch 19/25, Batch 19/119, Loss: 8.36553290584589\n",
      "Epoch 19/25, Batch 20/119, Loss: 5.810157047759685\n",
      "Epoch 19/25, Batch 21/119, Loss: 5.021985533153475\n",
      "Epoch 19/25, Batch 22/119, Loss: 7.929629295834903\n",
      "Epoch 19/25, Batch 23/119, Loss: 8.115053497672868\n",
      "Epoch 19/25, Batch 24/119, Loss: 6.765806606526211\n",
      "Epoch 19/25, Batch 25/119, Loss: 8.315689263397214\n",
      "Epoch 19/25, Batch 26/119, Loss: 8.47626802279284\n",
      "Epoch 19/25, Batch 27/119, Loss: 5.050217669979327\n",
      "Epoch 19/25, Batch 28/119, Loss: 7.6208626748410095\n",
      "Epoch 19/25, Batch 29/119, Loss: 4.961787671882505\n",
      "Epoch 19/25, Batch 30/119, Loss: 9.907056747697894\n",
      "Epoch 19/25, Batch 31/119, Loss: 9.657536345257355\n",
      "Epoch 19/25, Batch 32/119, Loss: 6.065838676043048\n",
      "Epoch 19/25, Batch 33/119, Loss: 7.9697664458602295\n",
      "Epoch 19/25, Batch 34/119, Loss: 7.74156595888332\n",
      "Epoch 19/25, Batch 35/119, Loss: 9.257503264053941\n",
      "Epoch 19/25, Batch 36/119, Loss: 5.863042261430576\n",
      "Epoch 19/25, Batch 37/119, Loss: 5.56591366698271\n",
      "Epoch 19/25, Batch 38/119, Loss: 5.708119807484245\n",
      "Epoch 19/25, Batch 39/119, Loss: 6.601771457733896\n",
      "Epoch 19/25, Batch 40/119, Loss: 10.727892887745432\n",
      "Epoch 19/25, Batch 41/119, Loss: 8.250204324372598\n",
      "Epoch 19/25, Batch 42/119, Loss: 5.680206735012796\n",
      "Epoch 19/25, Batch 43/119, Loss: 7.319728020795423\n",
      "Epoch 19/25, Batch 44/119, Loss: 6.812531388897503\n",
      "Epoch 19/25, Batch 45/119, Loss: 9.441321313887075\n",
      "Epoch 19/25, Batch 46/119, Loss: 4.88303832460284\n",
      "Epoch 19/25, Batch 47/119, Loss: 8.141142493813051\n",
      "Epoch 19/25, Batch 48/119, Loss: 7.4331350840087875\n",
      "Epoch 19/25, Batch 49/119, Loss: 6.60462869762993\n",
      "Epoch 19/25, Batch 50/119, Loss: 9.734060832435382\n",
      "Epoch 19/25, Batch 51/119, Loss: 7.289480156849998\n",
      "Epoch 19/25, Batch 52/119, Loss: 8.580775185055979\n",
      "Epoch 19/25, Batch 53/119, Loss: 8.113202440819252\n",
      "Epoch 19/25, Batch 54/119, Loss: 7.164045643404075\n",
      "Epoch 19/25, Batch 55/119, Loss: 6.9871235499176025\n",
      "Epoch 19/25, Batch 56/119, Loss: 7.665592889140329\n",
      "Epoch 19/25, Batch 57/119, Loss: 5.339974248980632\n",
      "Epoch 19/25, Batch 58/119, Loss: 7.146243214185512\n",
      "Epoch 19/25, Batch 59/119, Loss: 9.111661852096082\n",
      "Epoch 19/25, Batch 60/119, Loss: 7.235523488556413\n",
      "Epoch 19/25, Batch 61/119, Loss: 8.574653343324533\n",
      "Epoch 19/25, Batch 62/119, Loss: 8.699611161062224\n",
      "Epoch 19/25, Batch 63/119, Loss: 6.377408770028052\n",
      "Epoch 19/25, Batch 64/119, Loss: 6.513373754646599\n",
      "Epoch 19/25, Batch 65/119, Loss: 6.257157467242586\n",
      "Epoch 19/25, Batch 66/119, Loss: 7.661118424654882\n",
      "Epoch 19/25, Batch 67/119, Loss: 5.788426175675105\n",
      "Epoch 19/25, Batch 68/119, Loss: 8.078390984589893\n",
      "Epoch 19/25, Batch 69/119, Loss: 9.816363119075383\n",
      "Epoch 19/25, Batch 70/119, Loss: 7.544949185967685\n",
      "Epoch 19/25, Batch 71/119, Loss: 6.701911577982152\n",
      "Epoch 19/25, Batch 72/119, Loss: 8.223744337691935\n",
      "Epoch 19/25, Batch 73/119, Loss: 5.295396016239208\n",
      "Epoch 19/25, Batch 74/119, Loss: 6.742513374882105\n",
      "Epoch 19/25, Batch 75/119, Loss: 5.925225877966284\n",
      "Epoch 19/25, Batch 76/119, Loss: 10.215152910562058\n",
      "Epoch 19/25, Batch 77/119, Loss: 7.978216022676778\n",
      "Epoch 19/25, Batch 78/119, Loss: 5.103342840671835\n",
      "Epoch 19/25, Batch 79/119, Loss: 5.493259486838703\n",
      "Epoch 19/25, Batch 80/119, Loss: 7.066055575687673\n",
      "Epoch 19/25, Batch 81/119, Loss: 6.049582040529765\n",
      "Epoch 19/25, Batch 82/119, Loss: 7.686509749605491\n",
      "Epoch 19/25, Batch 83/119, Loss: 7.546019326390308\n",
      "Epoch 19/25, Batch 84/119, Loss: 5.582206044789406\n",
      "Epoch 19/25, Batch 85/119, Loss: 11.104530776731167\n",
      "Epoch 19/25, Batch 86/119, Loss: 5.989948950280835\n",
      "Epoch 19/25, Batch 87/119, Loss: 4.332317831784647\n",
      "Epoch 19/25, Batch 88/119, Loss: 9.005267375723854\n",
      "Epoch 19/25, Batch 89/119, Loss: 6.162391498715958\n",
      "Epoch 19/25, Batch 90/119, Loss: 8.798754231560146\n",
      "Epoch 19/25, Batch 91/119, Loss: 6.275444969963182\n",
      "Epoch 19/25, Batch 92/119, Loss: 6.315353614324056\n",
      "Epoch 19/25, Batch 93/119, Loss: 6.687848455569355\n",
      "Epoch 19/25, Batch 94/119, Loss: 7.714273688757795\n",
      "Epoch 19/25, Batch 95/119, Loss: 5.5058678893712365\n",
      "Epoch 19/25, Batch 96/119, Loss: 8.056779657331443\n",
      "Epoch 19/25, Batch 97/119, Loss: 8.914630156614459\n",
      "Epoch 19/25, Batch 98/119, Loss: 6.544938381118684\n",
      "Epoch 19/25, Batch 99/119, Loss: 6.759559605748204\n",
      "Epoch 19/25, Batch 100/119, Loss: 7.490497193285966\n",
      "Epoch 19/25, Batch 101/119, Loss: 7.883635352776726\n",
      "Epoch 19/25, Batch 102/119, Loss: 6.956842298227587\n",
      "Epoch 19/25, Batch 103/119, Loss: 9.74275814996242\n",
      "Epoch 19/25, Batch 104/119, Loss: 7.607437844114105\n",
      "Epoch 19/25, Batch 105/119, Loss: 7.1019234828100055\n",
      "Epoch 19/25, Batch 106/119, Loss: 6.772495688157014\n",
      "Epoch 19/25, Batch 107/119, Loss: 7.574235252140125\n",
      "Epoch 19/25, Batch 108/119, Loss: 4.603919717705679\n",
      "Epoch 19/25, Batch 109/119, Loss: 7.163495011974001\n",
      "Epoch 19/25, Batch 110/119, Loss: 8.297926235507576\n",
      "Epoch 19/25, Batch 111/119, Loss: 8.013231246298703\n",
      "Epoch 19/25, Batch 112/119, Loss: 8.731978729582321\n",
      "Epoch 19/25, Batch 113/119, Loss: 7.126581968776445\n",
      "Epoch 19/25, Batch 114/119, Loss: 8.236034371250533\n",
      "Epoch 19/25, Batch 115/119, Loss: 7.288632337459621\n",
      "Epoch 19/25, Batch 116/119, Loss: 7.880500861715544\n",
      "Epoch 19/25, Batch 117/119, Loss: 7.590813184611398\n",
      "Epoch 19/25, Batch 118/119, Loss: 8.426643354579358\n",
      "Epoch 19/25, Batch 119/119, Loss: 6.271694614564901\n",
      "Epoch 19/25, Batch 120/119, Loss: 8.94837397508093\n",
      "Epoch 20/25, Batch 1/119, Loss: 7.631572447547558\n",
      "Epoch 20/25, Batch 2/119, Loss: 8.627818966562288\n",
      "Epoch 20/25, Batch 3/119, Loss: 5.752889322168054\n",
      "Epoch 20/25, Batch 4/119, Loss: 9.419819134926575\n",
      "Epoch 20/25, Batch 5/119, Loss: 4.058042800403609\n",
      "Epoch 20/25, Batch 6/119, Loss: 5.982894270774576\n",
      "Epoch 20/25, Batch 7/119, Loss: 6.334406762326825\n",
      "Epoch 20/25, Batch 8/119, Loss: 5.270444788946612\n",
      "Epoch 20/25, Batch 9/119, Loss: 6.484752417063575\n",
      "Epoch 20/25, Batch 10/119, Loss: 5.121010583755807\n",
      "Epoch 20/25, Batch 11/119, Loss: 7.658723809080569\n",
      "Epoch 20/25, Batch 12/119, Loss: 7.7049724375001585\n",
      "Epoch 20/25, Batch 13/119, Loss: 6.195669352302147\n",
      "Epoch 20/25, Batch 14/119, Loss: 6.034943385350146\n",
      "Epoch 20/25, Batch 15/119, Loss: 7.960137558471311\n",
      "Epoch 20/25, Batch 16/119, Loss: 4.737596265737777\n",
      "Epoch 20/25, Batch 17/119, Loss: 9.516470755292266\n",
      "Epoch 20/25, Batch 18/119, Loss: 5.8991357635025095\n",
      "Epoch 20/25, Batch 19/119, Loss: 8.101664482329909\n",
      "Epoch 20/25, Batch 20/119, Loss: 7.093660431311352\n",
      "Epoch 20/25, Batch 21/119, Loss: 8.336668181685736\n",
      "Epoch 20/25, Batch 22/119, Loss: 8.004045916090789\n",
      "Epoch 20/25, Batch 23/119, Loss: 9.223258958592687\n",
      "Epoch 20/25, Batch 24/119, Loss: 5.711165566588273\n",
      "Epoch 20/25, Batch 25/119, Loss: 5.979298974558187\n",
      "Epoch 20/25, Batch 26/119, Loss: 9.236378693417967\n",
      "Epoch 20/25, Batch 27/119, Loss: 3.842001535817149\n",
      "Epoch 20/25, Batch 28/119, Loss: 8.211880123000219\n",
      "Epoch 20/25, Batch 29/119, Loss: 6.7916014912024965\n",
      "Epoch 20/25, Batch 30/119, Loss: 6.28368854784808\n",
      "Epoch 20/25, Batch 31/119, Loss: 7.065848142557571\n",
      "Epoch 20/25, Batch 32/119, Loss: 6.01101708694617\n",
      "Epoch 20/25, Batch 33/119, Loss: 9.59005671743086\n",
      "Epoch 20/25, Batch 34/119, Loss: 7.058311926155992\n",
      "Epoch 20/25, Batch 35/119, Loss: 7.706733300955262\n",
      "Epoch 20/25, Batch 36/119, Loss: 7.916064353763049\n",
      "Epoch 20/25, Batch 37/119, Loss: 7.463127064845265\n",
      "Epoch 20/25, Batch 38/119, Loss: 6.088883097331442\n",
      "Epoch 20/25, Batch 39/119, Loss: 8.92763056756761\n",
      "Epoch 20/25, Batch 40/119, Loss: 6.580740793262586\n",
      "Epoch 20/25, Batch 41/119, Loss: 8.700808879980475\n",
      "Epoch 20/25, Batch 42/119, Loss: 8.966062057143304\n",
      "Epoch 20/25, Batch 43/119, Loss: 8.775858588963237\n",
      "Epoch 20/25, Batch 44/119, Loss: 8.559834011429157\n",
      "Epoch 20/25, Batch 45/119, Loss: 8.16835522932259\n",
      "Epoch 20/25, Batch 46/119, Loss: 6.863313621645248\n",
      "Epoch 20/25, Batch 47/119, Loss: 5.821377578981193\n",
      "Epoch 20/25, Batch 48/119, Loss: 7.212219955504278\n",
      "Epoch 20/25, Batch 49/119, Loss: 7.588993455567148\n",
      "Epoch 20/25, Batch 50/119, Loss: 6.860514767038181\n",
      "Epoch 20/25, Batch 51/119, Loss: 7.106527312520845\n",
      "Epoch 20/25, Batch 52/119, Loss: 9.560383170659382\n",
      "Epoch 20/25, Batch 53/119, Loss: 4.403070449863492\n",
      "Epoch 20/25, Batch 54/119, Loss: 6.2942061694292635\n",
      "Epoch 20/25, Batch 55/119, Loss: 9.053135059862473\n",
      "Epoch 20/25, Batch 56/119, Loss: 8.688312816591573\n",
      "Epoch 20/25, Batch 57/119, Loss: 4.738414591947234\n",
      "Epoch 20/25, Batch 58/119, Loss: 5.295196121497449\n",
      "Epoch 20/25, Batch 59/119, Loss: 8.335837855481662\n",
      "Epoch 20/25, Batch 60/119, Loss: 5.513916203797723\n",
      "Epoch 20/25, Batch 61/119, Loss: 7.80464913729727\n",
      "Epoch 20/25, Batch 62/119, Loss: 5.335515125772559\n",
      "Epoch 20/25, Batch 63/119, Loss: 5.8300678699184365\n",
      "Epoch 20/25, Batch 64/119, Loss: 6.3323871504499305\n",
      "Epoch 20/25, Batch 65/119, Loss: 4.857953713815603\n",
      "Epoch 20/25, Batch 66/119, Loss: 7.8908961235668205\n",
      "Epoch 20/25, Batch 67/119, Loss: 8.417056780052741\n",
      "Epoch 20/25, Batch 68/119, Loss: 6.262931204977257\n",
      "Epoch 20/25, Batch 69/119, Loss: 7.4049762726836255\n",
      "Epoch 20/25, Batch 70/119, Loss: 9.705360894301988\n",
      "Epoch 20/25, Batch 71/119, Loss: 6.893043632176806\n",
      "Epoch 20/25, Batch 72/119, Loss: 6.186856411969213\n",
      "Epoch 20/25, Batch 73/119, Loss: 7.925313053848315\n",
      "Epoch 20/25, Batch 74/119, Loss: 7.535017354634534\n",
      "Epoch 20/25, Batch 75/119, Loss: 7.1686003783968095\n",
      "Epoch 20/25, Batch 76/119, Loss: 9.130828409898783\n",
      "Epoch 20/25, Batch 77/119, Loss: 7.950516226564269\n",
      "Epoch 20/25, Batch 78/119, Loss: 9.178122017645773\n",
      "Epoch 20/25, Batch 79/119, Loss: 10.64988943627095\n",
      "Epoch 20/25, Batch 80/119, Loss: 8.186826953441859\n",
      "Epoch 20/25, Batch 81/119, Loss: 8.177588498028106\n",
      "Epoch 20/25, Batch 82/119, Loss: 9.910462134200264\n",
      "Epoch 20/25, Batch 83/119, Loss: 6.086907487493347\n",
      "Epoch 20/25, Batch 84/119, Loss: 5.8505348789130505\n",
      "Epoch 20/25, Batch 85/119, Loss: 6.790532520139723\n",
      "Epoch 20/25, Batch 86/119, Loss: 5.301410950989731\n",
      "Epoch 20/25, Batch 87/119, Loss: 5.734094148196188\n",
      "Epoch 20/25, Batch 88/119, Loss: 5.244718034704712\n",
      "Epoch 20/25, Batch 89/119, Loss: 6.670519766585799\n",
      "Epoch 20/25, Batch 90/119, Loss: 8.538691804126145\n",
      "Epoch 20/25, Batch 91/119, Loss: 5.606839093250866\n",
      "Epoch 20/25, Batch 92/119, Loss: 8.567025817953029\n",
      "Epoch 20/25, Batch 93/119, Loss: 8.983471289914842\n",
      "Epoch 20/25, Batch 94/119, Loss: 9.820000763138626\n",
      "Epoch 20/25, Batch 95/119, Loss: 6.506589968617598\n",
      "Epoch 20/25, Batch 96/119, Loss: 9.058972342184601\n",
      "Epoch 20/25, Batch 97/119, Loss: 8.482336316583565\n",
      "Epoch 20/25, Batch 98/119, Loss: 6.532557319084933\n",
      "Epoch 20/25, Batch 99/119, Loss: 5.597424620501304\n",
      "Epoch 20/25, Batch 100/119, Loss: 6.277773273098851\n",
      "Epoch 20/25, Batch 101/119, Loss: 8.922288752935515\n",
      "Epoch 20/25, Batch 102/119, Loss: 4.830078193068429\n",
      "Epoch 20/25, Batch 103/119, Loss: 5.067950542169736\n",
      "Epoch 20/25, Batch 104/119, Loss: 6.88260474021797\n",
      "Epoch 20/25, Batch 105/119, Loss: 5.810253306813574\n",
      "Epoch 20/25, Batch 106/119, Loss: 7.2183201763465465\n",
      "Epoch 20/25, Batch 107/119, Loss: 6.846818030143483\n",
      "Epoch 20/25, Batch 108/119, Loss: 10.407916130926099\n",
      "Epoch 20/25, Batch 109/119, Loss: 7.966262329496382\n",
      "Epoch 20/25, Batch 110/119, Loss: 7.617480892179687\n",
      "Epoch 20/25, Batch 111/119, Loss: 8.657546259439089\n",
      "Epoch 20/25, Batch 112/119, Loss: 7.332291234443272\n",
      "Epoch 20/25, Batch 113/119, Loss: 8.52414507411526\n",
      "Epoch 20/25, Batch 114/119, Loss: 5.145044127687698\n",
      "Epoch 20/25, Batch 115/119, Loss: 6.296367128139183\n",
      "Epoch 20/25, Batch 116/119, Loss: 6.037187538496431\n",
      "Epoch 20/25, Batch 117/119, Loss: 9.939375149740949\n",
      "Epoch 20/25, Batch 118/119, Loss: 7.8847936592697305\n",
      "Epoch 20/25, Batch 119/119, Loss: 8.297540459240354\n",
      "Epoch 20/25, Batch 120/119, Loss: 5.739507642310147\n",
      "Epoch 21/25, Batch 1/119, Loss: 6.067652170707979\n",
      "Epoch 21/25, Batch 2/119, Loss: 7.817699646402424\n",
      "Epoch 21/25, Batch 3/119, Loss: 4.093868630111122\n",
      "Epoch 21/25, Batch 4/119, Loss: 10.013437509287217\n",
      "Epoch 21/25, Batch 5/119, Loss: 7.2961457995202315\n",
      "Epoch 21/25, Batch 6/119, Loss: 5.714068341557091\n",
      "Epoch 21/25, Batch 7/119, Loss: 8.867838063374762\n",
      "Epoch 21/25, Batch 8/119, Loss: 5.04339513314082\n",
      "Epoch 21/25, Batch 9/119, Loss: 8.050257471128393\n",
      "Epoch 21/25, Batch 10/119, Loss: 7.624572900998396\n",
      "Epoch 21/25, Batch 11/119, Loss: 8.698948806433949\n",
      "Epoch 21/25, Batch 12/119, Loss: 5.283017278661291\n",
      "Epoch 21/25, Batch 13/119, Loss: 9.085527772310947\n",
      "Epoch 21/25, Batch 14/119, Loss: 8.11673873126272\n",
      "Epoch 21/25, Batch 15/119, Loss: 8.075832297974008\n",
      "Epoch 21/25, Batch 16/119, Loss: 9.567666499717147\n",
      "Epoch 21/25, Batch 17/119, Loss: 4.305785460174571\n",
      "Epoch 21/25, Batch 18/119, Loss: 6.489546118645998\n",
      "Epoch 21/25, Batch 19/119, Loss: 7.712724632495944\n",
      "Epoch 21/25, Batch 20/119, Loss: 6.323366380204925\n",
      "Epoch 21/25, Batch 21/119, Loss: 8.218523968494686\n",
      "Epoch 21/25, Batch 22/119, Loss: 6.608832024819853\n",
      "Epoch 21/25, Batch 23/119, Loss: 9.23915652753028\n",
      "Epoch 21/25, Batch 24/119, Loss: 7.887400727371087\n",
      "Epoch 21/25, Batch 25/119, Loss: 7.324983990855394\n",
      "Epoch 21/25, Batch 26/119, Loss: 7.723022671177995\n",
      "Epoch 21/25, Batch 27/119, Loss: 6.813316230402557\n",
      "Epoch 21/25, Batch 28/119, Loss: 10.429625138406697\n",
      "Epoch 21/25, Batch 29/119, Loss: 7.823292301511431\n",
      "Epoch 21/25, Batch 30/119, Loss: 9.040098954861577\n",
      "Epoch 21/25, Batch 31/119, Loss: 7.597506802874906\n",
      "Epoch 21/25, Batch 32/119, Loss: 7.8601099861941455\n",
      "Epoch 21/25, Batch 33/119, Loss: 7.69373634405425\n",
      "Epoch 21/25, Batch 34/119, Loss: 4.9206209960408644\n",
      "Epoch 21/25, Batch 35/119, Loss: 6.514852675094931\n",
      "Epoch 21/25, Batch 36/119, Loss: 5.415773296045657\n",
      "Epoch 21/25, Batch 37/119, Loss: 7.272173138760303\n",
      "Epoch 21/25, Batch 38/119, Loss: 7.98642474823757\n",
      "Epoch 21/25, Batch 39/119, Loss: 8.852799083884149\n",
      "Epoch 21/25, Batch 40/119, Loss: 7.808221656595278\n",
      "Epoch 21/25, Batch 41/119, Loss: 7.4733058340645435\n",
      "Epoch 21/25, Batch 42/119, Loss: 9.136559636507355\n",
      "Epoch 21/25, Batch 43/119, Loss: 6.258514233838092\n",
      "Epoch 21/25, Batch 44/119, Loss: 8.19105928959649\n",
      "Epoch 21/25, Batch 45/119, Loss: 7.9561778661647455\n",
      "Epoch 21/25, Batch 46/119, Loss: 7.946789137035091\n",
      "Epoch 21/25, Batch 47/119, Loss: 6.289677386990313\n",
      "Epoch 21/25, Batch 48/119, Loss: 8.872995209005477\n",
      "Epoch 21/25, Batch 49/119, Loss: 7.870434117278908\n",
      "Epoch 21/25, Batch 50/119, Loss: 8.829886019575591\n",
      "Epoch 21/25, Batch 51/119, Loss: 8.801104056720549\n",
      "Epoch 21/25, Batch 52/119, Loss: 8.566863336998447\n",
      "Epoch 21/25, Batch 53/119, Loss: 7.792420131603926\n",
      "Epoch 21/25, Batch 54/119, Loss: 7.885301823126815\n",
      "Epoch 21/25, Batch 55/119, Loss: 8.356844429406571\n",
      "Epoch 21/25, Batch 56/119, Loss: 7.170178191174795\n",
      "Epoch 21/25, Batch 57/119, Loss: 9.501630805375907\n",
      "Epoch 21/25, Batch 58/119, Loss: 9.533249575913416\n",
      "Epoch 21/25, Batch 59/119, Loss: 4.855999082573205\n",
      "Epoch 21/25, Batch 60/119, Loss: 5.747689167585601\n",
      "Epoch 21/25, Batch 61/119, Loss: 8.94074087376661\n",
      "Epoch 21/25, Batch 62/119, Loss: 5.066583014885057\n",
      "Epoch 21/25, Batch 63/119, Loss: 7.660246015651214\n",
      "Epoch 21/25, Batch 64/119, Loss: 5.853428980580489\n",
      "Epoch 21/25, Batch 65/119, Loss: 8.427472278662714\n",
      "Epoch 21/25, Batch 66/119, Loss: 7.754683433194401\n",
      "Epoch 21/25, Batch 67/119, Loss: 4.737139727433211\n",
      "Epoch 21/25, Batch 68/119, Loss: 6.782802275693228\n",
      "Epoch 21/25, Batch 69/119, Loss: 10.0574284566393\n",
      "Epoch 21/25, Batch 70/119, Loss: 8.007954917313405\n",
      "Epoch 21/25, Batch 71/119, Loss: 11.013901067586493\n",
      "Epoch 21/25, Batch 72/119, Loss: 6.682203255620986\n",
      "Epoch 21/25, Batch 73/119, Loss: 8.565493171656778\n",
      "Epoch 21/25, Batch 74/119, Loss: 6.799553763970517\n",
      "Epoch 21/25, Batch 75/119, Loss: 9.12577098153139\n",
      "Epoch 21/25, Batch 76/119, Loss: 7.123038189519263\n",
      "Epoch 21/25, Batch 77/119, Loss: 4.875969743260059\n",
      "Epoch 21/25, Batch 78/119, Loss: 6.617466130219108\n",
      "Epoch 21/25, Batch 79/119, Loss: 9.28150848077884\n",
      "Epoch 21/25, Batch 80/119, Loss: 9.023829091698891\n",
      "Epoch 21/25, Batch 81/119, Loss: 10.149221401461547\n",
      "Epoch 21/25, Batch 82/119, Loss: 9.022472162886936\n",
      "Epoch 21/25, Batch 83/119, Loss: 7.908663238201109\n",
      "Epoch 21/25, Batch 84/119, Loss: 10.091466454459615\n",
      "Epoch 21/25, Batch 85/119, Loss: 7.107814670509676\n",
      "Epoch 21/25, Batch 86/119, Loss: 5.85176870365543\n",
      "Epoch 21/25, Batch 87/119, Loss: 8.914835175144908\n",
      "Epoch 21/25, Batch 88/119, Loss: 8.7675543609413\n",
      "Epoch 21/25, Batch 89/119, Loss: 10.275165180803077\n",
      "Epoch 21/25, Batch 90/119, Loss: 7.054026156164239\n",
      "Epoch 21/25, Batch 91/119, Loss: 7.372790304487773\n",
      "Epoch 21/25, Batch 92/119, Loss: 9.783233896710499\n",
      "Epoch 21/25, Batch 93/119, Loss: 7.25747600399596\n",
      "Epoch 21/25, Batch 94/119, Loss: 7.415972066218166\n",
      "Epoch 21/25, Batch 95/119, Loss: 5.948245345826478\n",
      "Epoch 21/25, Batch 96/119, Loss: 9.541469602322769\n",
      "Epoch 21/25, Batch 97/119, Loss: 6.9560518198435215\n",
      "Epoch 21/25, Batch 98/119, Loss: 7.834709945299832\n",
      "Epoch 21/25, Batch 99/119, Loss: 6.653754381839807\n",
      "Epoch 21/25, Batch 100/119, Loss: 5.171335992841123\n",
      "Epoch 21/25, Batch 101/119, Loss: 9.042537528147554\n",
      "Epoch 21/25, Batch 102/119, Loss: 9.762906208282578\n",
      "Epoch 21/25, Batch 103/119, Loss: 10.430870957176204\n",
      "Epoch 21/25, Batch 104/119, Loss: 5.002090073180863\n",
      "Epoch 21/25, Batch 105/119, Loss: 8.600331441814784\n",
      "Epoch 21/25, Batch 106/119, Loss: 6.31572326079022\n",
      "Epoch 21/25, Batch 107/119, Loss: 6.526354764914946\n",
      "Epoch 21/25, Batch 108/119, Loss: 9.510656254693576\n",
      "Epoch 21/25, Batch 109/119, Loss: 10.330265908525005\n",
      "Epoch 21/25, Batch 110/119, Loss: 7.556472254531111\n",
      "Epoch 21/25, Batch 111/119, Loss: 4.06128065164444\n",
      "Epoch 21/25, Batch 112/119, Loss: 9.660192322318427\n",
      "Epoch 21/25, Batch 113/119, Loss: 6.624027444895221\n",
      "Epoch 21/25, Batch 114/119, Loss: 6.889721683926447\n",
      "Epoch 21/25, Batch 115/119, Loss: 7.453767186359324\n",
      "Epoch 21/25, Batch 116/119, Loss: 4.934016000780197\n",
      "Epoch 21/25, Batch 117/119, Loss: 8.378890741242996\n",
      "Epoch 21/25, Batch 118/119, Loss: 6.103601478851782\n",
      "Epoch 21/25, Batch 119/119, Loss: 6.176553471189194\n",
      "Epoch 21/25, Batch 120/119, Loss: 6.590238359885069\n",
      "Epoch 22/25, Batch 1/119, Loss: 10.21788371210984\n",
      "Epoch 22/25, Batch 2/119, Loss: 6.149137471051517\n",
      "Epoch 22/25, Batch 3/119, Loss: 5.785883647754392\n",
      "Epoch 22/25, Batch 4/119, Loss: 5.062919184781044\n",
      "Epoch 22/25, Batch 5/119, Loss: 5.491966044995683\n",
      "Epoch 22/25, Batch 6/119, Loss: 7.976923775171344\n",
      "Epoch 22/25, Batch 7/119, Loss: 7.540315002706737\n",
      "Epoch 22/25, Batch 8/119, Loss: 8.724310052813095\n",
      "Epoch 22/25, Batch 9/119, Loss: 6.029714733374402\n",
      "Epoch 22/25, Batch 10/119, Loss: 7.004287821453248\n",
      "Epoch 22/25, Batch 11/119, Loss: 8.850301636281282\n",
      "Epoch 22/25, Batch 12/119, Loss: 8.324640816352192\n",
      "Epoch 22/25, Batch 13/119, Loss: 8.98882387828557\n",
      "Epoch 22/25, Batch 14/119, Loss: 6.846743360873204\n",
      "Epoch 22/25, Batch 15/119, Loss: 10.01395769098206\n",
      "Epoch 22/25, Batch 16/119, Loss: 8.30570264728556\n",
      "Epoch 22/25, Batch 17/119, Loss: 7.017241192172573\n",
      "Epoch 22/25, Batch 18/119, Loss: 6.557840966172902\n",
      "Epoch 22/25, Batch 19/119, Loss: 7.722696854858694\n",
      "Epoch 22/25, Batch 20/119, Loss: 9.138309750917427\n",
      "Epoch 22/25, Batch 21/119, Loss: 9.244252707812661\n",
      "Epoch 22/25, Batch 22/119, Loss: 5.566061513081101\n",
      "Epoch 22/25, Batch 23/119, Loss: 7.050987768538333\n",
      "Epoch 22/25, Batch 24/119, Loss: 6.845925576455328\n",
      "Epoch 22/25, Batch 25/119, Loss: 7.6613762638194585\n",
      "Epoch 22/25, Batch 26/119, Loss: 5.116234669331654\n",
      "Epoch 22/25, Batch 27/119, Loss: 9.434965440167458\n",
      "Epoch 22/25, Batch 28/119, Loss: 4.741721175623115\n",
      "Epoch 22/25, Batch 29/119, Loss: 7.407513046696826\n",
      "Epoch 22/25, Batch 30/119, Loss: 6.5789739972927705\n",
      "Epoch 22/25, Batch 31/119, Loss: 8.192701845389\n",
      "Epoch 22/25, Batch 32/119, Loss: 6.031305689900999\n",
      "Epoch 22/25, Batch 33/119, Loss: 9.173987249551475\n",
      "Epoch 22/25, Batch 34/119, Loss: 8.74279158901215\n",
      "Epoch 22/25, Batch 35/119, Loss: 6.75797959121026\n",
      "Epoch 22/25, Batch 36/119, Loss: 8.025386909541586\n",
      "Epoch 22/25, Batch 37/119, Loss: 8.065215067716611\n",
      "Epoch 22/25, Batch 38/119, Loss: 6.864455595665537\n",
      "Epoch 22/25, Batch 39/119, Loss: 7.9236350706846785\n",
      "Epoch 22/25, Batch 40/119, Loss: 6.92730175822508\n",
      "Epoch 22/25, Batch 41/119, Loss: 7.216185993012448\n",
      "Epoch 22/25, Batch 42/119, Loss: 7.242748134207701\n",
      "Epoch 22/25, Batch 43/119, Loss: 7.075801126854988\n",
      "Epoch 22/25, Batch 44/119, Loss: 4.804423787792889\n",
      "Epoch 22/25, Batch 45/119, Loss: 9.820672038032146\n",
      "Epoch 22/25, Batch 46/119, Loss: 8.214250964556518\n",
      "Epoch 22/25, Batch 47/119, Loss: 7.797418013998347\n",
      "Epoch 22/25, Batch 48/119, Loss: 7.321293058629516\n",
      "Epoch 22/25, Batch 49/119, Loss: 8.123466269139357\n",
      "Epoch 22/25, Batch 50/119, Loss: 9.308862656490932\n",
      "Epoch 22/25, Batch 51/119, Loss: 9.732506508935668\n",
      "Epoch 22/25, Batch 52/119, Loss: 4.953101505585438\n",
      "Epoch 22/25, Batch 53/119, Loss: 4.987747162595295\n",
      "Epoch 22/25, Batch 54/119, Loss: 6.445502425066921\n",
      "Epoch 22/25, Batch 55/119, Loss: 8.702245120813378\n",
      "Epoch 22/25, Batch 56/119, Loss: 4.469546910291634\n",
      "Epoch 22/25, Batch 57/119, Loss: 8.694009462587667\n",
      "Epoch 22/25, Batch 58/119, Loss: 7.370864810486262\n",
      "Epoch 22/25, Batch 59/119, Loss: 5.232051851422751\n",
      "Epoch 22/25, Batch 60/119, Loss: 6.172597763656809\n",
      "Epoch 22/25, Batch 61/119, Loss: 6.324682738963783\n",
      "Epoch 22/25, Batch 62/119, Loss: 7.364003678460257\n",
      "Epoch 22/25, Batch 63/119, Loss: 6.805467685781742\n",
      "Epoch 22/25, Batch 64/119, Loss: 6.535445374910483\n",
      "Epoch 22/25, Batch 65/119, Loss: 9.286312493590088\n",
      "Epoch 22/25, Batch 66/119, Loss: 9.520008213825076\n",
      "Epoch 22/25, Batch 67/119, Loss: 9.321742094755384\n",
      "Epoch 22/25, Batch 68/119, Loss: 6.895106392337007\n",
      "Epoch 22/25, Batch 69/119, Loss: 8.02427480988568\n",
      "Epoch 22/25, Batch 70/119, Loss: 8.237714941181082\n",
      "Epoch 22/25, Batch 71/119, Loss: 6.755475574923119\n",
      "Epoch 22/25, Batch 72/119, Loss: 4.419011768008646\n",
      "Epoch 22/25, Batch 73/119, Loss: 5.6923655906478094\n",
      "Epoch 22/25, Batch 74/119, Loss: 6.4997776145984965\n",
      "Epoch 22/25, Batch 75/119, Loss: 8.917320816832996\n",
      "Epoch 22/25, Batch 76/119, Loss: 8.735093378141048\n",
      "Epoch 22/25, Batch 77/119, Loss: 7.831436937505781\n",
      "Epoch 22/25, Batch 78/119, Loss: 8.166632536191834\n",
      "Epoch 22/25, Batch 79/119, Loss: 6.319592700748442\n",
      "Epoch 22/25, Batch 80/119, Loss: 8.332556927636299\n",
      "Epoch 22/25, Batch 81/119, Loss: 8.653875776580433\n",
      "Epoch 22/25, Batch 82/119, Loss: 7.630805661867015\n",
      "Epoch 22/25, Batch 83/119, Loss: 4.703907578335327\n",
      "Epoch 22/25, Batch 84/119, Loss: 8.151666637820574\n",
      "Epoch 22/25, Batch 85/119, Loss: 10.618147769205667\n",
      "Epoch 22/25, Batch 86/119, Loss: 9.365705313079935\n",
      "Epoch 22/25, Batch 87/119, Loss: 7.698969760999754\n",
      "Epoch 22/25, Batch 88/119, Loss: 7.127495730415858\n",
      "Epoch 22/25, Batch 89/119, Loss: 5.547415778276368\n",
      "Epoch 22/25, Batch 90/119, Loss: 8.364473680758234\n",
      "Epoch 22/25, Batch 91/119, Loss: 5.237563126811041\n",
      "Epoch 22/25, Batch 92/119, Loss: 8.241951107081247\n",
      "Epoch 22/25, Batch 93/119, Loss: 6.628278835148399\n",
      "Epoch 22/25, Batch 94/119, Loss: 6.098001906849991\n",
      "Epoch 22/25, Batch 95/119, Loss: 7.798356739421816\n",
      "Epoch 22/25, Batch 96/119, Loss: 7.07635894826173\n",
      "Epoch 22/25, Batch 97/119, Loss: 8.441600879905783\n",
      "Epoch 22/25, Batch 98/119, Loss: 6.768363509899618\n",
      "Epoch 22/25, Batch 99/119, Loss: 4.9619381292611155\n",
      "Epoch 22/25, Batch 100/119, Loss: 7.008609644737153\n",
      "Epoch 22/25, Batch 101/119, Loss: 8.349149406946404\n",
      "Epoch 22/25, Batch 102/119, Loss: 8.409551222223328\n",
      "Epoch 22/25, Batch 103/119, Loss: 9.088873043154056\n",
      "Epoch 22/25, Batch 104/119, Loss: 10.321958654689928\n",
      "Epoch 22/25, Batch 105/119, Loss: 7.375182236910189\n",
      "Epoch 22/25, Batch 106/119, Loss: 8.422904969441307\n",
      "Epoch 22/25, Batch 107/119, Loss: 7.571723515529882\n",
      "Epoch 22/25, Batch 108/119, Loss: 5.575876882924973\n",
      "Epoch 22/25, Batch 109/119, Loss: 7.115444135657656\n",
      "Epoch 22/25, Batch 110/119, Loss: 8.302133766617883\n",
      "Epoch 22/25, Batch 111/119, Loss: 7.56659971021279\n",
      "Epoch 22/25, Batch 112/119, Loss: 8.053206249586204\n",
      "Epoch 22/25, Batch 113/119, Loss: 8.63684421649284\n",
      "Epoch 22/25, Batch 114/119, Loss: 4.238967589931687\n",
      "Epoch 22/25, Batch 115/119, Loss: 6.600968824473621\n",
      "Epoch 22/25, Batch 116/119, Loss: 8.645336477097114\n",
      "Epoch 22/25, Batch 117/119, Loss: 5.761738078575201\n",
      "Epoch 22/25, Batch 118/119, Loss: 8.660468015122756\n",
      "Epoch 22/25, Batch 119/119, Loss: 6.74895375493748\n",
      "Epoch 22/25, Batch 120/119, Loss: 6.890572969369755\n",
      "Epoch 23/25, Batch 1/119, Loss: 7.033832334228959\n",
      "Epoch 23/25, Batch 2/119, Loss: 7.561388552706704\n",
      "Epoch 23/25, Batch 3/119, Loss: 6.789030135958312\n",
      "Epoch 23/25, Batch 4/119, Loss: 8.789607301861187\n",
      "Epoch 23/25, Batch 5/119, Loss: 7.794773223329349\n",
      "Epoch 23/25, Batch 6/119, Loss: 8.601866583187519\n",
      "Epoch 23/25, Batch 7/119, Loss: 6.425238646855819\n",
      "Epoch 23/25, Batch 8/119, Loss: 8.286310254710827\n",
      "Epoch 23/25, Batch 9/119, Loss: 10.029717888685449\n",
      "Epoch 23/25, Batch 10/119, Loss: 8.437763737366593\n",
      "Epoch 23/25, Batch 11/119, Loss: 6.954999578989651\n",
      "Epoch 23/25, Batch 12/119, Loss: 4.367516480864683\n",
      "Epoch 23/25, Batch 13/119, Loss: 5.5652848334485165\n",
      "Epoch 23/25, Batch 14/119, Loss: 7.80900099488077\n",
      "Epoch 23/25, Batch 15/119, Loss: 5.218086202686166\n",
      "Epoch 23/25, Batch 16/119, Loss: 7.925465036680279\n",
      "Epoch 23/25, Batch 17/119, Loss: 4.675132936888129\n",
      "Epoch 23/25, Batch 18/119, Loss: 9.675442277106171\n",
      "Epoch 23/25, Batch 19/119, Loss: 6.029294797708031\n",
      "Epoch 23/25, Batch 20/119, Loss: 3.7165038855873895\n",
      "Epoch 23/25, Batch 21/119, Loss: 7.2796486430991285\n",
      "Epoch 23/25, Batch 22/119, Loss: 9.03912684099082\n",
      "Epoch 23/25, Batch 23/119, Loss: 6.149984693042946\n",
      "Epoch 23/25, Batch 24/119, Loss: 4.947330033685761\n",
      "Epoch 23/25, Batch 25/119, Loss: 4.616056020887978\n",
      "Epoch 23/25, Batch 26/119, Loss: 10.54673117443379\n",
      "Epoch 23/25, Batch 27/119, Loss: 5.8628976538671616\n",
      "Epoch 23/25, Batch 28/119, Loss: 7.116055770245074\n",
      "Epoch 23/25, Batch 29/119, Loss: 9.46037887305077\n",
      "Epoch 23/25, Batch 30/119, Loss: 6.478164063181972\n",
      "Epoch 23/25, Batch 31/119, Loss: 10.330917593765431\n",
      "Epoch 23/25, Batch 32/119, Loss: 6.2622629347163645\n",
      "Epoch 23/25, Batch 33/119, Loss: 6.341394667901463\n",
      "Epoch 23/25, Batch 34/119, Loss: 5.380538568229341\n",
      "Epoch 23/25, Batch 35/119, Loss: 7.32473562550289\n",
      "Epoch 23/25, Batch 36/119, Loss: 7.505222270091498\n",
      "Epoch 23/25, Batch 37/119, Loss: 5.249615609848392\n",
      "Epoch 23/25, Batch 38/119, Loss: 9.726450680254745\n",
      "Epoch 23/25, Batch 39/119, Loss: 9.222346199288777\n",
      "Epoch 23/25, Batch 40/119, Loss: 6.579796375656979\n",
      "Epoch 23/25, Batch 41/119, Loss: 8.870091137563508\n",
      "Epoch 23/25, Batch 42/119, Loss: 7.58437012399331\n",
      "Epoch 23/25, Batch 43/119, Loss: 7.544413351887014\n",
      "Epoch 23/25, Batch 44/119, Loss: 6.676256127765318\n",
      "Epoch 23/25, Batch 45/119, Loss: 9.8739750135728\n",
      "Epoch 23/25, Batch 46/119, Loss: 8.582137774924094\n",
      "Epoch 23/25, Batch 47/119, Loss: 7.065442661204236\n",
      "Epoch 23/25, Batch 48/119, Loss: 6.707900654989128\n",
      "Epoch 23/25, Batch 49/119, Loss: 9.861257772362062\n",
      "Epoch 23/25, Batch 50/119, Loss: 8.12172962508681\n",
      "Epoch 23/25, Batch 51/119, Loss: 8.26282649167769\n",
      "Epoch 23/25, Batch 52/119, Loss: 6.519405737476029\n",
      "Epoch 23/25, Batch 53/119, Loss: 10.07415650902938\n",
      "Epoch 23/25, Batch 54/119, Loss: 7.047738082626531\n",
      "Epoch 23/25, Batch 55/119, Loss: 9.256451749150873\n",
      "Epoch 23/25, Batch 56/119, Loss: 7.661390056108377\n",
      "Epoch 23/25, Batch 57/119, Loss: 4.450138203702611\n",
      "Epoch 23/25, Batch 58/119, Loss: 7.837621051143418\n",
      "Epoch 23/25, Batch 59/119, Loss: 7.259656105880202\n",
      "Epoch 23/25, Batch 60/119, Loss: 6.89756806291345\n",
      "Epoch 23/25, Batch 61/119, Loss: 9.271199943164158\n",
      "Epoch 23/25, Batch 62/119, Loss: 10.114467592561683\n",
      "Epoch 23/25, Batch 63/119, Loss: 9.020455095617972\n",
      "Epoch 23/25, Batch 64/119, Loss: 8.71200590404183\n",
      "Epoch 23/25, Batch 65/119, Loss: 9.543763045886175\n",
      "Epoch 23/25, Batch 66/119, Loss: 7.346005790109496\n",
      "Epoch 23/25, Batch 67/119, Loss: 6.008679584924816\n",
      "Epoch 23/25, Batch 68/119, Loss: 5.556620621363741\n",
      "Epoch 23/25, Batch 69/119, Loss: 6.4005982138989745\n",
      "Epoch 23/25, Batch 70/119, Loss: 10.51701605276791\n",
      "Epoch 23/25, Batch 71/119, Loss: 6.383794622561729\n",
      "Epoch 23/25, Batch 72/119, Loss: 8.31031032364832\n",
      "Epoch 23/25, Batch 73/119, Loss: 6.608205025069218\n",
      "Epoch 23/25, Batch 74/119, Loss: 8.06881068752804\n",
      "Epoch 23/25, Batch 75/119, Loss: 7.176106781973645\n",
      "Epoch 23/25, Batch 76/119, Loss: 4.732165349505685\n",
      "Epoch 23/25, Batch 77/119, Loss: 6.219180281788154\n",
      "Epoch 23/25, Batch 78/119, Loss: 7.007763809688426\n",
      "Epoch 23/25, Batch 79/119, Loss: 8.523037380696644\n",
      "Epoch 23/25, Batch 80/119, Loss: 7.405737551059188\n",
      "Epoch 23/25, Batch 81/119, Loss: 6.896644545100812\n",
      "Epoch 23/25, Batch 82/119, Loss: 8.57030573422844\n",
      "Epoch 23/25, Batch 83/119, Loss: 8.109670725022697\n",
      "Epoch 23/25, Batch 84/119, Loss: 7.260192484598266\n",
      "Epoch 23/25, Batch 85/119, Loss: 7.94715660947315\n",
      "Epoch 23/25, Batch 86/119, Loss: 7.5829698283175535\n",
      "Epoch 23/25, Batch 87/119, Loss: 5.919098967618697\n",
      "Epoch 23/25, Batch 88/119, Loss: 6.002608163844369\n",
      "Epoch 23/25, Batch 89/119, Loss: 6.504823770712814\n",
      "Epoch 23/25, Batch 90/119, Loss: 8.178670184314331\n",
      "Epoch 23/25, Batch 91/119, Loss: 5.261677526474746\n",
      "Epoch 23/25, Batch 92/119, Loss: 4.835234564500621\n",
      "Epoch 23/25, Batch 93/119, Loss: 9.359935953322124\n",
      "Epoch 23/25, Batch 94/119, Loss: 7.904587174058176\n",
      "Epoch 23/25, Batch 95/119, Loss: 8.623464437565517\n",
      "Epoch 23/25, Batch 96/119, Loss: 9.902931955583952\n",
      "Epoch 23/25, Batch 97/119, Loss: 6.576314188715846\n",
      "Epoch 23/25, Batch 98/119, Loss: 5.910604410294738\n",
      "Epoch 23/25, Batch 99/119, Loss: 8.402400900528825\n",
      "Epoch 23/25, Batch 100/119, Loss: 6.7297568185298156\n",
      "Epoch 23/25, Batch 101/119, Loss: 8.338141550665833\n",
      "Epoch 23/25, Batch 102/119, Loss: 8.85398484605572\n",
      "Epoch 23/25, Batch 103/119, Loss: 7.650992220377529\n",
      "Epoch 23/25, Batch 104/119, Loss: 7.296428283668378\n",
      "Epoch 23/25, Batch 105/119, Loss: 8.464813190984481\n",
      "Epoch 23/25, Batch 106/119, Loss: 4.806578034674572\n",
      "Epoch 23/25, Batch 107/119, Loss: 6.801042398002129\n",
      "Epoch 23/25, Batch 108/119, Loss: 7.4051482953042695\n",
      "Epoch 23/25, Batch 109/119, Loss: 5.886604882882688\n",
      "Epoch 23/25, Batch 110/119, Loss: 8.05859805274882\n",
      "Epoch 23/25, Batch 111/119, Loss: 4.4861388373535425\n",
      "Epoch 23/25, Batch 112/119, Loss: 5.779389278009613\n",
      "Epoch 23/25, Batch 113/119, Loss: 5.887709042698051\n",
      "Epoch 23/25, Batch 114/119, Loss: 7.8354308579370615\n",
      "Epoch 23/25, Batch 115/119, Loss: 9.050481212802598\n",
      "Epoch 23/25, Batch 116/119, Loss: 8.99522195479294\n",
      "Epoch 23/25, Batch 117/119, Loss: 5.887813304515857\n",
      "Epoch 23/25, Batch 118/119, Loss: 7.228565407739169\n",
      "Epoch 23/25, Batch 119/119, Loss: 6.774387455593038\n",
      "Epoch 23/25, Batch 120/119, Loss: 6.584589701328144\n",
      "Epoch 24/25, Batch 1/119, Loss: 7.673084754879123\n",
      "Epoch 24/25, Batch 2/119, Loss: 7.20966567807547\n",
      "Epoch 24/25, Batch 3/119, Loss: 6.671235761635375\n",
      "Epoch 24/25, Batch 4/119, Loss: 8.975870855986349\n",
      "Epoch 24/25, Batch 5/119, Loss: 7.433267646801804\n",
      "Epoch 24/25, Batch 6/119, Loss: 9.382562084303984\n",
      "Epoch 24/25, Batch 7/119, Loss: 7.455097884046771\n",
      "Epoch 24/25, Batch 8/119, Loss: 7.41838905571184\n",
      "Epoch 24/25, Batch 9/119, Loss: 6.61112450986933\n",
      "Epoch 24/25, Batch 10/119, Loss: 8.32931617548472\n",
      "Epoch 24/25, Batch 11/119, Loss: 7.279327039623582\n",
      "Epoch 24/25, Batch 12/119, Loss: 6.579322692091568\n",
      "Epoch 24/25, Batch 13/119, Loss: 6.069757176707926\n",
      "Epoch 24/25, Batch 14/119, Loss: 11.352030555942955\n",
      "Epoch 24/25, Batch 15/119, Loss: 6.105482812713871\n",
      "Epoch 24/25, Batch 16/119, Loss: 6.7273713361340155\n",
      "Epoch 24/25, Batch 17/119, Loss: 4.9799192106222945\n",
      "Epoch 24/25, Batch 18/119, Loss: 3.88489716286017\n",
      "Epoch 24/25, Batch 19/119, Loss: 7.108770556147386\n",
      "Epoch 24/25, Batch 20/119, Loss: 6.128885095778983\n",
      "Epoch 24/25, Batch 21/119, Loss: 6.530976381325811\n",
      "Epoch 24/25, Batch 22/119, Loss: 4.834516714293896\n",
      "Epoch 24/25, Batch 23/119, Loss: 7.534735414439101\n",
      "Epoch 24/25, Batch 24/119, Loss: 7.157083155196874\n",
      "Epoch 24/25, Batch 25/119, Loss: 8.698953618004015\n",
      "Epoch 24/25, Batch 26/119, Loss: 5.725277081694812\n",
      "Epoch 24/25, Batch 27/119, Loss: 7.079554233648343\n",
      "Epoch 24/25, Batch 28/119, Loss: 8.384498239031142\n",
      "Epoch 24/25, Batch 29/119, Loss: 11.077596749712994\n",
      "Epoch 24/25, Batch 30/119, Loss: 6.871194486931053\n",
      "Epoch 24/25, Batch 31/119, Loss: 6.440597555541427\n",
      "Epoch 24/25, Batch 32/119, Loss: 8.06717467341468\n",
      "Epoch 24/25, Batch 33/119, Loss: 6.166096272739047\n",
      "Epoch 24/25, Batch 34/119, Loss: 7.844784263852207\n",
      "Epoch 24/25, Batch 35/119, Loss: 7.137084212056828\n",
      "Epoch 24/25, Batch 36/119, Loss: 5.573119077817849\n",
      "Epoch 24/25, Batch 37/119, Loss: 7.108374586789899\n",
      "Epoch 24/25, Batch 38/119, Loss: 8.8500495687215\n",
      "Epoch 24/25, Batch 39/119, Loss: 6.597266891822985\n",
      "Epoch 24/25, Batch 40/119, Loss: 7.140035177608319\n",
      "Epoch 24/25, Batch 41/119, Loss: 9.106306422529247\n",
      "Epoch 24/25, Batch 42/119, Loss: 5.5141082416982465\n",
      "Epoch 24/25, Batch 43/119, Loss: 6.8214057086043995\n",
      "Epoch 24/25, Batch 44/119, Loss: 10.477538670752262\n",
      "Epoch 24/25, Batch 45/119, Loss: 7.594709551748838\n",
      "Epoch 24/25, Batch 46/119, Loss: 6.666172377890247\n",
      "Epoch 24/25, Batch 47/119, Loss: 8.215826586858164\n",
      "Epoch 24/25, Batch 48/119, Loss: 7.950416889002778\n",
      "Epoch 24/25, Batch 49/119, Loss: 8.450052975516346\n",
      "Epoch 24/25, Batch 50/119, Loss: 6.046954202173024\n",
      "Epoch 24/25, Batch 51/119, Loss: 6.750536952767628\n",
      "Epoch 24/25, Batch 52/119, Loss: 8.537881615993927\n",
      "Epoch 24/25, Batch 53/119, Loss: 8.612026049637793\n",
      "Epoch 24/25, Batch 54/119, Loss: 6.43923142238626\n",
      "Epoch 24/25, Batch 55/119, Loss: 8.746208848782697\n",
      "Epoch 24/25, Batch 56/119, Loss: 7.31748364293812\n",
      "Epoch 24/25, Batch 57/119, Loss: 5.787508638251071\n",
      "Epoch 24/25, Batch 58/119, Loss: 8.511008912382215\n",
      "Epoch 24/25, Batch 59/119, Loss: 8.407287511054854\n",
      "Epoch 24/25, Batch 60/119, Loss: 7.280151860276032\n",
      "Epoch 24/25, Batch 61/119, Loss: 6.448590349357502\n",
      "Epoch 24/25, Batch 62/119, Loss: 5.3722274919178945\n",
      "Epoch 24/25, Batch 63/119, Loss: 5.962515641384006\n",
      "Epoch 24/25, Batch 64/119, Loss: 6.782560508445392\n",
      "Epoch 24/25, Batch 65/119, Loss: 7.427986564963906\n",
      "Epoch 24/25, Batch 66/119, Loss: 6.926293406067602\n",
      "Epoch 24/25, Batch 67/119, Loss: 4.570659506850909\n",
      "Epoch 24/25, Batch 68/119, Loss: 9.815581030217974\n",
      "Epoch 24/25, Batch 69/119, Loss: 5.990204420227198\n",
      "Epoch 24/25, Batch 70/119, Loss: 7.053792510545413\n",
      "Epoch 24/25, Batch 71/119, Loss: 10.471596523066792\n",
      "Epoch 24/25, Batch 72/119, Loss: 8.667301495962201\n",
      "Epoch 24/25, Batch 73/119, Loss: 6.9635610541717226\n",
      "Epoch 24/25, Batch 74/119, Loss: 5.861941890178061\n",
      "Epoch 24/25, Batch 75/119, Loss: 6.065351188733839\n",
      "Epoch 24/25, Batch 76/119, Loss: 7.902326144268186\n",
      "Epoch 24/25, Batch 77/119, Loss: 8.304862650059846\n",
      "Epoch 24/25, Batch 78/119, Loss: 6.257944768363748\n",
      "Epoch 24/25, Batch 79/119, Loss: 8.169839575727709\n",
      "Epoch 24/25, Batch 80/119, Loss: 9.140222891476808\n",
      "Epoch 24/25, Batch 81/119, Loss: 8.042648414849399\n",
      "Epoch 24/25, Batch 82/119, Loss: 8.128922194594878\n",
      "Epoch 24/25, Batch 83/119, Loss: 6.811570078231043\n",
      "Epoch 24/25, Batch 84/119, Loss: 5.765143405520149\n",
      "Epoch 24/25, Batch 85/119, Loss: 8.196304001646503\n",
      "Epoch 24/25, Batch 86/119, Loss: 7.931079530679673\n",
      "Epoch 24/25, Batch 87/119, Loss: 6.4661439015182065\n",
      "Epoch 24/25, Batch 88/119, Loss: 5.035502775908145\n",
      "Epoch 24/25, Batch 89/119, Loss: 5.910556343980883\n",
      "Epoch 24/25, Batch 90/119, Loss: 9.793867163096282\n",
      "Epoch 24/25, Batch 91/119, Loss: 7.772400991322561\n",
      "Epoch 24/25, Batch 92/119, Loss: 10.186555201221358\n",
      "Epoch 24/25, Batch 93/119, Loss: 7.987455404451957\n",
      "Epoch 24/25, Batch 94/119, Loss: 5.202752650026888\n",
      "Epoch 24/25, Batch 95/119, Loss: 10.006070747405074\n",
      "Epoch 24/25, Batch 96/119, Loss: 6.714541730207571\n",
      "Epoch 24/25, Batch 97/119, Loss: 8.480347429181597\n",
      "Epoch 24/25, Batch 98/119, Loss: 9.199737123999252\n",
      "Epoch 24/25, Batch 99/119, Loss: 7.805275010825101\n",
      "Epoch 24/25, Batch 100/119, Loss: 7.247547972568607\n",
      "Epoch 24/25, Batch 101/119, Loss: 8.038621512831362\n",
      "Epoch 24/25, Batch 102/119, Loss: 8.835962843623198\n",
      "Epoch 24/25, Batch 103/119, Loss: 4.835809059344122\n",
      "Epoch 24/25, Batch 104/119, Loss: 5.722580723257511\n",
      "Epoch 24/25, Batch 105/119, Loss: 8.810484489130701\n",
      "Epoch 24/25, Batch 106/119, Loss: 11.306108615931054\n",
      "Epoch 24/25, Batch 107/119, Loss: 6.282272338830508\n",
      "Epoch 24/25, Batch 108/119, Loss: 5.710937809907891\n",
      "Epoch 24/25, Batch 109/119, Loss: 10.36847916408344\n",
      "Epoch 24/25, Batch 110/119, Loss: 6.655364493708142\n",
      "Epoch 24/25, Batch 111/119, Loss: 7.584084029100799\n",
      "Epoch 24/25, Batch 112/119, Loss: 8.371766119644825\n",
      "Epoch 24/25, Batch 113/119, Loss: 8.00291082417548\n",
      "Epoch 24/25, Batch 114/119, Loss: 6.872881586497015\n",
      "Epoch 24/25, Batch 115/119, Loss: 7.5021375493784\n",
      "Epoch 24/25, Batch 116/119, Loss: 5.497601029305931\n",
      "Epoch 24/25, Batch 117/119, Loss: 6.801072802028609\n",
      "Epoch 24/25, Batch 118/119, Loss: 5.873256305381529\n",
      "Epoch 24/25, Batch 119/119, Loss: 10.104447357785471\n",
      "Epoch 24/25, Batch 120/119, Loss: 8.7512672645714\n",
      "Epoch 25/25, Batch 1/119, Loss: 9.891907448030436\n",
      "Epoch 25/25, Batch 2/119, Loss: 7.908589133434991\n",
      "Epoch 25/25, Batch 3/119, Loss: 5.471797411913069\n",
      "Epoch 25/25, Batch 4/119, Loss: 6.222193641896066\n",
      "Epoch 25/25, Batch 5/119, Loss: 5.353454281176279\n",
      "Epoch 25/25, Batch 6/119, Loss: 9.849532929563205\n",
      "Epoch 25/25, Batch 7/119, Loss: 7.234188257594598\n",
      "Epoch 25/25, Batch 8/119, Loss: 10.17071420852433\n",
      "Epoch 25/25, Batch 9/119, Loss: 11.346019032770265\n",
      "Epoch 25/25, Batch 10/119, Loss: 8.312592727875804\n",
      "Epoch 25/25, Batch 11/119, Loss: 6.730262044656526\n",
      "Epoch 25/25, Batch 12/119, Loss: 5.4823098661862755\n",
      "Epoch 25/25, Batch 13/119, Loss: 9.38665608194938\n",
      "Epoch 25/25, Batch 14/119, Loss: 4.22860808952659\n",
      "Epoch 25/25, Batch 15/119, Loss: 8.78813095591322\n",
      "Epoch 25/25, Batch 16/119, Loss: 8.537692864692472\n",
      "Epoch 25/25, Batch 17/119, Loss: 6.881984409602429\n",
      "Epoch 25/25, Batch 18/119, Loss: 5.179310595078372\n",
      "Epoch 25/25, Batch 19/119, Loss: 9.865921269345812\n",
      "Epoch 25/25, Batch 20/119, Loss: 5.801620268217503\n",
      "Epoch 25/25, Batch 21/119, Loss: 6.435390265817124\n",
      "Epoch 25/25, Batch 22/119, Loss: 5.709694516399157\n",
      "Epoch 25/25, Batch 23/119, Loss: 6.528739955952113\n",
      "Epoch 25/25, Batch 24/119, Loss: 7.759837725317666\n",
      "Epoch 25/25, Batch 25/119, Loss: 9.668265879712283\n",
      "Epoch 25/25, Batch 26/119, Loss: 7.4418476592071325\n",
      "Epoch 25/25, Batch 27/119, Loss: 8.106726053692002\n",
      "Epoch 25/25, Batch 28/119, Loss: 8.532418713926562\n",
      "Epoch 25/25, Batch 29/119, Loss: 6.807393931362058\n",
      "Epoch 25/25, Batch 30/119, Loss: 6.690150760774904\n",
      "Epoch 25/25, Batch 31/119, Loss: 9.308798570716215\n",
      "Epoch 25/25, Batch 32/119, Loss: 5.377412106005679\n",
      "Epoch 25/25, Batch 33/119, Loss: 5.257121516034571\n",
      "Epoch 25/25, Batch 34/119, Loss: 7.248519442622637\n",
      "Epoch 25/25, Batch 35/119, Loss: 7.961994616874614\n",
      "Epoch 25/25, Batch 36/119, Loss: 5.764794908570737\n",
      "Epoch 25/25, Batch 37/119, Loss: 5.962720462604168\n",
      "Epoch 25/25, Batch 38/119, Loss: 7.494702033320139\n",
      "Epoch 25/25, Batch 39/119, Loss: 9.146151234709416\n",
      "Epoch 25/25, Batch 40/119, Loss: 7.035948322416828\n",
      "Epoch 25/25, Batch 41/119, Loss: 10.30625587842154\n",
      "Epoch 25/25, Batch 42/119, Loss: 7.14305319183003\n",
      "Epoch 25/25, Batch 43/119, Loss: 4.647093942654387\n",
      "Epoch 25/25, Batch 44/119, Loss: 8.81246172904397\n",
      "Epoch 25/25, Batch 45/119, Loss: 5.51036251560079\n",
      "Epoch 25/25, Batch 46/119, Loss: 5.89385727690092\n",
      "Epoch 25/25, Batch 47/119, Loss: 9.531686898224494\n",
      "Epoch 25/25, Batch 48/119, Loss: 9.36781835423099\n",
      "Epoch 25/25, Batch 49/119, Loss: 9.13616941523847\n",
      "Epoch 25/25, Batch 50/119, Loss: 8.259086619675191\n",
      "Epoch 25/25, Batch 51/119, Loss: 5.750114707824686\n",
      "Epoch 25/25, Batch 52/119, Loss: 5.8386646807371125\n",
      "Epoch 25/25, Batch 53/119, Loss: 4.867392995013696\n",
      "Epoch 25/25, Batch 54/119, Loss: 6.855349825401157\n",
      "Epoch 25/25, Batch 55/119, Loss: 5.057141534124651\n",
      "Epoch 25/25, Batch 56/119, Loss: 8.044885534715476\n",
      "Epoch 25/25, Batch 57/119, Loss: 7.766919455548605\n",
      "Epoch 25/25, Batch 58/119, Loss: 7.413049000673276\n",
      "Epoch 25/25, Batch 59/119, Loss: 7.502797764391037\n",
      "Epoch 25/25, Batch 60/119, Loss: 5.860314985206265\n",
      "Epoch 25/25, Batch 61/119, Loss: 4.839368149860932\n",
      "Epoch 25/25, Batch 62/119, Loss: 9.006771314212349\n",
      "Epoch 25/25, Batch 63/119, Loss: 6.7965911929192915\n",
      "Epoch 25/25, Batch 64/119, Loss: 6.0217199582242165\n",
      "Epoch 25/25, Batch 65/119, Loss: 6.720561399482642\n",
      "Epoch 25/25, Batch 66/119, Loss: 8.354052079876531\n",
      "Epoch 25/25, Batch 67/119, Loss: 8.063937507144367\n",
      "Epoch 25/25, Batch 68/119, Loss: 7.226996311327028\n",
      "Epoch 25/25, Batch 69/119, Loss: 8.968565767436912\n",
      "Epoch 25/25, Batch 70/119, Loss: 5.910255516319762\n",
      "Epoch 25/25, Batch 71/119, Loss: 6.2348309290523405\n",
      "Epoch 25/25, Batch 72/119, Loss: 4.505466356524214\n",
      "Epoch 25/25, Batch 73/119, Loss: 6.971172252531106\n",
      "Epoch 25/25, Batch 74/119, Loss: 6.854129267921603\n",
      "Epoch 25/25, Batch 75/119, Loss: 8.242314085690873\n",
      "Epoch 25/25, Batch 76/119, Loss: 6.9101123250509975\n",
      "Epoch 25/25, Batch 77/119, Loss: 7.06891825345114\n",
      "Epoch 25/25, Batch 78/119, Loss: 8.0112427394902\n",
      "Epoch 25/25, Batch 79/119, Loss: 8.391241975296186\n",
      "Epoch 25/25, Batch 80/119, Loss: 8.2732243879576\n",
      "Epoch 25/25, Batch 81/119, Loss: 9.73628626104994\n",
      "Epoch 25/25, Batch 82/119, Loss: 11.158746655024862\n",
      "Epoch 25/25, Batch 83/119, Loss: 8.371353809929976\n",
      "Epoch 25/25, Batch 84/119, Loss: 7.2795339039676525\n",
      "Epoch 25/25, Batch 85/119, Loss: 6.524992400208974\n",
      "Epoch 25/25, Batch 86/119, Loss: 7.438268758618466\n",
      "Epoch 25/25, Batch 87/119, Loss: 6.168436414086945\n",
      "Epoch 25/25, Batch 88/119, Loss: 7.648172993885876\n",
      "Epoch 25/25, Batch 89/119, Loss: 7.6924504219632475\n",
      "Epoch 25/25, Batch 90/119, Loss: 8.034210558051818\n",
      "Epoch 25/25, Batch 91/119, Loss: 7.88129096973538\n",
      "Epoch 25/25, Batch 92/119, Loss: 5.087958200245234\n",
      "Epoch 25/25, Batch 93/119, Loss: 5.724987337657593\n",
      "Epoch 25/25, Batch 94/119, Loss: 7.148797738554186\n",
      "Epoch 25/25, Batch 95/119, Loss: 5.432128335734026\n",
      "Epoch 25/25, Batch 96/119, Loss: 7.840401379653617\n",
      "Epoch 25/25, Batch 97/119, Loss: 4.831531452247811\n",
      "Epoch 25/25, Batch 98/119, Loss: 6.237036622886652\n",
      "Epoch 25/25, Batch 99/119, Loss: 6.663661289963328\n",
      "Epoch 25/25, Batch 100/119, Loss: 9.641440046284002\n",
      "Epoch 25/25, Batch 101/119, Loss: 6.310012443222811\n",
      "Epoch 25/25, Batch 102/119, Loss: 9.431278750325461\n",
      "Epoch 25/25, Batch 103/119, Loss: 5.246372569435359\n",
      "Epoch 25/25, Batch 104/119, Loss: 8.521407118621747\n",
      "Epoch 25/25, Batch 105/119, Loss: 8.010931895316782\n",
      "Epoch 25/25, Batch 106/119, Loss: 4.817346697258048\n",
      "Epoch 25/25, Batch 107/119, Loss: 8.345438540390715\n",
      "Epoch 25/25, Batch 108/119, Loss: 6.753764357705729\n",
      "Epoch 25/25, Batch 109/119, Loss: 5.159013181742803\n",
      "Epoch 25/25, Batch 110/119, Loss: 9.075537594067685\n",
      "Epoch 25/25, Batch 111/119, Loss: 7.835193985275731\n",
      "Epoch 25/25, Batch 112/119, Loss: 7.288567998407639\n",
      "Epoch 25/25, Batch 113/119, Loss: 5.700228115297041\n",
      "Epoch 25/25, Batch 114/119, Loss: 7.997657817476401\n",
      "Epoch 25/25, Batch 115/119, Loss: 6.078980710451148\n",
      "Epoch 25/25, Batch 116/119, Loss: 9.29185237488915\n",
      "Epoch 25/25, Batch 117/119, Loss: 8.603526114099484\n",
      "Epoch 25/25, Batch 118/119, Loss: 8.225658135120003\n",
      "Epoch 25/25, Batch 119/119, Loss: 6.2975435582109265\n",
      "Epoch 25/25, Batch 120/119, Loss: 8.556719786006218\n",
      "Output of a neural network with 30 neurons in a single hidden layer, a learning rate of 0.01, data divided into 500 and passed over 25 times:\n",
      "Correct classifications made: 54167\n",
      "Incorrect classifications made: 5832\n",
      "Overall Accuracy: 90.27983799729995%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "testing_data = pd.read_csv(\"assets/testing10000.csv\")\n",
    "testing_data_labels = pd.read_csv(\"assets/testing10000_labels.csv\")\n",
    "\n",
    "training_data = pd.read_csv(\"assets/training60000.csv\")\n",
    "training_data_labels = pd.read_csv(\"assets/training60000_labels.csv\")\n",
    "\n",
    "#print(\"training data labels dimensions look like: \")\n",
    "#print(training_data_labels.shape)\n",
    "#print(\"The first 5 rows of the original labels: \")\n",
    "#print(training_data_labels[:5])\n",
    "\n",
    "\n",
    "#need functions to pull data from the csv, pass 2 dataframes\n",
    "def load_from_csv(features, labels):\n",
    "    X = features.values\n",
    "    y = labels.values\n",
    "    return X, y\n",
    "\n",
    "#for final accuracy calc\n",
    "def calculate_accuracy(predictions, ground_truth):\n",
    "    correct_predictions = np.sum(predictions == ground_truth)\n",
    "    total_samples = len(ground_truth)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return accuracy * 100\n",
    "\n",
    "#logistic activation function, also known as sigmoid\n",
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#derivative of the logistic function as well\n",
    "def logistic_deriv(x):\n",
    "    return x * (1-x)\n",
    "\n",
    "#softmax activation function\n",
    "def softmax(x):\n",
    "    exp = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp / np.sum(exp, axis=1, keepdims=True)\n",
    "\n",
    "#mean squared error for the cost of prediction\n",
    "def mean_squared_error(true, prediction):\n",
    "    return np.mean((true, prediction)**2)\n",
    "\n",
    "#and the derivative of the function\n",
    "def mean_squared_error_deriv(true, prediction):\n",
    "    return 2 * (prediction - true) / len(true)\n",
    "\n",
    "#cross entropy\n",
    "def cross_entropy_loss(true, prediction):\n",
    "    #epsilon storage\n",
    "    epsilon = 1e-8\n",
    "    prediction = np.clip(prediction, epsilon, 1 - epsilon)\n",
    "    return -np.sum(true * np.log(prediction)) / len(true)\n",
    "\n",
    "#and the cross entropy derivative\n",
    "def cross_entropy_loss_deriv(true, prediction):\n",
    "    return (prediction - true) / len(true)\n",
    "\n",
    "\n",
    "\n",
    "def initialize_weights(input, hidden, output):\n",
    "    #maybe have to set a random seed here? keep it consistent\n",
    "    np.random.seed(42)\n",
    "    weights_input_hidden = np.random.randn(input, hidden)\n",
    "    biases_input_hidden = np.zeros((1, hidden))\n",
    "    weights_hidden_output = np.random.randn(hidden, output)\n",
    "    biases_hidden_output = np.zeros((1, output))\n",
    "    return weights_input_hidden, biases_input_hidden, weights_hidden_output, biases_hidden_output\n",
    "\n",
    "\n",
    "def forward_propogation(X, weights_input, bias_input, weights_hidden_output, biases_hidden_output):\n",
    "    #forward pass\n",
    "    hidden_input = np.dot(X, weights_input) + bias_input\n",
    "    hidden_output = logistic(hidden_input) #use the activation function on the dot product\n",
    "    output_input = np.dot(hidden_output, weights_hidden_output) + biases_hidden_output #for next layer, dot product the activated layer and the weights + bias\n",
    "    output_output = softmax(output_input) #apply softmax to change the values to probabilities, 0.0-1.0\n",
    "    \n",
    "    return hidden_output, output_output #return output of the hidden layer, as well as the probability output we continue passing \n",
    "    \n",
    "\n",
    "#backpropogation\n",
    "def Back_propogate(X, y, hidden_output, output_output, weights_input_hidden, weights_hidden_output, biases_input_hidden, biases_hidden_output, learning_rate):\n",
    "\n",
    "    #find the derivative of the error of the output layer, first by output with cross entropy and then the dot product of the output error with the weights\n",
    "    #to find what we need to change, multiplying it by the deriv of the sigmoid func\n",
    "    output_error = cross_entropy_loss_deriv(y, output_output)\n",
    "    hidden_error = np.dot(output_error, weights_hidden_output.T) * logistic_deriv(hidden_output)\n",
    "\n",
    "    #weight updates with the learning rate\n",
    "    weights_hidden_output -= learning_rate * np.dot(hidden_output.T, output_error)\n",
    "    biases_hidden_output -= learning_rate * np.sum(output_error, axis=0, keepdims=True)\n",
    "    weights_input_hidden -= learning_rate * np.dot(X.reshape(1, -1).T, hidden_error)\n",
    "    biases_input_hidden -= learning_rate * np.sum(hidden_error, axis=0, keepdims=True)\n",
    "\n",
    "def train_neural_network(X_train, Y_train, batch_size, input_size, hidden_size, output_size, learning_rate, epochs):\n",
    "    #generate the weights and biases\n",
    "    weights_input_hidden, biases_input_hidden, weights_hidden_output, biases_hidden_output = initialize_weights(input_size, hidden_size, output_size)\n",
    "\n",
    "    #printed line just to know we entered and that data is being processed\n",
    "    print(\"now processing the data, this will take a while...\")\n",
    "    \n",
    "    #for tracking and printing\n",
    "    correct_classifs = 0\n",
    "    incorrect_classifs = 0\n",
    "\n",
    "    #start doing training loops\n",
    "    for epoch in range(epochs):\n",
    "        indices = np.arange(len(X_train)) #create a var that spans the length of the X training set\n",
    "        np.random.shuffle(indices) #shuffle those indices\n",
    "        X_shuffle, Y_shuffle = X_train[indices], Y_train[indices] #take a data nugget from the y and x training set\n",
    "\n",
    "        for i in range(len(X_shuffle)):\n",
    "            #forward propogation\n",
    "            hidden_output, output_output = forward_propogation(X_shuffle[i], weights_input_hidden, biases_input_hidden, weights_hidden_output, biases_hidden_output)\n",
    "            \n",
    "            #backwards propogation\n",
    "            Back_propogate(X_shuffle[i], Y_shuffle[i], hidden_output, output_output, weights_input_hidden, weights_hidden_output, biases_input_hidden, biases_hidden_output, learning_rate)\n",
    "            \n",
    "            #passing X_shuffle into the forward prop is using the entire dataset, which obviously cant be used\n",
    "            #calculating info loss for the batch\n",
    "            if i % batch_size == 0:\n",
    "                _, train_output = forward_propogation(X_shuffle[i], weights_input_hidden, biases_input_hidden, weights_hidden_output, biases_hidden_output)\n",
    "                loss = cross_entropy_loss(Y_train, train_output)\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Batch {i//batch_size + 1}/{len(X_shuffle)//batch_size}, Loss: {loss}\")\n",
    "\n",
    "    _, final_output = forward_propogation(X_train, weights_input_hidden, biases_input_hidden, weights_hidden_output, biases_hidden_output)\n",
    "    predicted_labels = np.argmax(final_output, axis=1)\n",
    "    ground_truth_labels = np.argmax(Y_train, axis=1)\n",
    "\n",
    "\n",
    "    #print out the params of the process\n",
    "    print(f\"Output of a neural network with {hidden_size} neurons in a single hidden layer, a learning rate of {learning_rate}, data divided into {batch_size} and passed over {epochs} times:\")\n",
    "    \n",
    "    #count the classifs\n",
    "    correct_classifs += np.sum(predicted_labels == ground_truth_labels)\n",
    "    incorrect_classifs += np.sum(predicted_labels != ground_truth_labels)\n",
    "    print(f\"Correct classifications made: {correct_classifs}\")\n",
    "    print(f\"Incorrect classifications made: {incorrect_classifs}\")\n",
    "\n",
    "    # No need for one-hot encoding for ground truth labels in the accuracy calculation\n",
    "    accuracy = calculate_accuracy(predicted_labels, ground_truth_labels)\n",
    "    print(f\"Overall Accuracy: {accuracy}%\")\n",
    "\n",
    "    return weights_input_hidden, biases_input_hidden, weights_hidden_output, biases_hidden_output\n",
    "\n",
    "    \n",
    "x_train, y_train = load_from_csv(training_data, training_data_labels)\n",
    "\n",
    "#details of the ANN outlined by assignment + experiment numbers\n",
    "inputs = 784 #logistic\n",
    "hidden_layers = 30 #can change the number to experiment\n",
    "output_layers = 10 #softmax\n",
    "epochs = 25\n",
    "batches = 500 #batch length, make it much larger for the actual data\n",
    "learn_rate = .01\n",
    "\n",
    "#gotta \"one hot\" the y graph to remove errors\n",
    "def one_hot(y):\n",
    "    one_hot_y = np.zeros((y.size, y.max() + 1))\n",
    "    one_hot_y[np.arange(y.size), y.flatten()] = 1  # Use flatten to ensure correct indexing\n",
    "    return one_hot_y\n",
    "    \n",
    "y_train_hot = one_hot(y_train)\n",
    "\n",
    "#finally, call the program\n",
    "trained_weights_input_hidden, trained_biases_input_hidden, trained_weights_hidden_output, trained_biases_hidden_output = train_neural_network(x_train, y_train_hot, batches, inputs, hidden_layers, output_layers, learn_rate, epochs) \n",
    "\n",
    "#stats for configs:\n",
    "#baseline: 30 layers, 85 epochs, 500 batches, .01 learn rate\n",
    "#Overall Accuracy: 0.9396823280388007 -baseline,\n",
    "#Overall Accuracy: 0.9345655760929349 -15 epochs\n",
    "#Overall Accuracy: 0.9185153085884765 -45 epochs\n",
    "#Overall Accuracy: 0.9090151502525042 -55 epochs\n",
    "#Overall Accuracy: 0.89504825080418 -65 epochs\n",
    "#Overall Accuracy: 0.9027983799729995 -60 epochs, the magic number\n",
    "\n",
    "#proceeding with 25 epochs:\n",
    "# 250 batches = no difference in the loss jumping\n",
    "# .1 learning rate = massive jump in percent, not in the loss jumping\n",
    "#    proceeding to push down the pochs with learn rate at this value:\n",
    "#    20 epochs = Overall Accuracy: 0.9587326455440924 \n",
    "#    10 epochs = Overall Accuracy: 0.9430157169286155\n",
    "#    1 epoch? = Overall Accuracy: 0.8652144202403373 \n",
    "#\n",
    "#    this is likely an overshooting issue, time to see learning rate .001 impact:\n",
    "#    20 epochs = Overall Accuracy: 0.7585126418773647 \n",
    "#    30 epochs = Overall Accuracy: 0.797046617443624 \n",
    "#    85 epoochs = Overall Accuracy: 0.8594476574609576\n",
    "#    the least necessary epochs for the model to have 90% accuracy is much higher than .01,  \n",
    "#    each epoch contributes much less accuracy in this learning rate, implying its too low a number\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f03108-4eb5-421f-9fe1-eda1c29293fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
